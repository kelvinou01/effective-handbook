[{"id":0,"href":"/chapters/","title":"Handbook","section":"The Effective Altruism Handbook You Can Remember (Alpha)","content":" The Effective Altruism Handbook You Can Remember # Contents\n"},{"id":1,"href":"/chapters/the-effectiveness-mindset/","title":"The Effectiveness Mindset","section":"Handbook","content":" About this handbook # What the program is about 1 # Effective altruism (EA) is an ongoing project to find the best ways to do good, and put them into practice.\nOur core goal with this program is to introduce you to some of the principles and thinking tools behind effective altruism. We hope that these tools can help you as you think through how you can best help the world.\nWe also want to share some of the arguments for working on specific problems, like global health or biosecurity. People involved in effective altruism tend to agree that, partly due to uncertainty about which cause is best, we should split our resources between problems. But they don’t agree on what that split should be. People in the effective altruism community actively discuss and disagree about which causes to prioritize and how, even though we’ve learned a lot over the last decade. We hope that you will take these ideas seriously and think for yourself about which ways to help are most effective.\nFinally, we give you some time at the end of the program to begin to reflect on how you personally can help to solve these problems. We don’t expect you’ll have an answer by the end of the eight weeks, but we hope you’re better prepared to explore this further.\nWhat the program involves # Each part of the program has a set of core posts and sometimes an exercise.\nWe think that the core posts take most people about 1-2 hours to get through, and the exercise another 30-60 minutes. We have matched the readings and exercises so that, in total, we think it will take around 2-2.5 hours per week to prepare for the weekly session.\nThe exercises help you put the concepts from the reading into practice.\nBeyond the core posts, there are more materials each week in ‘More to Explore’ — these are all optional and explore the themes of the week in more depth and breadth.\nApproximate reading times are given for each of the posts. Generally, we’d prefer you to take your time and think through the readings instead of rushing.\nThis curriculum was drawn up by staff from the Centre for Effective Altruism, incorporating feedback from others. Ultimately we had to make many judgement calls, and other people would have drawn up a different curriculum. 2\nHow we hope you’ll approach the program # Taking ideas seriously # Often, conversations about ideas are recreational: we enjoy batting around interesting thoughts and saying smart things, and then go back to doing whatever we were already doing in our lives. This is a fine thing to do — but at least sometimes, we think we should be asking ourselves questions like:\n“How could I tell if this idea was true?” “What evidence would it take to convince me that I was wrong about an idea?” “If it is true, what does that imply I should be doing differently in my life? What else does it imply I’m wrong about?” “How might this impact my plans for my career/life?” And, zooming out:\n“Where are my blind spots?” “Which important questions should I be thinking about that I’m not?” “Do I really know if this idea/plan will help make things better or not?” Answering these questions can help make our worldviews as accurate and full as possible and, by extension, help us make better decisions about things that we care about.\nDisagreements are useful # When thoughtful people with access to the same information reach very different conclusions from each other, we should be curious about why and we should actively encourage people to voice and investigate where those disagreements are coming from. If, for example, a medical community is divided on whether Treatment A or B does a better job of curing some disease, they should want to get to the bottom of that disagreement, because the right answer matters — lives are at stake. If you start off disagreeing with someone then change your mind, that can be hard to admit, but we think that should be celebrated. Helping conversations become clearer by changing your mind in response to arguments you find compelling will help the community act to save lives more effectively Even if you don’t expect to end up agreeing with the other person, you’ll learn more if you acknowledge that you disagree and try to understand exactly how and why their views disagree with yours.\nBe aware of our privilege and the seriousness of these issues # We shouldn’t lose sight of our privilege in being able to read and discuss these ideas, or that we are talking about real lives. We’re lucky to be in a position where we can have such a large impact, and this opportunity for impact is the consequence of a profoundly unequal world. Also, be conscious of the fact that people in this program come to these discussions with different ideas, backgrounds, and knowledge. Some of these topics can be uncomfortable to talk about — which is one of the reasons they’re so neglected, and so important to talk about — especially when we may have personal ties to some of these areas.\nExplore further # This handbook aims to introduce people to effective altruism in a structured manner. There are far too many relevant topics, ideas, and research for all but a small fraction of them to fit into this very short program. If you are interested in these topics, you may find it very useful to dive into the linked websites, and the websites those sites link to, and so on.\nThe Effectiveness Mindset # “We are always in triage. I fervently hope that one day we will be able to save everyone. In the meantime, it is irresponsible to pretend that we aren’t making life and death decisions with the allocation of our resources. Pretending there is no choice only makes our decisions worse.\u0026quot;\n— Holly Elmore, explaining the need to prioritize given our limited resources.\nIn this chapter we’ll explore why you might want to help others, why it’s so critical to think carefully about how many people are affected by an intervention, and come to terms with the tradeoffs we face in our altruistic efforts.\nKey concepts in this chapter include:\nScope sensitivity: saving ten lives is more important than saving one, and saving a billion lives is a lot more important than saving ten. Tradeoffs: Because we have limited time and money, we need to prioritize between different ways to improve the world. Scout mindset: We’ll be better able to help others if we’re working together to think clearly and orient towards finding the truth, rather than trying to defend our own ideas. Humans naturally aren’t great at this (aside from wanting to defend our own ideas, we have a host of other biases), but if we want to really understand the world, it’s worth seeking the truth and trying to become clearer thinkers. Introduction to Effective Altruism # This is a linkpost for https://www.effectivealtruism.org/articles/introduction-to-effective-altruism What is effective altruism? # Effective altruism is a project that aims to find the best ways to help others, and put them into practice.\nIt’s both a research field, which aims to identify the world’s most pressing problems and the best solutions to them, and a *practical community** that aims to use those findings to do good.\nThis project matters because, while many attempts to do good fail, some are enormously effective. For instance, some charities help 100 or even 1,000 times as many people as others, when given the same amount of resources.\nThis means that by thinking carefully about the best ways to help, we can do far more to tackle the world’s biggest problems.\nEffective altruism was formalized by scholars at Oxford University, but has now spread around the world, and is being applied by tens of thousands of people in more than 70 countries.3\nPeople inspired by effective altruism have worked on projects that range from funding the distribution of 200 million malaria nets, to academic research on the future of AI, to campaigning for policies to prevent the next pandemic.\nThey’re not united by any particular solution to the world’s problems, but by a way of thinking. They try to find unusually good ways of helping, such that a given amount of effort goes an unusually long way. Here are some examples of what they\u0026rsquo;ve done so far, followed by the values that unite them:\nWhat are some examples of effective altruism in practice? # Preventing the next pandemic # Why this issue? # People in effective altruism typically try to identify issues that are big in scale, tractable, and unfairly neglected.4 The aim is to find the biggest gaps in current efforts, in order to find where an additional person can have the greatest impact. One issue that seems to match those criteria is preventing pandemics.\nResearchers in effective altruism argued as early as 2014 that, given the history of near-misses, there was a good chance that a large pandemic would happen in our lifetimes.\nBut preparing for the next pandemic was, and remains, hugely underfunded compared to other global issues. For instance, the US invests around $8bn per year preventing pandemics, compared to around $280bn per year spent on counterterrorism over the last decade.5\nPreventing terror attacks is certainly important. But the scale of the issue seems smaller. For instance, just to focus on the number of deaths, in the last 50 years, around 500,000 people have been killed by terrorism. But over 21 million people were killed by COVID-19 alone6 – or consider the 40 million killed by HIV/AIDS.7\nNot to mention, a future pandemic could easily be much worse than COVID-19: there’s nothing to rule out a disease that’s more infectious than the Omicron variant, but that’s as deadly as smallpox. (See more on the comparison in footnote 6.)\nIn effective altruism, once a big and neglected problem has been identified, the community then looks for solutions that have a chance of making a big contribution to solving the problem, and are neglected by others working on that issue, which brings us to\u0026hellip;\nSome examples of what’s been done # In 2016 Open Philanthropy – a foundation inspired by effective altruism – became the largest funder of the Johns Hopkins Center for Health Security, which is one of the few groups doing research to identify better policy responses to pandemics, and was an important group in the response to COVID-19.8\nWhen COVID-19 broke out, members of the community founded 1DaySooner, a non-profit that advocates for human challenge trials. In this type of vaccine trial, healthy volunteers are deliberately infected with the disease, enabling near-instant testing of the vaccine. As one of the only advocates for this intervention, 1DaySooner has signed up over 30,000 volunteers,9 and played an important role in starting the world’s first COVID-19 human challenge trial. This model can be repeated when we face the next pandemic.\nMembers of the effective altruism community helped to create the Apollo Programme for Biodefense, a multibillion dollar policy proposal designed to prevent the next pandemic.\nProviding basic medical supplies in poor countries # Why this issue? # It’s common to say that charity begins at home, but in effective altruism, charity begins where we can help the most. And this often means focusing on the people who are most neglected by the current system – which is often those who are more distant from us.\nOver 700 million people live on less than $1.90 per day.10\nIn contrast, an American living near the poverty line lives on 20 times as much, and the average American college graduate lives on about 107 times as much. This places them in the top 1.3% of income, globally speaking.11 (These amounts are already adjusted for the fact that money goes further in poor countries.)\nGlobal inequality is extreme. Because of this, transferring resources to the very poorest people in the world can do a huge amount of good. In richer countries like the US and UK, governments are typically willing to spend over $1 million to save a life.12 This is well worth doing, but in the world’s poorest countries, the cost of saving a life is far lower.\nGiveWell is an organization that does in-depth research to find the most evidence-backed and cost-effective health and development projects. It discovered that while many aid interventions don’t work, some, like providing insecticide-treated bednets, can save a child’s life for about $5,500 on average. That\u0026rsquo;s 180 times less.13\nThese basic medical interventions are so cheap and effective that even the most prominent aid sceptics agree they’re worthwhile.\nSome examples of what’s been done # Over 110,000 individual donors have used GiveWell’s research to contribute more than $1 billion to its recommended charities, supporting organisations like the Against Malaria Foundation, which has distributed over 200 million insecticide-treated bednets. Collectively these efforts are estimated to have saved 159,000 lives.14\nIn addition to charity, it’s possible to help the world’s poorest people through business. Wave is a technology company founded by members of the effective altruism community, which allows people to transfer money to several African countries faster and several times more cheaply than existing services. It’s especially helpful for migrants sending money home to their families, and has been used by over 800,000 people in countries like Kenya, Uganda and Senegal. In Senegal alone, Wave has saved its users hundreds of millions of dollars in transfer fees – around 1% of the country’s GDP.15\nHelping to create the field of AI alignment research # Why this issue? # People in effective altruism often end up focusing on issues that seem counterintuitive, obscure or exaggerated. But this is because it’s more impactful to work on the issues that are neglected by others (all else equal), and these issues are (almost by definition) going to be unconventional ones. One example is the AI alignment problem.\nArtificial intelligence (AI) is progressing rapidly. The leading AI systems are now able to engage in limited conversation, solve college-level maths problems, explain jokes, generate extremely realistic images from text, and do basic coding.16 None of this was possible just ten years ago.\nThe ultimate goal of the leading AI labs is to develop AI that is as good as, or better than, human beings on all tasks. It’s extremely hard to predict the future of technology, but various arguments and expert surveys suggest that this achievement is more likely than not this century. And according to standard economic models, once general AI can perform at human level, technological progress could dramatically accelerate.\nThe result would be an enormous transformation, perhaps of a significance similar to or greater than the industrial revolution in the 1800s. If handled well, this transformation could bring about abundance and prosperity for everyone. If handled poorly, it could result in an extreme concentration of power in the hands of a tiny elite.\nIn the worst case, we could lose control of the AI systems themselves. Unable to govern beings with capabilities far greater than our own, we would find ourselves with as little control over our future as chimpanzees have control over theirs.\nThis means this issue could not only have a dramatic impact on the present generation, but also on all future generations. This makes it especially pressing from a “longtermist” perspective, a school of thinking which holds that improving the long-term future is a key moral priority of our time.\nHow to ensure AI systems continue to further human values, even as they become equal (or superior) to humans in their capabilities, is called the AI alignment problem, and solving it requires advances in computer science.\nDespite its potentially historic importance, only a couple of hundred researchers work on this problem, compared to tens of thousands working to make AI systems more powerful.17\nIt’s hard to sum up the case for the issue in a few paragraphs, so if you’d like to explore more, we’d recommend starting here, here and here.\nSome examples of what’s been done # One priority is to simply tell more people about the issue. The book Superintelligence was published in 2014, making the case for the importance of AI alignment, and became a New York Times best-seller.\nAnother priority is to build a research field focused on this problem. For instance, AI pioneer Stuart Russell, and others inspired by effective altruism, founded The Center for Human-Compatible AI at UC Berkeley. This research institute aims to develop a new paradigm of AI development, in which the act of furthering human values is central.\nOthers have helped to start teams focused on AI alignment at major AI labs such as DeepMind and OpenAI, and outline research agendas for AI alignment, in works such as Concrete Problems in AI Safety.\nEnding factory farming # Why this issue? # People in effective altruism try to extend their circle of concern – not only to those living in distant countries or future generations, but also to non-human animals.\nNearly 10 billion animals live and die in factory farms in the US every year18 – often unable to physically turn around their entire lives, or castrated without anaesthetic.\nLots of people agree we shouldn’t make animals suffer needlessly, but most of this attention goes towards pet shelters. In the US, about 1,400 times more animals pass through factory farms than pet shelters.19\nDespite this, pet shelters receive around $5 billion per year in the US, compared to only $97 million on advocacy to end factory farming.20\nSome examples of what’s been done # One strategy is advocacy. The Open Wing Alliance, which received significant funding from funders inspired by effective altruism, developed a campaign to encourage large companies to commit to stop buying eggs from caged chickens. To date, they have won over 2,200 commitments, and as a result over 100 million birds have been spared from cages.[^21]\nAnother strategy is to create alternative proteins, which if made cheaper and tastier than factory farmed meat, could make demand disappear, ending factory farming. The Good Food Institute is working to kick-start this industry, helping to create companies like Dao Foods in China and Good Catch in the US, encouraging big business to enter the industry (including JBS, the world’s largest meat company) and securing tens of millions of dollars of government support.[^22]\nOpen Philanthropy was an early investor in Impossible Foods, which created the Impossible Burger – an entirely vegan burger that tastes much more like meat, and is now sold in Burger King.\nImproving decision-making # Why this issue? # People who want to do good often prefer to directly tackle problems, since it’s more motivating to see the tangible effects of their actions. But what matters is that the world gets better, not that you do it with your own two hands. So people applying effective altruism often try to help indirectly, by empowering others.\nOne example of this is by improving decision-making. Namely: if key actors — such as politicians, private and third sector leaders, or grantmakers at funding bodies — were generally better at making decisions, society would be in a better position to deal with a whole range of future global problems, whatever they turn out to be.\nSo, if we can find new, neglected ways to improve the decision-making of important actors, that could be a route to having a big impact. And it seems like there are some promising solutions that could achieve this.\nSome examples of what’s been done # Many global problems are exacerbated by a lack of trustworthy information. Metaculus is a forecasting technology platform that identifies important questions (such as the chance of Russia invading Ukraine), aggregates forecasts made by hundreds of forecasters, and weighs them by their past accuracy. Metaculus gave a probability of a Russian invasion of Ukraine of 47% by mid January 2022, and 80% shortly before the invasion on the 24th of February21 – a time when many pundits, journalists and experts were saying it definitely wouldn’t happen.\nThe Global Priorities Institute at the University of Oxford does foundational research at the intersection of philosophy and economics into how key decision-makers can identify the world’s most pressing problems. It has helped to create a new academic field of global priorities research, creating a research agenda, publishing tens of papers, and helping to inspire relevant research at Harvard, NYU, UT Austin, Yale, Princeton and elsewhere.\n"},{"id":2,"href":"/chapters/differences-in-impact/","title":"Differences in Impact","section":"Handbook","content":" Differences in impact # Coming soon.\n"}]