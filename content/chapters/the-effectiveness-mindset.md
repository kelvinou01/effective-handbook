+++
title = 'The Effectiveness Mindset'
date = 2024-01-23T01:12:26+08:00
draft = false
weight = 10
+++

# The Effectiveness Mindset

---

# About this handbook
## What the program is about[^1]

 **Effective altruism (EA) is an ongoing project to find the best ways to do good, and put them into practice.**

 **Our core goal with this program is to introduce you to some of the principles and thinking tools behind effective altruism.** We hope that these tools can help you as you think through how you can best help the world.

We also want to share some of the arguments for working on specific problems, like global health or biosecurity. People involved in effective altruism tend to agree that, partly due to uncertainty about which cause is best, we should split our resources between problems. But they don’t agree on what that split should be. **People in the effective altruism community actively discuss and disagree about which causes to prioritize and how** , even though we’ve learned a lot over the last decade. We hope that you will take these ideas seriously and think for yourself about which ways to help are most effective.

 **Finally, we give you some time at the end of the program to begin to reflect on how you personally can help to solve these problems.** We don’t expect you’ll have an answer by the end of the eight weeks, but we hope you’re better prepared to explore this further.

## What the program involves

Each part of the program has a set of core posts and sometimes an exercise. 

We think that the core posts take most people about 1-2 hours to get through, and the exercise another 30-60 minutes. We have matched the readings and exercises so that, in total, we think it will take around 2-2.5 hours per week to prepare for the weekly session.

The exercises help you put the concepts from the reading into practice.

Beyond the core posts, there are more materials each week in ‘More to Explore’ — these are all optional and explore the themes of the week in more depth and breadth. 

Approximate reading times are given for each of the posts. Generally, we’d prefer you to take your time and think through the readings instead of rushing.

This curriculum was drawn up by staff from the Centre for Effective Altruism, incorporating feedback from others. Ultimately we had to make many judgement calls, and other people would have drawn up a different curriculum.[^2]

## How we hope you’ll approach the program

###  **Taking ideas seriously**

Often, conversations about ideas are recreational: we enjoy batting around interesting thoughts and saying smart things, and then go back to doing whatever we were already doing in our lives. This is a fine thing to do — but at least sometimes, we think we should be asking ourselves questions like: 

  * “How could I tell if this idea was true?”
  * “What evidence would it take to convince me that I was wrong about an idea?”
  * “If it is true, what does that imply I should be doing differently in my life? What else does it imply I’m wrong about?”
  * “How might this impact my plans for my career/life?”



And, zooming out: 

  * “Where are my blind spots?”
  * “Which important questions should I be thinking about that I’m not?”
  * “Do I really know if this idea/plan will help make things better or not?”



Answering these questions can help make our worldviews as accurate and full as possible and, by extension, help us make better decisions about things that we care about.

###  **Disagreements are useful**

When thoughtful people with access to the same information reach very different conclusions from each other, we should be curious about why and we should actively encourage people to voice and investigate where those disagreements are coming from. If, for example, a medical community is divided on whether Treatment A or B does a better job of curing some disease, they should want to get to the bottom of that disagreement, because the right answer matters — lives are at stake. If you start off disagreeing with someone then change your mind, that can be hard to admit, but we think that should be celebrated. Helping conversations become clearer by changing your mind in response to arguments you find compelling will help the community act to save lives more effectively Even if you don’t expect to end up agreeing with the other person, you’ll learn more if you acknowledge that you disagree and try to _understand_ exactly how and why their views disagree with yours.

###  **Be aware of our privilege and the seriousness of these issues**

We shouldn’t lose sight of our privilege in being able to read and discuss these ideas, or that we are talking about real lives. We’re lucky to be in a position where we can have such a large impact, and this opportunity for impact is the consequence of a profoundly unequal world. Also, be conscious of the fact that people in this program come to these discussions with different ideas, backgrounds, and knowledge. Some of these topics can be uncomfortable to talk about — which is one of the reasons they’re so neglected, and so important to talk about — especially when we may have personal ties to some of these areas.

###  **Explore further**

This handbook aims to introduce people to effective altruism in a structured manner. There are far too many relevant topics, ideas, and research for all but a small fraction of them to fit into this very short program. If you are interested in these topics, you may find it very useful to dive into the linked websites, and the websites those sites link to, and so on.

_This work is licensed under a_[ _Creative Commons Attribution 4.0 International License_](https://creativecommons.org/licenses/by/4.0/) _._  

[^1]: This handbook is also accessible as a Google Doc version [here](https://docs.google.com/document/d/1ju83W3yFqvUBvsSrHadjEwazNBphCTmLWd-xZkVArBM/edit?usp=sharin
[^2]: Our goal is to introduce people to some of the core principles of effective altruism, to share the arguments for different problems that people in effective altruism work on, and to encourage you to think about what you want to do on the basis of those ideas. We also tried to give a balance of materials that is in line with the (significant) diversity of views on these topics within effective altruism. 

    In drawing up the curriculum, we consulted community members, subject matter experts, and program facilitators.

    We think that these readings are interesting and give a good introduction, but we hope that you engage with them critically, rather than taking them all at face value. Once you’ve read this curriculum, we encourage you to explore other EA writings (e.g. on [_this wiki_](https://forum.effectivealtruism.org/topics/all)
# The Effectiveness Mindset
> _“We are always in triage. I fervently hope that one day we will be able to save everyone. In the meantime, it is irresponsible to pretend that we aren’t making life and death decisions with the allocation of our resources. Pretending there is no choice only makes our decisions worse."_

\- [_Holly Elmore_](https://forum.effectivealtruism.org/s/B79ro5zkhndbBKRRX/p/vQpk3cxdAe5RX9xzo), explaining the need to prioritize given our limited resources.

In this chapter we’ll explore why you might want to help others, why it’s so critical to think carefully about how many people are affected by an intervention, and come to terms with the tradeoffs we face in our altruistic efforts.

Key concepts in this chapter include:

  *  **Scope sensitivity:** saving ten lives is more important than saving one, and saving a billion lives is a lot more important than saving ten.
  *  **Tradeoffs:** Because we have limited time and money, we need to prioritize between different ways to improve the world.
  *  **Scout mindset:** We’ll be better able to help others if we’re working together to think clearly and orient towards finding the truth, rather than trying to defend our own ideas. Humans naturally aren’t great at this (aside from wanting to defend our own ideas, we have a host of other biases), but if we want to really understand the world, it’s worth seeking the truth and trying to become clearer thinkers.  


{{< rawhtml >}}

<html>
  <head>
    <script type="module" src="https://js.withorbit.com/orbit-web-component.js"></script>
  </head>
  <body>
    <orbit-reviewarea color="blue">
      <orbit-prompt
        question="What's scope sensitivity?"
        answer="Saving ten lives is more important than saving one."
      ></orbit-prompt>
      <orbit-prompt
        question="What kinds of tradeoffs will this chapter cover?"
        answer="How to prioritize between different ways of improving the world."
      ></orbit-prompt>
      <orbit-prompt
        question="What's the scout mindset in a nutshell?"
        answer="To think more clearly, it's better to truthseek rather than defend our own ideas."
      ></orbit-prompt>
    </orbit-reviewarea>
  </body>
</html>

{{< /rawhtml >}}


_This work is licensed under a_[ _Creative Commons Attribution 4.0 International License_](https://creativecommons.org/licenses/by/4.0/) _._

# Introduction to Effective Altruism
This is a linkpost for [https://www.effectivealtruism.org/articles/introduction-to-effective-altruism](https://forum-bots.effectivealtruism.org/out?url=https%3A%2F%2Fwww.effectivealtruism.org%2Farticles%2Fintroduction-to-effective-altruism)

## What is effective altruism?

Effective altruism is a project that aims to find the best ways to help others, and put them into practice.

It’s both a **research field** , which aims to identify the world’s most pressing problems and the best solutions to them, and a **practical community** that aims to use those findings to do good.

This project matters because, while many attempts to do good fail, some are enormously effective. For instance, some charities help 100 or even 1,000 times as many people as others, when given the same amount of resources.

This means that by thinking carefully about the best ways to help, we can do far more to tackle the world’s biggest problems.

Effective altruism was formalized by scholars at Oxford University, but has now spread around the world, and is being applied by tens of thousands of people in more than 70 countries.[^3]

People inspired by effective altruism have worked on projects that range from funding the distribution of 200 million malaria nets, to academic research on the future of AI, to campaigning for policies to prevent the next pandemic.

They’re not united by any particular solution to the world’s problems, but by a way of thinking. They try to find _unusually_ good ways of helping, such that a given amount of effort goes an unusually long way. Here are some examples of what they've done so far, followed by the values that unite them:

{{< rawhtml >}}

<html>
  <head>
    <script type="module" src="https://js.withorbit.com/orbit-web-component.js"></script>
  </head>
  <body>
    <orbit-reviewarea color="blue">
      <orbit-prompt
        question="Why does effective altruism matter?"
        answer="Some charities help 100 or 1,000 times as many people as others, when given the same amount of resources. By thinking carefully, we can help alot more. "
      ></orbit-prompt>
      <orbit-prompt
        question="Is Effective Altruism tied to a few cause areas or solutions?"
        answer="Effective Altruism is about a way of thinking, and not about any particular solution to a problem. EAs have worked on projects that range from funding the distribution of 200 million malaria nets, to academic research on the future of AI, to campaigning for policies to prevent the next pandemic."
      ></orbit-prompt>
    </orbit-reviewarea>
  </body>
</html>

{{< /rawhtml >}}

## What are some examples of effective altruism in practice?

### Preventing the next pandemic

_**Why this issue?**_

People in effective altruism [typically try to](https://forum.effectivealtruism.org/topics/itn-framework) identify issues that are big in scale, tractable, and unfairly neglected.[^4] The aim is to find the biggest gaps in current efforts, in order to find where an additional person can have the greatest impact. One issue that seems to match those criteria is preventing pandemics.

Researchers in effective altruism argued as [early as 2014](https://www.openphilanthropy.org/research/biosecurity/) that, given the history of near-misses, there was a good chance that a large pandemic would happen in our lifetimes.

But preparing for the next pandemic was, and remains, hugely underfunded compared to other global issues. For instance, the US invests around $8bn per year preventing pandemics, compared to around $280bn per year spent on counterterrorism over the last decade.[^5]

![Pandemic prevention spending](//images.ctfassets.net/ohf186sfn6di/2RSKzGMbKhiDFJCCWYAWrl/4d922de1a547a6c84fb9101494628520/preventing-pandemics.png)

Preventing terror attacks is certainly important. But the scale of the issue seems smaller. For instance, just to focus on the number of deaths, in the last 50 years, around 500,000 people have been killed by terrorism. But over 21 million people were killed by COVID-19 alone[^6] – or consider the 40 million killed by HIV/AIDS.[^7]

![Pandemic deaths comparison](//images.ctfassets.net/ohf186sfn6di/425KeJZGR7KzkYCLd5XGRa/affb2cda3497371f1b1a67bfbdb7387a/people-died-pandemics.png)

Not to mention, a future pandemic could easily be much worse than COVID-19: there’s nothing to rule out a disease that’s more infectious than the Omicron variant, but that’s as deadly as smallpox. (See more on the comparison in footnote 4.)

In effective altruism, once a big and neglected problem has been identified, the community then looks for solutions that have a chance of making a big contribution to solving the problem, and are neglected by others working on that issue, which brings us to...

_**Some examples of what’s been done**_

In 2016 Open Philanthropy – a foundation inspired by effective altruism – became the largest funder of the [Johns Hopkins Center for Health Security](https://www.centerforhealthsecurity.org/), which is one of the few groups doing research to identify better policy responses to pandemics, and was an important group in the response to COVID-19.[^8]

When COVID-19 broke out, members of the community founded [1DaySooner](https://www.1daysooner.org/), a non-profit that advocates for human challenge trials. In this type of vaccine trial, healthy volunteers are deliberately infected with the disease, enabling near-instant testing of the vaccine. As one of the only advocates for this intervention, 1DaySooner has signed up over 30,000 volunteers,[^9] and played an important role in starting the world’s first COVID-19 human challenge trial. This model can be repeated when we face the next pandemic.

Members of the effective altruism community helped to create the [Apollo Programme for Biodefense](https://biodefensecommission.org/reports/the-apollo-program-for-biodefense-winning-the-race-against-biological-threats/), a multibillion dollar policy proposal designed to prevent the next pandemic.

### Providing basic medical supplies in poor countries

_**Why this issue?**_

It’s common to say that charity begins at home, but in effective altruism, charity begins where we can help the most. And this often means focusing on the people who are most neglected by the current system – which is often those who are more distant from us.

Over 700 million people live on less than $1.90 per day.[^10]

In contrast, an American living near the poverty line lives on 20 times as much, and the average American college graduate lives on about 107 times as much. This places them in the top 1.3% of income, globally speaking.[^11] (These amounts are already adjusted for the fact that money goes further in poor countries.)

![Income distribution](//images.ctfassets.net/ohf186sfn6di/2OBdC3oRfp4Naw8wr9CoT3/e4b50e3f0a32612355ad860212aba460/income-inequality.png)

Global inequality is extreme. Because of this, transferring resources to the very poorest people in the world can do a huge amount of good. In richer countries like the US and UK, governments are typically willing to spend over $1 million to save a life.[^12] This is well worth doing, but in the world’s poorest countries, the cost of saving a life is far lower.

[GiveWell](https://www.givewell.org/) is an organization that does in-depth research to find the most evidence-backed and cost-effective health and development projects. It discovered that while [many aid interventions don’t work](https://www.givewell.org/international/technical/criteria/impact/failure-stories), some, like providing insecticide-treated bednets, can save a child’s life for about $5,500 on average. That's 180 times less.[^13]

These basic medical interventions are so cheap and effective that even the [most prominent aid sceptics agree](https://blog.givewell.org/2015/11/06/the-lack-of-controversy-over-well-targ) they’re worthwhile.

![Cost to save a life](//images.ctfassets.net/ohf186sfn6di/4boif3LzHTuApM9zJnLiCO/0240962897ddce69fd87e3b55b505e99/cost-to-save-a-life.png)

_**Some examples of what’s been done**_

Over **110,000 individual donors** have used GiveWell’s research to contribute more than $1 billion to its recommended charities, supporting organisations like the [Against Malaria Foundation](https://www.givewell.org/charities/amf), which has distributed over 200 million insecticide-treated bednets. Collectively these efforts are estimated to have saved **159,000 lives**.[^14]

In addition to charity, it’s possible to help the world’s poorest people through business. [Wave](https://www.wave.com/) is a technology company founded by members of the effective altruism community, which allows people to transfer money to several African countries faster and several times more cheaply than existing services. It’s especially helpful for migrants sending money home to their families, and has been used by over 800,000 people in countries like Kenya, Uganda and Senegal. In Senegal alone, Wave has saved its users hundreds of millions of dollars in transfer fees – around 1% of the country’s GDP.[^15]

### Helping to create the field of AI alignment research

_**Why this issue?**_

People in effective altruism often end up focusing on issues that seem counterintuitive, obscure or exaggerated. But this is because it’s more impactful to work on the issues that are neglected by others (all else equal), and these issues are (almost by definition) going to be unconventional ones. One example is the AI alignment problem.

Artificial intelligence (AI) is progressing rapidly. The leading AI systems are now able to engage in limited conversation, solve college-level maths problems, explain jokes, generate extremely realistic images from text, and do basic coding.[^16] None of this was possible just ten years ago.

The ultimate goal of the leading AI labs is to develop AI that is as good as, or better than, human beings on all tasks. It’s extremely hard to predict the future of technology, but [various arguments and expert surveys](https://www.cold-takes.com/where-ai-forecasting-stands-today/) suggest that this achievement is more likely than not this century. And according to [standard economic models](https://www.openphilanthropy.org/research/could-advanced-ai-drive-explosive-economic-growth/), once general AI can perform at human level, technological progress could dramatically accelerate.

The result would be an enormous transformation, perhaps of a significance similar to or greater than the industrial revolution in the 1800s. If handled well, this transformation could bring about abundance and prosperity for everyone. If handled poorly, it could result in an extreme concentration of power in the hands of a tiny elite.

In the worst case, we could [lose control](https://www.cold-takes.com/ai-could-defeat-all-of-us-combined/) of the AI systems themselves. Unable to govern beings with capabilities far greater than our own, we would find ourselves with as little control over our future as chimpanzees have control over theirs.

This means this issue could not only have a dramatic impact on the present generation, but also on all future generations. This makes it especially pressing from a [“longtermist”](https://en.wikipedia.org/wiki/Longtermism) perspective, a school of thinking which holds that improving the long-term future is a key moral priority of our time.

How to ensure AI systems continue to further human values, even as they become equal (or superior) to humans in their capabilities, is called the AI alignment problem, and solving it requires advances in computer science.

Despite its potentially historic importance, only a couple of hundred researchers work on this problem, compared to tens of thousands working to make AI systems more powerful.[^17]

![AI research distribution](//images.ctfassets.net/ohf186sfn6di/4Dmdh2qtvIIFset8KpgQ3f/7e8e43eb82f3f6ff42b47828714a701a/ai-alignment.png)

It’s hard to sum up the case for the issue in a few paragraphs, so if you’d like to explore more, we’d recommend starting [here](https://www.vox.com/future-perfect/2018/12/21/18126576/ai-artificial-intelligence-machine-learning-safety-alignment), [here](https://80000hours.org/problem-profiles/positively-shaping-artificial-intelligence/) and [here](https://www.cold-takes.com/most-important-century/).

_**Some examples of what’s been done**_

One priority is to simply tell more people about the issue. The book [Superintelligence](https://en.wikipedia.org/wiki/Superintelligence:_Paths,_Dangers,_Strategies) was published in 2014, making the case for the importance of AI alignment, and became a [New York Times best-seller](https://en.wikipedia.org/wiki/Superintelligence:_Paths,_Dangers,_Strategies#Reception).

Another priority is to build a research field focused on this problem. For instance, AI pioneer Stuart Russell, and others inspired by effective altruism, founded [The Center for Human-Compatible AI](https://humancompatible.ai/) at UC Berkeley. This research institute aims to develop a new paradigm of AI development, in which the act of furthering human values is central.

Others have helped to start teams focused on AI alignment at major AI labs such as [DeepMind](https://www.deepmind.com/safety-and-ethics) and [OpenAI](https://openai.com/alignment/), and outline research agendas for AI alignment, in works such as _[Concrete Problems in AI Safety](https://arxiv.org/abs/1606.06565)_.

### Ending factory farming

_**Why this issue?**_

People in effective altruism try to extend their circle of concern – not only to those living in distant countries or future generations, but also to non-human animals.

Nearly 10 billion animals live and die in factory farms in the US every year[^18] – often unable to physically turn around their entire lives, or castrated without anaesthetic.

Lots of people agree we shouldn’t make animals suffer needlessly, but most of this attention goes towards pet shelters. In the US, about 1,400 times more animals pass through factory farms than pet shelters.[^19]

![Animals welfare populations](//images.ctfassets.net/ohf186sfn6di/5dA70W90MID78GFwwIRqld/b0d116e4fd89ee23038e69867a46e2c1/farm-population.png)

Despite this, pet shelters receive around $5 billion per year in the US, compared to only $97 million on advocacy to end factory farming.[^20]

![Animal welfare spending](//images.ctfassets.net/ohf186sfn6di/1kZ0PaxZYmCbQojCedld2r/6ad67f274012f394bf0c3fd6962fa6c3/spending-on-farms.png)

_**Some examples of what’s been done**_

One strategy is advocacy. The [Open Wing Alliance](https://openwingalliance.org/impact), which received significant funding from funders inspired by effective altruism, developed a campaign to encourage large companies to commit to stop buying eggs from caged chickens. To date, they have won over 2,200 commitments, and as a result over 100 million birds have been spared from cages.[^21]

Another strategy is to create alternative proteins, which if made cheaper and tastier than factory farmed meat, could make demand disappear, ending factory farming. The [Good Food Institute](https://gfi.org/) is working to kick-start this industry, helping to create companies like Dao Foods in China and Good Catch in the US, encouraging big business to enter the industry (including JBS, the world’s largest meat company) and securing tens of millions of dollars of government support.[^22]

Open Philanthropy was an [early investor](https://www.openphilanthropy.org/grants/impossible-foods-rd-investment/#:~:text=working%20to%20overcome.-,Background,Impossible%20Burger%2C%20in%20July%202016.) in [Impossible Foods](https://en.wikipedia.org/wiki/Impossible_Foods), which created the Impossible Burger – an entirely vegan burger that tastes much more like meat, and is now sold in Burger King.

### Improving decision-making

_**Why this issue?**_

People who want to do good often prefer to _directly_ tackle problems, since it’s more motivating to see the tangible effects of their actions. But what matters is that the world gets better, not that you do it with your own two hands. So people applying effective altruism often try to help indirectly, by empowering others.

One example of this is by improving decision-making. Namely: if key actors — such as politicians, private and third sector leaders, or grantmakers at funding bodies — were generally better at making decisions, society would be in a better position to deal with a whole range of future global problems, whatever they turn out to be.

So, if we can find new, neglected ways to improve the decision-making of important actors, that could be a route to having a big impact. And it seems like there are some promising solutions that could achieve this.

_**Some examples of what’s been done**_

Many global problems are exacerbated by a lack of trustworthy information. [Metaculus](https://www.metaculus.com/questions/) is a forecasting technology platform that identifies important questions (such as the chance of Russia invading Ukraine), aggregates forecasts made by hundreds of forecasters, and weighs them by their past accuracy. Metaculus gave a probability of a Russian invasion of Ukraine of 47% by mid January 2022, and 80% shortly before the invasion on the 24th of February[^23] – a time when many pundits, journalists and experts were saying it definitely wouldn’t happen.

![Metaculus Ukraine Prediction](//images.ctfassets.net/ohf186sfn6di/22g4yYIsFMo0Kxb5kDsFxW/1358738ab1c09daadf73896c9929e89d/metaculus.png)

The [Global Priorities Institute](https://globalprioritiesinstitute.org/) at the University of Oxford does foundational research at the intersection of philosophy and economics into how key decision-makers can identify the world’s most pressing problems. It has helped to create a new academic field of global priorities research, creating a [research agenda](https://globalprioritiesinstitute.org/research-agenda/), publishing [tens of papers](https://globalprioritiesinstitute.org/papers/), and helping to inspire relevant research at Harvard, NYU, UT Austin, Yale, Princeton and elsewhere.

{{< rawhtml >}}

<html>
  <head>
    <script type="module" src="https://js.withorbit.com/orbit-web-component.js"></script>
  </head>
  <body>
    <orbit-reviewarea color="blue">
      <orbit-prompt
        question="Why is preventing the next pandemic a big issue?"
        answer="Much less is spent on preventing pandemics compared to counterterrorism, while the number of deaths due to covid-19 far exceed the number of deaths from terrorism.
        In effective altruism, once a big and neglected problem has been identified, the community then looks for solutions that have a chance of making a big contribution to solving the problem, and are neglected by others working on that issue"
      ></orbit-prompt>
      <orbit-prompt
        question="Why is providing basic medical supplies in poor countries a big issue?"
        answer="Over 700 million people live on less than $1.90 per day. In contrast, an American living near the poverty line lives on 20 times as much, and the average American college graduate lives on about 107 times as much. Global inequality is extreme. Because of this, transferring resources to the very poorest people in the world can do a huge amount of good."
      ></orbit-prompt>
      <orbit-prompt
        question="Why is AI alignment a big issue?"
        answer="With rapid progress in artificial intelligence (AI), the goal is to develop AI surpassing human capabilities. The potential consequences, both positive and negative, are compared to the significance of the industrial revolution. If handled well, AI advancements could bring prosperity, but if mismanaged, power could concentrate in the hands of a few, or worse, control could be lost.
        The AI alignment problem, ensuring AI systems align with human values, is crucial for the future. Despite its significance, only a small number of researchers work on this problem compared to those enhancing AI capabilities. The issue not only impacts the present generation but holds long-term implications, making it a priority from a "longtermist" perspective."
      ></orbit-prompt>
      <orbit-prompt
        question="Why is ending factory farming a big issue?"
        answer="Nearly 10 billion animals live and die in factory farms in the US every year – often unable to physically turn around their entire lives, or castrated without anaesthetic. In the US, about 1,400 times more animals pass through factory farms than pet shelters, but pet shelters receive around $5 billion per year in the US, compared to only $97 million on advocacy to end factory farming "
      ></orbit-prompt>
      <orbit-prompt
        question="Why is improving decision making a big issue?"
        answer="If key actors — such as politicians, private and third sector leaders, or grantmakers at funding bodies — were generally better at making decisions, society would be in a better position to deal with a whole range of future global problems, whatever they turn out to be."
      ></orbit-prompt>
    </orbit-reviewarea>
  </body>
</html>

{{< /rawhtml >}}

## What values unite effective altruism?

Effective altruism isn't defined by the projects above, and what it focuses on could easily change. What defines effective altruism are some tentative values and principles that underpin its search for the best ways of helping others:

  1. **Prioritization:** Our [intuitions](https://en.wikipedia.org/wiki/Scope_neglect) about doing good don't usually take into account the scale of the outcomes — helping 100 people often makes us feel as satisfied as helping 1000. But since some ways of doing good also achieve dramatically more than others, it’s vital to attempt to use numbers to roughly weigh how much different actions help. The goal is to find _the best_ ways to help, rather than just working to make any difference at all.

  2. **Impartial altruism:** It's easy — and reasonable — to have special concern for one's own family, friends or nation. But, when trying to do as much good as possible, it seems that we should give everyone's interests equal weight, no matter where or when they live. This means focusing on the groups who are most neglected, which usually means focusing on those who don’t have as much power to protect their own interests.

  3. **Open truthseeking:** Rather than starting with a commitment to a certain cause, community or approach, it’s important to consider many different ways to help and seek to find the best ones. This means putting serious time into deliberation and reflection on one’s beliefs, being constantly open and curious for new evidence and arguments, and being ready to change one’s views quite radically.

  4. **Collaborative spirit:** It’s often possible to achieve more by working together, and doing this effectively requires high standards of honesty, integrity, and compassion. Effective altruism does not mean supporting ‘ends justify the means’ reasoning, but rather is about being a good citizen, while working toward a better world.




We’re not totally confident in the above ideas - but we think that they are probably right, and that they are undervalued by much of society. Anyone who is trying to find better ways to help others is participating in effective altruism. This is true no matter how much time or money they want to give, or which issue they choose to focus on.

Effective altruism can be compared to the scientific method. Science is the use of evidence and reason in search of truth – even if the results are unintuitive or run counter to tradition. Effective altruism is the use of evidence and reason in search of the best ways of doing good.

The scientific method is based on simple ideas (e.g. that you should test your beliefs) but it leads to a radically different picture of the world (e.g. quantum mechanics). Likewise, effective altruism is based on simple ideas – that we should treat people equally and it’s better to help more people than fewer – but it leads to an unconventional and ever-evolving picture of doing good.

{{< rawhtml >}}

<html>
  <head>
    <script type="module" src="https://js.withorbit.com/orbit-web-component.js"></script>
  </head>
  <body>
    <orbit-reviewarea color="blue">
      <orbit-prompt
        question="What are the values of Effective Altruism?"
        answer="Prioritization, impartial altruism, open seeking, and collaborative spirit."
      ></orbit-prompt>
    </orbit-reviewarea>
  </body>
</html>

{{< /rawhtml >}}

## How can you take action?

People interested in effective altruism most often attempt to apply the ideas in their lives by:

  * Choosing careers that help tackle pressing problems, or by finding ways to use their existing skills to contribute to these problems, such as by using advice from [80,000 Hours](https://80000hours.org/).

  * Donating to carefully chosen charities, such as by using research from [GiveWell](https://www.givewell.org/) or [Giving What We Can](https://www.givingwhatwecan.org/best-charities-to-donate-to-2022).

  * [Starting new organizations](https://80000hours.org/career-reviews/founder-impactful-organisations/#lists-of-ideas) that help to tackle pressing problems.

  * Helping to build communities tackling pressing problems.




See a [longer list of ways to take action](https://forum.effectivealtruism.org/topics/take-action).

The above are not exhaustive. You can apply effective altruism no matter how much you want to focus on doing good, and in any area of your life – what matters is that, no matter how much you want to contribute, your efforts are driven by the four values above, and you try to make your efforts as effective as possible.

Typically, this involves trying to identify big and neglected global problems, the most effective solutions to those problems, and ways you can contribute to those solutions – with whatever time or money you’re willing to give.

By doing this and thinking carefully, you might find it’s possible to have far more impact with those resources. It really is possible to save hundreds of people’s lives over your career. And by teaming up with others in the community, you can play a role in tackling some of the most important issues civilization faces today.
[^3]: You can see the global distribution of local EA groups on the [Effective Altruism Forum](https://forum.effectivealtruism.org/community), which lists groups in over 70 countries
[^4]: The less neglected an issue, the more the best opportunities will have been taken, so the harder it will be for an additional person to make an impact.

    In fact, there are [good reasons to expect](https://web.archive.org/web/20220728174703/https://www.fhi.ox.ac.uk/law-of-logarithmic-returns/) that returns to investment in an issue are roughly logarithmic.

    Logarithmic returns imply that if 10 times more has been invested in one cause compared to another, then additional resources will achieve about 1/10 as much progress.

    If the two issues are equally important, and then an additional person working on the more neglected one will have ten times the impact
[^5]: From 2010 to 2019, US Federal Funding for Health Security is estimated at $141 billion. We judge that 55% of this was spent on what could arguably prevent future pandemics. For example, 4% was spent tackling the ongoing ebola epidemic, which provided infrastructure for potential other pandemics. However, 17% was spent on chemical and nuclear radiation threats in a way unlikely to affect future pandemic spread.

    141 billion * 0.55 = 79 billion

    Annualized over the ten year period is $8 billion per year.

    [Federal funding for health security in FY2019](https://www.liebertpub.com/doi/10.1089/hs.2018.0077) Watson, Crystal, et al., Health security 16.5 (2018): pages 281-303. [Archived link](https://web.archive.org/web/20200305190440/https://www.liebertpub.com/doi/10.1089/hs.2018.0077), accessed 5 March 2020.

    [Open Philanthropy](https://web.archive.org/web/20220708181859/https://www.openphilanthropy.org/research/biosecurity/) also identifies other foundations and philanthropists working on the topic prior to the COVID pandemic, which we believe total under $100 million in funding.

    Crawford, director of the Costs of War project, calculates US spending on Counter-Terrorism from 2001-2022 to be $5.8 trillion.

    5.8 trillion / 20 years = $290 billion per year.

    [United States budgetary costs of Post-9/11 wars](https://watson.brown.edu/costsofwar/files/cow/imce/papers/2021/Costs%20of%20War_U.S.%20Budgetary%20Costs%20of%20Post-9%2011%20Wars_9.1.21.pdf) Crawford, Neta C., Watson Institute for International & Public Affairs, Brown University, 2021. [Archived link](https://web.archive.org/web/20220726160700/https://watson.brown.edu/costsofwar/files/cow/imce/papers/2021/Costs%20of%20War_U.S.%20Budgetary%20Costs%20of%20Post-9%2011%20Wars_9.1.21.pdf), accessed 26 July 2022
[^6]: Deaths from terrorism from 1970-2020 were approximately 456,000. This is from the [Global Terrorism Database 2020](https://web.archive.org/web/20220811132237/https://www.start.umd.edu/gtd/search/Results.aspx?chart=fatalities&casualties_type=&casualties_max=), accessed 11 August 2022.

    Note that Our World in Data says "The Global Terrorism Database is the most comprehensive dataset on terrorist attacks available and recent data is complete. However, we expect, based on our analysis, that longer-term data is incomplete (with the exception of the US and Europe). We therefore do not recommend this dataset for the inference of long-term trends in the prevalence of terrorism globally."

    This means the source above is likely an undercount of confirmed terrorism deaths; however, even if we assume deaths have been at the same level as the highest recorded decade (2010-2020) since 1970, the total deathtoll would still only be 1.2 million; far less than deaths due to pandemics.

    Deaths from COVID-19:

    The Economist estimated cumulative excess deaths due to COVID-19 were 21.47m as of June 2022, and this amount is still rising.

    You can see this data and their model through [Our World in Data](https://web.archive.org/web/20220728171227/https://ourworldindata.org/grapher/excess-deaths-cumulative-economist-single-entity?country=~OWID_WRL) (archived page, retrieved 28 July 2022).

    We see this as the best current estimate of COVID-19’s total death toll. The number of _confirmed_ deaths is lower, at around 6 million, but this excludes deaths that were indirectly caused or weren’t reported. The Economist’s methodology compares excess deaths to the seasonal average, to estimate in total how many additional people died, and adjusts for underreporting.

    Deaths due to pandemics and terrorism are both heavy tailed, so past death rates will typically understimate the magnitude of the risk.

    For instance, it’s possible that terrorists could set off a nuclear weapon in a large city, which might kill over 1 million people. This didn’t happen over the last fifty years, but would have been the main driver of the death toll if it had. And likewise, there could have been a pandemic much worse than COVID-19 or HIV/AIDS in the last 50 years.

    The key question then becomes whether the historical record is a greater undercount of the risk for terrorism or for pandemics (i.e. whether terrorism deaths are more heavily-tailed than pandemic deaths).

    It seems plausible that the worst case scenario from pandemics is worse than for terrorism. There’s nothing to rule out the emergence of a pandemic that’s more infectious than COVID-19, but with a fatality rate of 10-50%, or worse. And there seem to be more near-misses in the historical record.

    So, the problem of missing tail events in the sample may well be worse for pandemics than terrorism. Indeed, the most plausible way for terrorism to kill 1+ billion people is probably via causing a pandemic.

    Given that terrorism receives ~100x more funding than pandemic prevention, while pandemics seem to have caused 10-100x more deaths historically, the corrections would need to be very heavily in favour of terrorism in order for the current allocation of resources to seem more balanced.

    The above analysis was just in terms of the number of deaths, since that’s an important yet relatively measurable metric. Deaths due to both pandemics and terrorism also produce important indirect costs, and a fuller comparison would attempt to consider the relative scale of each
[^7]: > “40.1 million [33.6 million–48.6million] people have died from AIDS-related illnesses since the start of the epidemic.”

    [Global HIV & AIDS statistics — Fact sheet](https://www.unaids.org/en/resources/fact-sheet) UNAIDS, 2022. [Archived link](https://web.archive.org/web/20220811142820/https://www.unaids.org/en/resources/fact-sheet), accessed 11 August 2022
[^8]: Open Philanthropy is a foundation inspired by effective altruism. They first funded the Johns Hopkins Centre for Health Security (CHS) [in 2016](https://web.archive.org/web/20220728171005/https://www.openphilanthropy.org/grants/johns-hopkins-center-for-health-security-emerging-leaders-in-biosecurity-initiative/). This was followed by several other large grants, including one for [$16m in 2017](https://web.archive.org/web/20220728171246/https://www.openphilanthropy.org/grants/johns-hopkins-center-for-health-security-biosecurity-global-health-security-and-global-catastrophic-risks-2017/) and another for [$19.5m in 2019](https://web.archive.org/web/20220728171354/https://www.openphilanthropy.org/grants/johns-hopkins-center-for-health-security-biosecurity-global-health-security-and-global-catastrophic-risks-2019/)
[^9]: 38,659 volunteers, as of 7 July 2022. [1Day Sooner](https://web.archive.org/web/20220707165739/https://www.1daysooner.org/
[^10]: Before COVID-19, the number of people living on less that $1.90 per day had decreased to 689 million in 2017. However, estimates now point to the first rise in the extreme poverty rate since 1998, leading to an estimated 731 million people now living on less than $1.90 per day.

    [UN SDG 1 - End poverty in all its forms](https://unstats.un.org/sdgs/report/2021/goal-01/). UN Statistics, 2022. [Archived link](javascript:void\(0\)), accessed 26 July 2022.

    These estimates have been adjusted for the fact that money goes further in poor countries (purchasing parity). There are many complications to the estimates, but it’s clear that hundreds of millions of people live at near subsidence levels of income. See “[how accurately does anyone know the global distribution of income?](https://web.archive.org/web/20220728171308/https://80000hours.org/2017/04/how-accurately-does-anyone-know-the-global-distribution-of-income/)” if you’d like to learn more
[^11]: The US poverty line for 1 person is an annual income of [$13,590](https://web.archive.org/web/20220728171458/https://aspe.hhs.gov/topics/poverty-economic-mobility/poverty-guidelines).

    13,590 / 365 = $37.23 per day.

    This is 20x the international poverty line of $1.90, which is adjusted for purchasing parity.

    According to the [2019 census](https://web.archive.org/web/20220728171531/https://www.census.gov/data/tables/2022/demo/acs-2019.html), full-time workers aged 25-65 with a college degree or higher earned a median of $74,000 per year.

    $74,000 / 365 = $202.7 per day

    $202 / 1.9 = 107x.

    According to [SmartAsset](https://smartasset.com/taxes/income-taxes#PgAT7oh2Ae), a single person household earning $74,000 pre-tax and living in New York, receives about $53,000 post-tax.

    According to Giving What We Can’s [calculator](https://web.archive.org/web/20220728165745/https://howrichami.givingwhatwecan.org/how-rich-am-i?income=53000&countryCode=USA&household%5Badults%5D=1&household%5Bchildren%5D=0), a post-tax income of $53,000 puts you in the top 1.3% of income globally
[^12]: The UK’s National Institute for Health and Care Excellence recommends spending up to £30,000 per [quality-adjusted life year](https://en.wikipedia.org/wiki/Quality-adjusted_life_year) (QALY) gained, where the intervention is reliable.

    “Above a most plausible ICER of £30,000 per QALY gained, advisory bodies will need to make an increasingly stronger case for supporting the intervention as an effective use of NHS resources” [Methods for the development of NICE public health guidance](https://www.nice.org.uk/process/pmg4/chapter/incorporating-health-economics). UK National Institute for Health and Care Excellence, September 2012. [Archived link](https://web.archive.org/web/20220728173611/https://www.nice.org.uk/process/pmg4/chapter/incorporating-health-economics), accessed July 28, 2022.

    It’s typical in global health to say that saving one life is equivalent to 30 QALYs. Source: [World Bank (Box 1.1)](https://web.archive.org/web/20220728171610/https://openknowledge.worldbank.org/bitstream/handle/10986/7039/364010PAPER0Gl101OFFICIAL0USE0ONLY1.pdf?sequence=1)

    This amounts to a cost of saving a life of 30 x £30,000 = £900,000 = $1.1 million.

    In the US, different global agencies estimate “[the value of life](https://en.wikipedia.org/wiki/Value_of_life)”, and use this figure in the prioritization of different spending projects. The Federal Emergency Management Agency estimated the value of life at [$7.5 million](https://web.archive.org/web/20220516225829/https://www.fema.gov/sites/default/files/2020-08/fema_bca_toolkit_release-notes-july-2020.pdf) in 2020. This estimate has fluctuated based on the context. For example, the US Department of Transport estimated the value of life to be between [$5.2 million and $13.0 million](https://web.archive.org/web/20220728173630/https://www.transportation.gov/sites/dot.gov/files/docs/VSL_Guidance_2014.pdf) in 2014
[^13]: GiveWell's estimates of the cost to save a life have varied over time (depending on their research, and which opportunities are available), but have typically fallen within $2,500 to $7,500. In 2021, GiveWell estimated that $5500 spent on distributing insecticide-treated bednets will save one life in expectation.

    You can see their most up-to-date estimates in their full cost-effectiveness analysis: [How We Produce Impact Estimates](https://www.givewell.org/impact-estimates) GiveWell, July 2022. [Archived link](https://web.archive.org/web/20220728173731/https://www.givewell.org/impact-estimates), accessed 28 July 2022
[^14]: > “More than 110,000 donors have trusted GiveWell to direct their donations. Together, they have given over $1 billion to the organizations we recommend. These donations will save over 150,000 lives and provide cash grants of over $175 million to the global poor.”

    [About GiveWell](https://www.givewell.org/about), GiveWell, July 2022. [Archived link](https://web.archive.org/web/20220728173759/https://www.givewell.org/about), accessed 28 July 2022
[^15]: > “When Wave launched in Senegal, our average transfer would have cost 3-5x more if done via the largest existing mobile money system. Multiplied by our millions of monthly active users, that comes out to a savings of over $200 million every year, … around 1% of Senegal’s GDP.”

    [Working at Wave is an extremely effective way to improve the world](https://www.wave.com/en/blog/world/). Ben Kuhn, July 8 2021. [Archived link](https://web.archive.org/web/20220726160441/https://www.wave.com/en/blog/world/), accessed 26 July 2022
[^16]: Conversation: "Our best end-to-end trained Meena model achieves a… SSA [Sensibleness and Specificity Average] score of 72%... our SSA score of 72% is not far from the 86% SSA achieved by the average person.” [Towards a Conversational Agent that Can Chat About…Anything](https://ai.googleblog.com/2020/01/towards-conversational-agent-that-can.html). Adiwardana et. al., Google, 28 January 2020. [Archived link](https://web.archive.org/web/20220728174004/https://ai.googleblog.com/2020/01/towards-conversational-agent-that-can.html), accessed 28 July 2022.

    Math: The graphs in the attached article show Google’s Minerva accurately answers over 50% of “high school math competition-level problems”. Other state-of-the-art models were achieving less than 10% accuracy.

    [Minerva: Solving Quantitative Reasoning Problems with Language Models](https://ai.googleblog.com/2022/06/minerva-solving-quantitative-reasoning.html). Dyer et. al, Google, 30 June 2022. [Archived link](https://web.archive.org/web/20220728174101/https://ai.googleblog.com/2022/06/minerva-solving-quantitative-reasoning.html), accessed 28 July 2022.

    Jokes: Google’s AI PaLM can provide explanations for jokes never seen before, including jokes nowhere on the internet. For example:

    “Joke: Did you see that Google just hired an eloquent whale for their TPU team? It showed them how to communicate between two different pods!

    Explanation: TPUs are a type of computer chip that Google uses for deep learning. A ‘pod’ is a group of TPUs. a ‘pod’ is also a group of whales. The joke is that the whale is able to communicate between two groups of whales, but the speaker is pretending that the whale is able to communicate between two groups of TPUs”

    [Pathways Language Model (PaLM): Scaling to 540 Billion Parameters for Breakthrough Performance](https://ai.googleblog.com/2022/04/pathways-language-model-palm-scaling-to.html). Narang et. al., Google, 4 April 2022. [Archived link](https://web.archive.org/web/20220728174127/https://ai.googleblog.com/2022/04/pathways-language-model-palm-scaling-to.html)

    Images: Example images from OpenAI’s Dall-E 2 can be seen [here](https://web.archive.org/web/20220728174215/https://openai.com/dall-e-2/).

    Coding: Section 3.1 in Salesforce’s [‘A Conversational Paradigm for Program Synthesis‘](https://web.archive.org/web/20220404070940/http://arxiv.org/pdf/2203.13474.pdf) research paper about CodeGen, their AI tool turning human instructions into code, outlines that CodeGen achieves a 75% HumanEval score, meaning it can solve 75% of the programming challenges described with normal human language in the [HumanEval set](https://web.archive.org/web/20211011051701/https://paperswithcode.com/dataset/humaneval)
[^17]: It’s difficult to estimate the number of researchers focused on a certain topic since it’s hard to define the topic in the first place, many researchers work on multiple topics, and it’s hard to know the bar for ‘being a researcher’. So these numbers should be understood as estimates to within a factor of three or so, and they could be out by an order of magnitude depending on some interpretations of the question.

    In 2020, 87,000 authors published AI research on arXiv. The [2020 Global AI Talent Report](https://web.archive.org/web/20201101062242/https://jfgagne.ai/global-ai-talent-report-2020/#anchor-5) from Element AI estimates there are even more people than this working on AI development globally, with 155,000 people labelled on social media as working in AI research or engineering. However we expect some working in AI engineering to not be working on engineering new advancements in AI. We have taken the smaller estimate of 87,000 and roughly halved it for an estimate of 40,000.

    In 2021, [Gavin Leech](https://web.archive.org/web/20220728174413/https://forum.effectivealtruism.org/posts/8ErtxW7FRPGMtDqJy/the-academic-contribution-to-ai-safety-seems-large) estimated that 270 to 830 FTE people worked on AI Safety. However, the upper end of the range of this estimate is based on what we think is an overly broad notion of what constitutes research into AI alignment, and much of the sum was driven by adding up time from lots of researchers spending a small fraction of their time on safety research; while our aim is to quantify the number of researchers _focused_ on AI safety.

    [AI Watch](https://web.archive.org/web/20220728170925/https://aiwatch.issarice.com/) attempted a headcount of AI Safety researchers, which found 160 notable researchers who have worked on AI Safety. This includes many people who have not published on AI safety in over a year, whereas for the estimate of 87,000 above, all had published in the last year. On the other hand, the bar for being a ‘notable’ researcher might be higher than publishing in arXiv.

    Our final estimate is 300 researchers focused on AI safety
[^18]: In 2018, 9.56 billion farm animals were slaughtered for meat in the US. This number has likely risen since then. This includes 9.16 billion chickens; 237 million turkey; 125 million pigs; 34 million cattle and 2 million sheep. Source: visualization at [Our World in Data](https://ourworldindata.org/meat-production#number-of-animals-slaughtered), using data from the [UN Food and Agriculture Organization](https://web.archive.org/web/20220811152257/https://www.fao.org/faostat/en/)
[^19]: In 2021, approximately 6.5 million animals passed through animal shelters in the US. In 2011, this number was 7.2 million. Assuming a steady decline, this means in 2018 there were approximately 6.7 million animals passing through animal shelters.

    9.56 billion / 6.7 million = 1427 times as many animals in factory farms.

    [Pet Statistics](https://www.aspca.org/helping-people-pets/shelter-intake-and-surrender/pet-statistics). American Society for the Prevention of Cruelty to Animals, 2021. [Archived link](https://web.archive.org/web/20210805170626/https://www.aspca.org/helping-people-pets/shelter-intake-and-surrender/pet-statistics), accessed August 2021
[^20]: Animal shelter spending:

    Andrew Rowan calculated $5 billion of funding to the top 3000 animal shelter organizations in the US in 2018, published in his paper [“Cat Demographics & Impact on Wildlife in the USA, the UK, Australia and New Zealand: Facts and Values”](https://www.researchgate.net/publication/335325531_Cat_Demographics_Impact_on_Wildlife_in_the_USA_the_UK_Australia_and_New_Zealand_Facts_and_Values) Rowan et. al. (2020), Journal of Applied Animal Ethics Research, pages 7–37.

    Andrew Rowan confirmed the data behind these calculations in correspondence with us.

    Farm animal advocacy funding:

    Research from Open Philanthropy published [here](https://docs.google.com/spreadsheets/d/19vdy-QojtXXcgXVUIYqbCREpX7dnQqSRPTgcly8trXA/edit#gid=1364826426) finds the following funding for farm animal advocacy groups in 2018:

      * $32.3 million for Established US groups (PETA, PCRM, HSUS, ALDF, ASPCA)
      * $32.6 million for new, major US-based groups (CIWF, WAP, RSPCA, HSI)
      * $32.2 million for all other US groups



    32.3 + 32.6 + 32.2 = $97.1 millio
[^21]: $32.3 million for Established US groups (PETA, PCRM, HSUS, ALDF, ASPC
[^22]: $32.6 million for new, major US-based groups (CIWF, WAP, RSPCA, HS
[^23]: $32.2 million for all other US grou
[^24]: 106.5 million hens are now in cage-free housing in the US alone as of May 2022, as reported by the [USDA Egg Markets Overview](https://web.archive.org/web/20220728174554/https://www.ams.usda.gov/sites/default/files/media/Egg%20Markets%20Overview.pdf), compared to [17 million in 2016](https://web.archive.org/web/20160823231743/https://www.ams.usda.gov/sites/default/files/media/Egg%20Markets%20Overview.pdf). We believe another 100 million have become cage-free in Europe as a result of Open Wing Alliance’s work, although this number is harder to attribute to them specifically.

    In addition, advocates have now secured corporate pledges that, if implemented, should cover more than 500 million hens alive at any time
[^25]: After engagement with GFI, the US government announced a $10 million grant to create a center of excellence in cellular agriculture at Tufts University. The UK’s independent National Food Strategy recommended a £125 million investment in alternative protein research and innovation. Source: [GFI Year in Review 2021](https://web.archive.org/web/20220728174648/https://gfi.org/wp-content/uploads/2022/03/GFI_Year-in-Review_2021_v2.pdf) (page 3
[^26]: The full timeline of forecasts can be found on [Metaculus](https://web.archive.org/web/20220228132434/https://www.metaculus.com/questions/8898/russian-invasion-of-ukraine-before-2023/)
# Four Ideas You Already Agree With
This is a linkpost for [https://www.givingwhatwecan.org/blog/four-things-you-already-agree-with-effective-altruism](https://forum-bots.effectivealtruism.org/out?url=https%3A%2F%2Fwww.givingwhatwecan.org%2Fblog%2Ffour-things-you-already-agree-with-effective-altruism)

Here are four ideas that you probably already agree with. Three are about your values, and one is an observation about the world. Individually, they each might seem a bit trite or self-evident. But taken together, they have significant implications for how we think about doing good in the world.

![Women in Uganda holding bales of insecticide-treated bednets provided by the Against Malaria Foundation, one of Giving What We Can's Top Charities.](https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/wYjMsKsEkDPgHeAbS/nbbvuynsnhzvyu7shir9)Women in Uganda holding bales of insecticide-treated bednets provided by the [Against Malaria Foundation](https://www.givingwhatwecan.org/charities/against-malaria-foundation), one of Giving What We Can's [Top Charities](https://www.givingwhatwecan.org/best-charities-to-donate-to-2022).

The four ideas are as follows:

  1.  **It's important to help others** — when people are in need and we can help them, we think that we should. Sometimes we think it might even be morally required: most people think that millionaires should give something back. But it may surprise you to learn that those of us on or above the median wage in a rich country are [typically part of the global 5%](https://www.givingwhatwecan.org/get-involved/how-rich-am-i)[^27] — maybe we can also afford to give back too.
  2.  **People** [^28] **are equal** — everyone has an equal claim to being happy, healthy, fulfilled and [free](http://www.dictionaryofobscuresorrows.com/post/23536922667/sonder), whatever their circumstances. All people matter, wherever they live, however rich they are, and whatever their ethnicity, age, gender, ability, religious views, etc.
  3.  **Helping more is better than helping less** — all else being equal, we should save more lives, help people live longer, and make more people happier. Imagine twenty sick people lining a hospital ward, who’ll die if you don’t give them medicine. You have enough medicine for everyone, and no reason to hold onto it for later: would anyone really choose to arbitrarily save only _some_ of the people if it was just as easy to save _all_ of them?
  4.  **Our resources are limited** — even millionaires have a finite amount of money they can spend. This is also true of our time — there are never enough hours in the day. Choosing to spend money or time on one option is an implicit choice [not to spend it on other options](https://en.wikipedia.org/wiki/Opportunity_cost) (whether we think about these options or not).



I think that these four ideas are all pretty uncontroversial. I think it seems pretty intuitive that we should help people in need if we can; that we shouldn’t arbitrarily preference some groups of people over others; that we would prefer to help more people if given the option; and that we don’t have infinite time and money.

In fact I’d go further — I’d say that we’d feel pretty uncomfortable trying to [defend the alternative positions](https://en.wikipedia.org/wiki/Reversal_test) if we were talking to someone, namely:

  1. Helping others in need isn’t morally required, important, or even that good
  2. It’s OK to value people differently based on arbitrary differences like race, gender, ability etc.
  3. It doesn’t matter if some people die even if it doesn’t really cost us anything extra to save their lives
  4. We have unlimited resources



See what I mean?

We don't have infinite money, so we always need to choose which worthy cause to support.

![](https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/wYjMsKsEkDPgHeAbS/g1aoagy0u623kdyfasxk)

So if we agree that these four ideas embody important values — and I think that they do — then there are big implications for how we should think about doing good. In fact, it means that the way we typically think about doing good is wrong.

In order to be true to these values, we need to think about how we can help the most people with our limited resources.

This is important, because there are [some causes](https://www.givingwhatwecan.org/cause-areas) where we can make a big impact for a small amount of money. In fact the best options are [much, much better than the average](https://80000hours.org/articles/effective-or-not/) — sometimes hundreds of times better. That might mean the difference between helping one person, and helping hundreds of people _for exactly the same amount of time or money_.

Because a charity chosen at random _is almost certainly not making as big an impact as the_[ _most effective charities_](https://www.givingwhatwecan.org/best-charities-to-donate-to-2022) (and let’s face it, many causes we choose to support tend to be the result of either random chance, or systemic factors that mean we’re only exposed to certain causes).

And this matters, because if we don’t choose well, then we’re either not giving people equal consideration (that is, implicitly discriminating against some groups of people), or we’re not helping as many people as we can (that is, allowing extra people to suffer or die, even though we could potentially help them).

So, at first, every worthy cause — from cancer research, to climate justice, to animal sanctuaries, to preventing [easily treatable but unpronounceable](https://www.givingwhatwecan.org/charities/unlimit-health) diseases in places that we'll probably never visit — should be on the table... _except_ that we also think it's better to help more people and we understand that we don’t have the resources to help everyone. So we should first focus on the causes where we can help the most people for our limited time and money, **not just on those that we happen to have already heard about**.

Trying to be cause-neutral can be a really hard thing to do. Most people have first-hand experience of loss: I’ve lost two relatives to leukaemia; watched as the disease consumed their bodies and the pain meds fogged their minds; lived through the shared grief of their passing. It’s entirely reasonable that this makes us want to donate to organisations trying to solve the specific problem or cure the particular disease that has robbed us of our loved ones. We’re empathetic creatures, and we don’t want other people to experience the same suffering, or for their loved ones to experience the same grief.

But if we care about treating _people_ equally, we should also care about treating their experiences equally. There’s not a really good reason that I should prefer averting the death, disability, and suffering caused by a particular disease (like leukaemia) any more than I should care about suffering caused by malaria, tuberculosis, traffic accidents, or anything else. What matters is that lives are cut short, parents are deprived of their children, people are living in pain. Caring about equality means treating _all_ death and suffering as a tragedy, not just that caused by specific diseases that we — by cruel twists of fate that thrust them into our field of view — happen to notice.

Making these decisions is really, really hard. But there is a set of thinking tools we can use to help us. This way of thinking is called [effective altruism](http://www.ethics.org.au/on-ethics/blog/january-2016/effective-altruism). It's basically the same as regular altruism (in that it emphasises the importance of helping other people) — the word 'effective' just means trying to think clearly about how your actions can help the _most people_ , or do the _most good_.

I see effective altruism as a way of being able to better live up to **values that we already hold**.

This way of thinking is applicable to any way that we might want to do good — whether that be agitating for political change, choosing where we donate our money, or how to have a big impact with our careers.

In a world where there are so many worthy causes we could work on, it gives us a way out of decision paralysis, by systematically looking for ways to do the most good with our limited time and money.

It asks us to face up to some hard choices. But remember, we’re making these choices anyway, whether we think about them or not. So even though it might be hard to not donate to something that seems really important — whether for personal reasons, or because you’re convinced by a charity’s marketing pitch — remember that you’re always trading off against other worthy causes.

Here’s an example of this in action. The typical person in the UK donates around £6,700 ($9,600USD)[^29] over the course of their working lifetimes. For this money we could fund the distribution of [around 1,900 mosquito nets](https://www.givingwhatwecan.org/charities/against-malaria-foundation)[^30] (likely preventing around 200children from becoming really, really sick from malaria[^31], and probably [saving at least two or three](https://www.givingwhatwecan.org/blog/bednets-have-prevented-450-million-cases-of-malaria) [_lives_](https://www.givingwhatwecan.org/blog/bednets-have-prevented-450-million-cases-of-malaria)). However, most voluntary donations go to domestic medical charities.[^32] The UK’s National Health Service considers it good value to save one _year_ of healthy life for around £25,000. [^33]It’s highly unlikely that a domestic charity will beat this figure, so the typical donor’s impact is going to be many, many times less than it could otherwise be. Remember, **just because we don’t think about these choices, doesn’t mean that they’re not there.**

So please, think carefully about these ideas — the importance of altruism, equality, and doing as much as we can with our scarce resources — and see if they make sense to you.

If they do, then the next time you think about how to make the world a better place, give voice to these values by thinking _effectively_ , as well as altruistically.

 **Some resources for learning more about effective altruism:**

  * [What is Effective Altruism?](https://www.givingwhatwecan.org/what-is-effective-altruism)
  * This really quick [summary of effective altruism](http://web.archive.org/web/20171111054827/http:/www.ethics.org.au/on-ethics/blog/january-2016/effective-altruism)
  * The [Wikipedia entry on effective altruism](https://en.wikipedia.org/wiki/Effective_altruism)
  * [Doing Good Better](http://www.effectivealtruism.com/) by Will MacAskill
  * The [Effective Altruism Handbook](http://effective-altruism.com/ea/hx/effective_altruism_handbook_now_online/)



 **Some actions you can take that we think are really effective**

  * [Donate](https://www.givingwhatwecan.org/best-charities-to-donate-to-2022) to a charity recommended on the basis of its impact and cost-effectiveness — check out our [Top Charities](https://www.givingwhatwecan.org/best-charities-to-donate-to-2022), and [GiveWell’s recommendations](http://www.givewell.org/charities/top-charities). If you’d like to support charities that increase the welfare of non-human animals effectively, check out [Animal Charity Evaluators](http://www.animalcharityevaluators.org/).
  * [Pledge](https://www.givingwhatwecan.org/pledge) to keep donating over the course of your lifetime — 8,438 people (and counting) have pledged to donate 10% of their lifetime income to the most effective charities, and 798 have made pledges of 1% or more of their income for a custom period.
  * Choose a career that’s really high-impact by reading career advice from [80,000 Hours](https://80000hours.org/)
  * Start a [chapter or discussion group](https://www.givingwhatwecan.org/get-involved/groups) in your local area or at your university, and get other people interested in making a bigger difference



_This work is licensed under a_[ _Creative Commons Attribution 4.0 International License_](https://creativecommons.org/licenses/by/4.0/) _._
[^27]: The number I’ve pre-loaded into the calculator ($32,140USD) is the [median personal income](https://en.wikipedia.org/wiki/Personal_income_in_the_United_States) for someone 25 or older in the US, but of course you should substitute in your own income, country, and household details. Some other generic values you could use for comparison are [$24,062USD](https://www.givingwhatwecan.org/blog/four-things-you-already-agree-with-effective-altruism#) ([median personal income](https://en.wikipedia.org/wiki/Personal_income_in_the_United_States) for people in the US over 18), [£21,100GBP](https://www.givingwhatwecan.org/blog/four-things-you-already-agree-with-effective-altruism#) ([median personal income](http://www.theguardian.com/money/2014/mar/25/uk-incomes-how-salary-compare) of the sixth decile in the UK), or [$59,900AUD](https://www.givingwhatwecan.org/blog/four-things-you-already-agree-with-effective-altruism#) ([median salary of full-time workers](http://www.abs.gov.au/ausstats/abs@.nsf/mf/6310.0) in Australia
[^28]: I’ve used the word ‘people’ in this article for convenience, but of course if you’re concerned with the welfare of non-human animals, then you could read this as ‘animals’ or ‘sentient beings’ etc. — the arguments all still app
[^29]: Charities Aid Foundation, _UK Giving 2014_ , p12 <<https://www.cafonline.org/docs/default-source/about-us-publications/caf-ukgiving2014>>. Arrived at by multiplying the typical amount donated each month (£14) by 12 (to get yearly donations) and then by 40 (number of years someone is typically active in the workforc
[^30]: This is using the figure of around $5 per bednet distributed by the Against Malaria Foundation, which is correct for most places in which they operate. Some countries (such as DRC) are more expensive to work in, but even at the higher figure of $7.50 per net, you could still distribute 1,000 bednet
[^31]: White, MT. "Costs and cost-effectiveness of malaria control interventions ..." 2011. <https://malariajournal.biomedcentral.com/articles/10.1186/1475-2875-10-33
[^32]: Charities Aid Foundation, _UK Giving 2014_ , p14 [_https://www.cafonline.org/docs/default-source/about-us-publications/caf-ukgiving2014_](https://www.cafonline.org/docs/default-source/about-us-publications/caf-ukgiving201
[^33]: <https://www.nice.org.uk/news/blog/carrying-nice-over-the-threshol
# The world is much better. The world is awful. The world can be much better.
(Cross-posted from [Our World in Data](https://ourworldindata.org/much-better-awful-can-be-better).)

The world is much better. The world is awful. The world can be much better. All three statements are true.

Here I focus on child mortality, but the same can be said for many aspects of global development. There are many aspects of development for which it is true that things have improved over time and are terrible still, and for which we know that things can get better.

## The world is awful

In the visualization below, I present three scenarios of child deaths. The blue bar represents the actual number of child deaths per year today. Of the [141 million children born](https://ourworldindata.org/grapher/the-annual-number-of-births-and-deaths-including-the-un-projections-until-2100) every year, 3.9% die before their 5th birthday. This means that every year, 5.5 million children die; on average, 15,000 children die every day. [^34]

Clearly, a world where such tragedy happens is an awful world.

## The world is much better

The big lesson of history is that things change. The scale of these changes is hard to grasp. The living conditions in today's poorest countries are now in many ways much better than they were even in the richest countries of the past: Child mortality in today's worst-off places is[ between 10-13%](https://ourworldindata.org/grapher/child-mortality-1990-vs-2017-slope); in all regions of the world it was more than three times as high [[30-50%](https://ourworldindata.org/child-mortality#estimates-for-child-mortality-over-the-last-two-centuries)] until a few generations ago. It's estimated that at the beginning of the 19th century, 43% of the world's children died by the age of five. If we still suffered the poor health of our ancestors, more than 60 million children would die every year — 166,000 every day. [^35]

This is what the red bar represents in the visualization below.

If you want to see how child mortality has changed, read Hannah Ritchie's post: [From commonplace to rarer tragedy — declining child mortality across the world](https://ourworldindata.org/child-mortality-global-overview)

Such large improvements are not limited to health; the same is true across other aspects of life (as I show in[ my short history of living conditions](https://ourworldindata.org/a-history-of-global-living-conditions-in-5-charts)). In a number of fundamental aspects (obviously[ not all](https://ourworldindata.org/obesity)), we have achieved very substantial progress and know that much more is possible. These aspects also include[ education](https://ourworldindata.org/global-rise-of-education),[ political freedom](https://ourworldindata.org/democracy),[ violence](https://ourworldindata.org/homicides),[ poverty](https://ourworldindata.org/extreme-poverty), [nutrition](https://ourworldindata.org/hunger-and-undernourishment), and [some](https://ourworldindata.org/ozone-layer) [aspects](https://ourworldindata.org/natural-catastrophes) of environmental change.

What we learn from this is that it is possible to change the world. I believe that one of the most important facts to know about our world is that we can make a difference.

![](http://res.cloudinary.com/cea/image/upload/v1667994756/mirroredImages/6dsrwxHtCgYfJNptp/aumtxkj5cvluiuuj96ym.png)

(You can see a larger version of this graph [here](https://i.ibb.co/ygc2Q9g/Our-World-in-Data-graph.png).)

## The world can be much better

Progress over time shows that it was possible to change the world in the past. But what do we know about what is possible for the future? Were we born at an unlucky time in modern history, in which global progress has come to a halt?

Studying the global data suggests that the answer is no. One way to see this is to look at those places in the world with the best living conditions. The[ inequality](https://ourworldindata.org/grapher/child-mortality-1990-vs-2017-slope) in living conditions in the world today shows that there is much work left to do. If health across all countries of the world was equal, it would not be possible to really know whether further improvements are possible or how to achieve them. But the fact that some places have already achieved much better child health leaves no doubt: Better child health than the global average is not just a possibility, but already a reality.

So what would global child mortality be if children around the world became as well off as the children in those places where children are healthiest today?

The dark green bar in the visualization shows the answer. The region with the lowest child mortality is the European Union. The average in the European Union (0.41%) is 10 times lower than the global average (3.9%).

In the EU, 1 in 250 children die, whilst globally the figure is 1 in 25. If children around the world were as well off as children in the EU, 5 million fewer children would die every year.

Of course, a child mortality rate of 1 in 250 is still too high. It will be a major achievement if the world as a whole catches up to that level of health, but in the healthiest places we should also try to push the boundaries of what has been shown to be possible.

We should certainly not make the mistake of believing that it would be easy to reduce the global child mortality rate to that of the EU. For a society to achieve such good health, many development aspects have to improve; today's best-off countries achieved two centuries of slow, sustained [economic growth](https://ourworldindata.org/economic-growth) that bought the infrastructure (housing,[ sanitation](https://ourworldindata.org/water-access-resources-sanitation), public health measures) necessary for good health.

But while a better world cannot be achieved overnight, we learn what is possible from the best-off regions; in this sense, we know that these 5 million annual deaths are preventable. The fact that child mortality in entire world regions is tenfold lower than in the world as a whole shows us that it is possible to make the world a better place.

## The world is terrible; this is why we need to know about positive change

It's easier to scare people than to instill confidence in them, and many writers on global development report on how awful the world is. I agree that it is important that we know what is wrong with the world, but given the scale of what we have achieved already and what is possible for the future, I think it's irresponsible to only report on how dreadful our situation is.

The world is much better. The world is awful. The world can be much better. We have to study the data to know all three perspectives on global living conditions. When we do this, these facts are impossible to miss. But the facts of how the world is changing [are not known to most of us](https://ourworldindata.org/wrong-about-the-world) because many of the writers that report on how the world is changing do not take the data seriously. This needs to change.

What we have to achieve as writers on global change is to convey both perspectives at the same time: We need to know how terrible the world still is and that a better world is possible. This is what I hope to do.

If we had achieved the best of all possible worlds, I wouldn't spend my life writing and researching about how we got here. What keeps me going is to share the knowledge that change is possible — though not inevitable — and the wealth of knowledge that researchers around the world have acquired on how to make a better world for everyone.

We know that it is possible to make the world a better place because we already did it. It is because the world is terrible still that it's so important to write about how, in several important aspects, the world became a better place.

_This work is licensed under a[Creative Commons Attribution 4.0 International License.](https://creativecommons.org/licenses/by/4.0/)_

* * *
[^34]: Child deaths in 2017: 140.95 * (3.9/100)=5,497,050. This means 5,497,050/365.25=15,050 child deaths per day. Here I'm assuming that the cohorts of children younger than 5 are all equally large. As the [number of births per year is not rising much anymore](https://ourworldindata.org/grapher/the-annual-number-of-births-and-deaths-including-the-un-projections-until-2100), this seems like a justified approximation that makes the calculation straightforward.
[^35]: We don't know how many children actually died at the time because I don't have estimates of the number of births globally for that period. We have estimates of both the number of births and the mortality rate for the 1950s and 1960s, and the records show that around 20 million children died every year. See the data shown [here](https://www.gatesnotes.com/Development/Max-Roser-three-facts-everyone-should-know).
# On Caring
_This version of the essay has been lightly edited. You can find the original_[ _ _here__](https://web.archive.org/web/20200108195437/http://mindingourway.com/on-caring/) _._

## 1

I'm not very good at _feeling_ the size of large numbers. Once you start tossing around numbers larger than 1,000 (or maybe even 100), the numbers just seem "big".

Consider Sirius, the brightest star in the night sky. If you told me that Sirius is as big as a million Earths, I would feel like that's a lot of Earths. If, instead, you told me that you could fit a _billion_ Earths inside Sirius … I would still just feel like that's a lot of Earths.

The feelings are almost identical. _In context_ , my brain grudgingly admits that a billion is a lot larger than a million, and puts forth a token effort to feel like a one-billion-Earths-sized star is bigger than a one-million-Earths-sized star. But out of context — if I weren’t anchored at "a million" when I heard "a billion" — both of these numbers just feel vaguely large.

I feel a _little_ respect for the bigness of numbers if you pick really, really large numbers. If you say, "One followed by 100 zeroes," then this feels _a lot_ bigger than a billion. But it certainly doesn't feel (in my gut) like it's 10 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 times bigger than a billion. Not in the way that four apples _internally feels_ like twice as many as two apples. My brain can't even begin to wrap itself around this sort of magnitude differential.

This phenomenon is related to [scope insensitivity](http://lesswrong.com/lw/hw/scope_insensitivity/), and it's important to me because I live in a world where sometimes the things I care about are really, really numerous.

For example, [billions of people live in dire poverty](https://www.worldbank.org/en/topic/poverty/overview), with hundreds of millions of them deprived of basic needs and/or dying from disease. And though most of them are out of my sight, I still care about them.

The loss of a human life with all its joys and all its sorrows is tragic no matter what the cause, and the tragedy is not reduced simply because I was far away, or because I did not know of it, or because I did not know how to help, or because I was not personally responsible.

Knowing this, I care about every single individual on this planet. The problem is, my brain is _simply incapable_ of taking the amount of caring I feel for a single person and scaling it up by a billion times. I lack the internal capacity to feel that much. My care-o-meter simply doesn't go up that far.

And this is a problem.

## 2

It's a common trope that courage isn't about being fearless; it's about being afraid but _doing the right thing anyway_. In the same sense, caring about the world isn't about having a gut feeling that corresponds to the amount of suffering in the world; it's about _doing the right thing anyway_. Even without the feeling.

My internal care-o-meter was calibrated to deal with [about 150 people](http://en.wikipedia.org/wiki/Dunbar's_number), and it _simply can't express_ the amount of caring that I have for billions of sufferers. The internal care-o-meter just doesn't go up that high.

Humanity is playing for unimaginably high stakes. At the very least, there are billions of people suffering today. At the worst, there are quadrillions (or more) potential humans, transhumans, or posthumans whose existence depends upon what we do here and now. All the intricate civilizations that the future could hold, the experience and art and beauty that is possible in the future, depends upon the present.

When you're faced with stakes like these, your internal caring heuristics — calibrated on numbers like 10 or 20, and [maxing out around ](http://en.wikipedia.org/wiki/Dunbar's_number)150 — completely fail to grasp the gravity of the situation.

Saving a person's life feels _great_ , and [it would probably feel just about as good to save one life as it would feel to save the world](http://lesswrong.com/lw/hx/one_life_against_the_world/). It surely wouldn't be _many billion times_ more of a high to save the world, because your hardware can't express a feeling a billion times bigger than the feeling of saving a person's life. But even though the altruistic high from saving someone's life would be shockingly similar to the altruistic high from saving the world, always remember that _behind_ those similar feelings there is a whole world of difference.

Our internal care-feelings are woefully inadequate for deciding how to act in a world with big problems.

## 3

There's a mental shift that happened to me when I first started internalizing scope insensitivity. It is a little difficult to articulate, so I'm going to start with a few stories.

Consider Alice, a software engineer at Amazon in Seattle. Once a month or so, college students show up on street corners with clipboards, looking ever more disillusioned as they struggle to convince people to donate to [Doctors Without Borders](http://www.doctorswithoutborders.org/). Usually, Alice avoids eye contact and goes about her day, but this month they finally manage to corner her. They explain Doctors Without Borders, and she actually has to admit that it sounds like a pretty good cause. She ends up handing them $20 through a combination of guilt, social pressure, and altruism, and then rushes back to work. (Next month, when they show up again, she avoids eye contact.)

Now consider Bob, who has been given the [Ice Bucket Challenge](http://en.wikipedia.org/wiki/Ice_Bucket_Challenge) by a friend on Facebook. He feels too busy to do the challenge, and instead just donates $100 to [ALSA](http://www.alsa.org/).

Now consider Christine, who is in the college sorority ΑΔΠ. ΑΔΠ is engaged in a competition with ΠΒΦ (another sorority) to see who can raise the most money for the National Breast Cancer Foundation in a week. Christine has a competitive spirit and gets engaged in fundraising, and gives a few hundred dollars herself over the course of the week (especially at times when ΑΔΠ is especially behind).

All three of these people are donating money to charitable organizations, and that's great. But notice that there's something similar in these three stories: These donations are largely motivated by a _social context_. Alice feels obligation and social pressure. Bob feels social pressure and maybe a bit of camaraderie. Christine feels camaraderie and competitiveness. These are all fine motivations, but notice that these motivations are related to the _social setting_ , and only tangentially to the _content_ of the charitable donation.

If you took Alice or Bob or Christine aside and asked them why they aren't donating _all_ of their time and money to these causes that they apparently believe are worthwhile, they'd look at you funny and they'd probably think you were being rude (with good reason!). If you pressed, they might tell you that money is a little tight right now, or that they would donate more if they were a better person.

But the question would still feel kind of _wrong_. Giving all of your money away is just not what you do with money. We can all _say out loud_ that people who give all of their possessions away are really great, but behind closed doors we all know that those people are crazy. (Good crazy, perhaps, but crazy all the same.)

This is a mindset that I inhabited for a while. But there's an alternative mindset that can hit you like a freight train when you start internalizing scope insensitivity.

## 4

Consider Daniel, a college student. Shortly after the [Deepwater Horizon](http://en.wikipedia.org/wiki/Deepwater_Horizon_oil_spill) BP oil spill, he encounters one of those people with the clipboards on the street corners, soliciting donations to the [World Wildlife Foundation](http://www.worldwildlife.org/). They're trying to save as many oiled birds as possible. Normally, Daniel would simply dismiss the charity as Not The Most Important Thing, or Not Worth His Time Right Now, or Somebody Else's Problem, but this time Daniel has been thinking about how his brain is bad at numbers and decides to do a quick sanity check.

He pictures himself walking along the beach after the oil spill and encountering a group of people cleaning birds as fast as they can. They simply don't have the resources to clean all of the available birds. A pathetic young bird flops toward his feet, slick with oil, eyes barely able to open. He kneels down to pick it up and help it onto the table. One of the bird-cleaners informs him that they won't have time to get to that bird themselves, but he could pull on some gloves and could probably save the bird with three minutes of washing.

![](http://res.cloudinary.com/cea/image/upload/v1667995740/mirroredImages/hkimyETEo76hJ6NpW/yzv0psp0mbvcfcsdz2vd.jpg)

Daniel decides that he _would_ spend three minutes of his time to save the bird, and that he would _also_ be happy to pay at least $3 to have someone else spend a few minutes cleaning the bird. He introspects and finds that this is not just because he imagined a bird right in front of him: He feels that it is _worth_ at least three minutes of his time (or $3) to save an oiled bird in some vague, platonic sense.

And, because he's been thinking about scope insensitivity, he _expects_ his brain to misreport how much he actually cares about large numbers of birds; the internal feeling of caring can't be expected to line up with the actual importance of the situation. So instead of just _asking his gut_ how much he cares about de-oiling lots of birds, he shuts up and multiplies.

[Thousands and thousands](http://dailydeadbirds.com/) of birds were oiled by the BP spill alone. After shutting up and multiplying, Daniel realizes (with growing horror) that the amount he _actually_ cares about oiled birds is lower-bounded by two months of hard work and/or fifty thousand dollars. And that's not even counting wildlife threatened by [other oil spills](http://en.wikipedia.org/wiki/List_of_oil_spills).

And if he cares that much about _de-oiling birds_ , then how much does he actually care about factory farming, nevermind hunger, or poverty, or sickness? How much does he actually care about wars that ravage nations? About neglected, deprived children? About the future of humanity? He _actually_ cares about these things to the tune of much more money than he has, and much more time than he has.

For the first time, Daniel sees a glimpse of how much he actually cares, and how poor a state the world is in.

This has the strange effect that Daniel's reasoning goes full-circle, and he realizes that he actually _can't_ care about oiled birds to the tune of 3 minutes or $3 — not because the birds aren't _worth_ the time and money (in fact, he thinks that the economy produces things priced at $3 which are worth less than a bird's survival), but because he can't spend _his_ time or money on saving the birds. The opportunity cost suddenly seems far too high: There is _too much else to do!_ People are sick and starving and dying! The very future of our civilization is at stake!

Daniel doesn't wind up giving $50,000 to the World Wildlife Fund, and he also doesn't donate to the ALS Association or the National Breast Cancer Foundation. But if you ask _Daniel_ why he's not donating all his money, he won't look at you funny or think you're rude. He's left the place where you don't care far behind, and has realized that _his mind was lying to him the whole time_ about the gravity of the real problems.

Now he realizes that he _can't possibly do enough_. After adjusting for his scope insensitivity (and the fact that his brain lies about the size of large numbers), even the "less important" causes like the WWF suddenly seem worthy of dedicating a life to. Wildlife destruction and ALS and breast cancer are suddenly all problems that he would _move mountains_ to solve — except he's finally understood that there are just too many mountains, and ALS isn't the bottleneck, and AHHH HOW DID ALL THESE MOUNTAINS GET HERE?

In the original mindstate, the reason he didn't drop everything to work on ALS was because it just didn't seem … pressing enough. Or tractable enough. Or important enough. Kind of. These are sort of the reason, but the real reason is more that the concept of "dropping everything to address ALS" never even _crossed his mind_ as a real possibility. The idea was too much of a break from the standard narrative. It wasn't his problem.

In the new mindstate, _everything_ is his problem. The only reason he's not dropping everything to work on ALS is because there are far too many things to do first.

Alice and Bob and Christine usually aren't spending time solving all the world's problems because they forget to see them. If you remind them — put them in a social context where they remember how much they care (hopefully without guilt or pressure) — then they'll likely donate a little money.

By contrast, Daniel and others who have undergone the mental shift aren't spending time solving all the world's problems because there are _just too many problems_. (Daniel hopefully goes on to discover movements like effective altruism and starts contributing toward fixing the world's most pressing problems.)

## 5

I'm not trying to preach here about how to be a good person. You don't need to share my viewpoint to be a good person (obviously).

Rather, I'm trying to point at a shift in perspective. Many of us go through life understanding that we _should_ care about people suffering far away from us, but failing to. I think that this attitude is tied, at least in part, to the fact that most of us implicitly trust our internal care-o-meters.

The "care feeling" isn't usually strong enough to compel us to frantically save everyone dying. So while we acknowledge that it would be _virtuous_ to do more for the world, we think that we _can't_ , because we weren't gifted with that virtuous extra-caring that prominent altruists must have.

But this is an error — prominent altruists aren't the people who have a larger care-o-meter; they're the people who have _learned not to trust their care-o-meters_.

Our care-o-meters are broken. They don't work on large numbers. Nobody has one capable of faithfully representing the scope of the world's problems. But the fact that you can't _feel_ the caring doesn't mean that you can't _do_ the caring.

You don't get to feel the appropriate amount of "care" in your body. Sorry — the world's problems are just too large, and your body is not built to respond appropriately to problems of this magnitude. But if you choose to do so, you can still _act_ like the world's problems are as big as they are. You can stop trusting internal feelings to guide your actions and switch over to manual control.

## 6

This, of course, leads us to the question of "What the hell do you do, then?"

And I don't really know yet. (Though I'll plug the [Giving What We Can pledge](http://givingwhatwecan.org/), [GiveWell](http://givewell.org/), [MIRI](http://intelligence.org/), and [The Future of Humanity Institute](http://www.fhi.ox.ac.uk/) as a good start.)

I think that at least part of it comes from a certain sort of desperate perspective. It's not enough to think you _should_ change the world — you also need the sort of desperation that comes from realizing that you would dedicate your entire life to solving the world's 100th biggest problem if you could, but you can't, because there are 99 bigger problems you have to address first.

I'm not trying to guilt you into giving more money away — becoming a philanthropist is _really, really hard_. (If you're _already_ a philanthropist, then you have my respect and my affection.) First it requires you to have money, which is uncommon, and then it requires you to _throw that money at distant, invisible problems_ , which is not an easy sell to a human brain. [Akrasia](http://en.wikipedia.org/wiki/Akrasia) is a formidable enemy. And more importantly, guilt doesn't seem like a good long-term motivator: If you want to join the ranks of people saving the world, I would rather you join them proudly. There are many trials and tribulations ahead, and we'd do better to face them with our heads held high.

## 7

Courage isn't about being fearless; it's about being able to do the right thing even if you're afraid.

And similarly, addressing the major problems of our time isn't about feeling a strong compulsion to do so. It's about trying to address them even when internal compulsion utterly fails to capture the scope of the problems we face.

It's easy to look at especially virtuous people — Gandhi, Mother Teresa, Nelson Mandela — and conclude that they must have cared more than we do. But I don't think that's the case.

Nobody gets to comprehend the scope of these problems. The closest we can get is doing the multiplication: finding something we care about, putting a number on it, and multiplying. And then trusting the numbers more than we trust our feelings.

Because our feelings lie to us.

When you do the multiplication, you realize that addressing global poverty and building a brighter future deserve more resources than currently exist. There is not enough money, time, or effort in the world to do what we need to do.

There is only you, and me, and everyone else who is trying anyway.

## 8

You can't actually feel the weight of the world. The human mind is not capable of that feat.

But sometimes, you can catch a glimpse.

_This work is licensed under a_[ _Creative Commons Attribution 4.0 International License_](https://creativecommons.org/licenses/by/4.0/) _._

# Scope insensitivity: failing to appreciate the numbers of those who need our help
This is a linkpost for [https://www.animal-ethics.org/scope-insensitivity-failing-to-appreciate-the-numbers-of-those-who-need-our-help/](https://forum-bots.effectivealtruism.org/out?url=https%3A%2F%2Fwww.animal-ethics.org%2Fscope-insensitivity-failing-to-appreciate-the-numbers-of-those-who-need-our-help%2F)

Consider one billion animals. Now consider one _trillion_ animals. The second number is vastly higher. However, it is difficult for many people to have a clear idea of what the magnitude of that difference is. As a result of this, we often fail to assess properly what we should do when large numbers of individuals are affected.

This is due to a cognitive bias called _scope insensitivity_. It is also known as _scope neglect_. It means we don’t realize the real scope of a certain quantity. So when we compare two different quantities we fail to notice the difference between them. This usually happens when those quantities are very large.

Scope insensitivity causes people not to adjust their valuation of an issue in proportion to the size or scale of it.[^36] Scope insensitivity especially impairs our judgments about helping animals because of the massive amount of animal suffering and death.

Scope insensitivity probably occurs due to our inability to visualize, or otherwise imagine, such large numbers. When we are not able to visualize a situation where a large number of individuals need our help, we must instead understand it at a more abstract quantitative level. This rarely triggers a strong emotional reaction in us, such as we get when we help a particular number of individuals we can visualize. Importantly from an ethical standpoint, it has been argued that too little emotional involvement can lead to a failure to react.[^37] Because of that, scope insensitivity may contribute to non-optimal decision outcomes in situations where the goal is to improve the situation of as many individuals as possible.[^38] In fact, sometimes those decisions are very poor ones.

## An example: how much would you be willing to pay to save a certain number of animals?

In the original study that assessed this phenomenon, different groups of people were asked how much they would pay to save either a group of 2,000 birds, another of 20,000 birds, or a group of 200,000 birds from drowning in ponds polluted with oil. Assuming people’s intention was truly to help as many birds as possible, they should value each of their lives equally. If they were looking clearly at the issue, we would expect them to be willing to pay 10 times as much for the second group as for the first group, and 100 times as much for the third group as for the first group. In fact, the results showed that willingness to pay did not increase in proportion with the number of birds saved.[^39] Participants were willing to pay $80 to save 2,000 birds. They were willing to pay $78 to save 20,000. That is, 2$ less to save 18,000 _more_ individuals. Finally, they were willing to pay $88 to save 200,000. Thus, only 8$ extra to help 180,000 more birds. That suggests that participants valued each individual bird less the more of them there were to save (4, 0.39, and 0.044 cents, respectively).

This is a clear case of scope insensitivity. The fact that participants were only willing to pay $80 to save a group of 2,000 birds is very problematic in its own right. Yet, the scope insensitivity they showed is also worrisome, given how it impairs our moral judgment when confronted when very large numbers of individuals in need of our help.

## A psychological explanation of the scope insensitivity bias

One explanation of how scope insensitivity occurs has to do with how we often represent things in order to understand them, which is called _representativeness heuristic_ (heuristics, often referred to as “mental shortcuts,” are ways to easily solve problems, especially when we have to make a decision). The representativeness heuristic describes people’s tendency to imagine a simple, normal example of the type of problem being presented to them, rather than picturing all the specific details of the case in question, which may be very complex. Like all heuristics, this can be a useful mental shortcut, since it reduces problems to a more manageable size, thereby simplifying our information processing and decision-making efforts.

However, as the example above shows, this mechanism can be inappropriate to use in many situations. In the example, people tended to imagine or visualize roughly the same thing, so their natural empathy was stimulated to roughly the same degree by all of them, despite the significant differences in the three numbers.[^40]

If a person’s aim is to feel good, or to avoid feeling bad, through some altruistic behavior (like a charitable donation), they do not have an incentive to check whether they are actually doing some good or just seeming to do so – because it feels the same in each case and that is their bottom line.[^41] In addition, being confronted with too much suffering can lead to what is often called the _collapse of compassion_ , a defense mechanism that reduces or eliminates our sensitivity to the harms others suffer when we are faced with massive amounts of suffering.[^42] As a result, people will tend not to do the cognitive work of adjusting for scope neglect.

That being said, part of the problem may consist in people simply failing to notice their bias, meaning that they would adjust their decisions if only they were informed about its existence.[^43]

In addition, due to the key role of emotions in moral intuitions and in decision-making processes,[^44] it has been shown that raising emotional concern for individual victims of large-scale suffering increases overall concern. It has also been shown that personal stories and visual images motivate helping responses more than using abstract numerical figures and statistics. These vivid descriptions of single individuals in need can be useful to keep emotions aroused when large numbers of individuals are concerned.[^45] This is a way of trying to adjust advocacy to the existence of cognitive biases. It is problematic, however, as we are not always going to be able to do this. For instance, we may not be able to provide such stories when we consider possible new forms of suffering in the future.

## Scope insensitivity and our failure to help animals in the wild in need of aid

Scope insensitivity is especially problematic when it biases us away from helping animals in the wild. There is an astronomical amount of suffering constantly going on in the natural world. For example, the leading estimate as to the number of insects in the wild is 1018.[^46] A majority of these animals die a painful death in their first days of life. This amount of suffering simply dwarfs any that we are used to dealing with or thinking about.

In order to react properly to these magnitudes, we should be prepared to adjust our initial emotional reaction based on our more abstract understanding of the quantity. For example, we can try to imagine the largest number of insects that we can and then try to remember how much bigger of an issue it is than we can possibly imagine.

## Giving everyone equal consideration

The equivalent suffering of each individual should be given the same consideration. Unfortunately, however, the valuations of individual lives and suffering are often guided by moral intuitions which are highly influenced by non-rational mechanisms and emotions that can lead to partial judgments. As we have seen here, one of these mechanisms is scope insensitivity.

Hence, we cannot rely solely on our more immediate decision-making processes when making moral judgments involving large numbers of individuals. We must bear this in mind and try to adjust for the errors our decision-making process will run into because of this bias.

* * *

##  **Further readings**

Baron, J. & Greene, J. (1996) “Determinants of insensitivity to quantity in valuation of public goods: Contribution, warm glow, budget constraints, availability, and prominence”, _Journal of Experimental Psychology: Applied_ , 2, pp. 107-125.

Bruers, S. (2016) “[A rational approach to improve worldwide well-being](https://stijnbruers.wordpress.com/2017/02/12/a-rational-approach-to-improve-worldwide-well-being/)”, _The Rational Ethicist_ , februari 12 [accessed on 20 May 2017].

Bruers, S. (2017) “[Moral illusions and wild animal suffering neglect](https://stijnbruers.wordpress.com/2016/07/20/moral-illusions-and-wild-animal-suffering-neglect/)”, _The Rational Ethicist_ , juli 20 [accessed on 18 May 2017].

Cameron, C. D. & Payne, B. K. (2011) “Escaping affect: How motivated emotion regulation creates insensitivity to mass suffering”, _Journal of Personality and Social Psychology,_ 100, pp. 1-15.

Carson, R. T. & Mitchell, R. C. 1995) “Sequencing and nesting in contingent valuation surveys”, _Journal of Environmental Economics and Management_ , 28, pp. 155-173.

Desmeules, R.; Bechara, A. & Dubé, L. (2008) “Subjective valuation and asymmetrical motivational systems: Implications of scope insensitivity for decision making”, _Journal of Behavioral Decision Makin_ g, 21, pp. 211-224.

Dickert, S.; Västfjäll, D.; Kleber, J. & Slovic, P. (2015) “[Scope insensitivity: The limits of intuitive valuation of human lives in public policy](https://www.sciencedirect.com/science/article/pii/S2211368114000795)”, _Journal of Applied Research in Memory and Cognition_ , 4, pp. 248-255 [accessed on 16 May 2017].

Erick, S. F. & Fischhoff, B. (1998) “Scope (in)sensitivity in elicited valuations”, _Risk Decision and Policy_ , 3, pp. 109-123.

Fetherstonhaugh, D.; Slovic, P.; Johnson, S. & Friedrich, J. (1997) “Insensitivity to the value of human life: A study of psychophysical numbing”, _Journal of Risk and Uncertainty_ , 14, pp. 238-300.

Kogut, T.; Slovic, P. & Västfjäll, D. (2015) “Scope insensitivity in helping decisions: Is it a matter of culture and values?”, _Journal of Experimental Psychology: General_ , 144, pp. 1042-1052.

* * *

 _This work is licensed under a_[ _Creative Commons Attribution 4.0 International License_](https://creativecommons.org/licenses/by/4.0/) _._

##  **Notes**
[^36]: Kahneman, D. & Tversky, A. (eds.) (2000) _Choices, values and frames_ , Cambridge: Cambridge University Pres
[^37]: Small, D. A.; Loewenstein, G. & Slovic, P. (2007) “Sympathy and callousness: The impact of deliberative thought on donations to identifiable and statistical victims”, _Organizational Behavior and Human Decision Processes_ , 102, pp. 143-15
[^38]: Baron, J. & Szymanska, E. (2011) “Heuristics and biases in charity”, in Oppenheimer, D.M. & Olivola, C. Y. (eds.) _The science of giving: Experimental approaches to the study of charity_ , New York: Psychology Press, pp. 215-23
[^39]: Kahneman, D.; Ritov, I.; Schkade, D.; Sherman, S. J. & Varian, H. R. (1999) “Economic preferences or attitude expressions?: An analysis of dollar responses to public issues”, _Journal of Risk and Uncertainty_ , 19, pp. 203-23
[^40]: Hsee, C. K. & Rottenstreich, Y. (2004) “Music, Pandas, and Muggers: On the Affective Psychology of Value”, _Journal of Experimental Psychology: General_ , 133, pp. 23-3
[^41]: Dickert, S.; Västfjäll, D.; Kleber, J. & Slovic, P. (2012) “Valuations of human lives: Normative expectations and psychological mechanisms of (ir)rationality”, _Synthese_ , 189, suppl. 1, pp. 95-10
[^42]: Slovic, P. (2007) “[‘If I look at the mass I will never act’: Psychic numbing and genocide](http://journal.sjdm.org/jdm7303a.pdf)”, _Judgment and Decision Making Journal_ , 2, pp. 79-95 [accessed on 15 May 2017
[^43]: Caviola, L.; Faulmüller, N.; Everett, J. A. C.; Savulescu, J. & Kahane, G. (2014) “[The evaluability bias in charitable giving: Saving administration costs or saving lives?](http://journal.sjdm.org/14/14402a/jdm14402a.pdf)”, _Judgment and Decision Making_ , 9, pp. 303-315 [accessed on 9 May 2017
[^44]: Haidt, J. (2001) “The emotional dog and its rational tail: A social intuitionist approach to moral judgment”, _Psychological Review_ , 108, pp. 814-83
[^45]: Slovic, P.; Zionts, D.; Woods, A.K.; Goodman, R. & Jinks, D. (2013) “Psychic numbing and mass atrocity”, in Shafir, E. (ed.) _The behavioral foundations of public policy_ , Princeton: Princeton University Press, pp. 126-14
[^46]: Tomasik, B. (2015) “[The importance of wild-animal suffering](http://www.ledonline.it/index.php/Relations/article/view/880)”, _Relations: Beyond Anthropocentrism_ , 3, pp. 133-152 [accessed on 20 May 2017
# Why you think you're right - even when you're wrong
This is a linkpost for [https://www.ted.com/talks/julia_galef_why_you_think_you_re_right_even_if_you_re_wrong?language=en](https://forum-bots.effectivealtruism.org/out?url=https%3A%2F%2Fwww.ted.com%2Ftalks%2Fjulia_galef_why_you_think_you_re_right_even_if_you_re_wrong%3Flanguage%3Den)

# What cognitive biases feel like from the inside
This is a linkpost for [https://www.lesswrong.com/posts/ERWeEA8op6s6tYCKy/what-cognitive-biases-feel-like-from-the-inside](https://forum-bots.effectivealtruism.org/out?url=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FERWeEA8op6s6tYCKy%2Fwhat-cognitive-biases-feel-like-from-the-inside)

by chaosmage

Building on the recent SSC post [_Why Doctors Think They’re The Best_](https://slatestarcodex.com/2020/01/02/why-doctors-think-theyre-the-best/)...

 **What it feels like for me**|  **How I see others who feel the same**  
---|---  
There is controversy on the subject but there shouldn't be because the side I am on is obviously right.| They have taken one side in a debate that is unresolved for good reason that they are struggling to understand  
I have been studying this carefully| They preferentially seek out conforming evidence  
The arguments for my side make obvious sense, they're almost boring.| They're very ready to accept any and all arguments for their side.  
The arguments for the opposing side are contradictory, superficial, illogical or debunked.| They dismiss arguments for the opposing side at the earliest opportunity.  
The people on the opposing side believe these arguments mostly because they are uninformed, have not thought about it enough or are being actively misled by people with bad motives.| The flawed way they perceive the opposing side makes them confused about how anyone could be on that side. They resolve that confusion by making strong assumptions that can approach conspiracy theories.  
  
 _The scientific term for this mismatch is:_ **confirmation bias**

 **What it feels like for me**|  **How I see others who feel the same**  
---|---  
My customers/friends/relationships love me, so I am good for them, so I am probably just generally good.| They neglect the customers / friends / relationships that did not love them and have left, so they overestimate how good they are.  
When customers / friends / relationships switch to me, they tell horror stories of who I'm replacing for them, so I'm better than those.| They don't see the people who are happy with who they have and therefore never become their customers / friends / relationships.  
  
 _The scientific term for this mismatch is:_ **selection bias**

 **What it feels like for me**|  **How I see others who feel the same**  
---|---  
Although I am smart and friendly, people don't listen to me.| Although they are smart and friendly, they are hard to understand.  
I have a deep understanding of the issue that people are too stupid or too disinterested to come to share.| They are failing to communicate their understanding, or to give unambiguous evidence if they even have it.  
This lack of being listened to affects several areas of my life but it is particularly jarring on topics that are very important to me.| This bad communication affects all areas of their life, but on the unimportant ones they don't even understand that others don't understand them.  
  
 _The scientific term for this mismatch is:_ **illusion of transparency**

 **What it feels like for me**|  **How I see others who feel the same**  
---|---  
I knew at the time this would not go as planned.| They did not predict what was going to happen.  
The plan was bad and we should have known it was bad.| They fail to appreciate how hard prediction is, so the mistake seems more obvious to them than it was.  
I knew it was bad, I just didn't say it, for good reasons (e.g. out of politeness or too much trust in those who made the bad plan) or because it is not my responsibility or because nobody listens to me anyway.| In order to avoid blame for the seemingly obvious mistake, they are making up excuses.   
  
_The scientific term for this mismatch is:_ **hindsight bias**

 **What it feels like for me**|  **How I see others who feel the same**  
---|---  
I have a good intuition; even decisions I make based on insufficient information tend to turn out to be right.| They tend to recall their own successes and forget their own failures, leading to an inflated sense of past success.  
I know early on how well certain projects are going to go or how well I will get along with certain people.| They make self-fulfilling prophecies that directly influence how much effort they put into a project or relationship.  
Compared to others, I am unusually successful in my decisions.| They evaluate the decisions of others more level-headedly than their own.  
I am therefore comfortable relying on my quick decisions.| They therefore overestimate the quality of their decisions.  
This is more true for life decisions that are very important to me.| Yes, this is more true for life decisions that are very important to them.  
  
 _The scientific term for this mismatch is:_ **optimism bias**

## Why this is better than how we usually talk about biases

Communication in abstracts is very hard. (See: [_Illusion of Transparency: Why No One Understands You_](https://www.lesswrong.com/posts/sSqoEw9eRP2kPKLCz/illusion-of-transparency-why-no-one-understands-you)) Therefore, it often fails. (See: [_Explainers Shoot High. Aim Low!_](https://www.lesswrong.com/posts/2TPph4EGZ6trEbtku/explainers-shoot-high-aim-low)) It is hard to even notice communication has failed. (See: [_Double Illusion of Transparency_](https://www.lesswrong.com/posts/sBBGxdvhKcppQWZZE/double-illusion-of-transparency)) Therefore it is hard to appreciate how rarely communication in abstracts actually succeeds.

Rationalists have noticed this. ([ _Example_](https://twitter.com/robinhanson/status/1206776893124546560)) Scott Alexander [_uses a lot of concrete examples_](https://slatestarcodex.com/2016/02/20/writing-advice/) and that should be a major reason why he’s our best communicator. Eliezer’s Sequences work partly because he uses examples and even fiction to illustrate. But when the rest of us talk about rationality we still mostly talk in abstracts.

For example, [_this recent video_](https://www.youtube.com/watch?v=HZGCoVF3YvM) was praised by many for being comparatively approachable. And it does do many things right, such as emphasize and repeat that evidence alone should not generate probabilities, but should only ever update prior probabilities. But it still spends more than half of its runtime displaying mathematical notation that no more than 3% of the population can even read. For the vast majority of people, only the example it uses can possibly “stick”. Yet the video uses its single example as no more than a means for getting to the abstract explanation.

This is a mistake. I believe a video with three to five vivid examples of how to apply Bayes’ Theorem, preferably funny or sexy ones, would leave a much more lasting impression on most people.

Our highly demanding style of communication correctly predicts that LessWrongians are, on average, much smarter, much more STEM-educated and much younger than the general population. You have to be that way to even be able to drink the Kool Aid! This makes us homogeneous, which is probably a big part of what makes LW feel tribal, which is emotionally satisfying. But it leaves most of the world with their bad decisions. We need to be [_Raising the Sanity Waterline_](https://www.lesswrong.com/posts/XqmjdBKa4ZaXJtNmf/raising-the-sanity-waterline) and we can’t do that by continuing to communicate largely in abstracts.

The tables above show one way to do better that does the following.

  * It aims low - merely to help people [_notice the flaws in their thinking_](https://www.lesswrong.com/posts/46qnWRSR7L2eyNbMA/the-lens-that-sees-its-flaws). It will not, and does not need to, enable readers to write scientific papers on the subject.
  * It reduces biases into mismatches between Inside View and Outside View. It lists concrete observations from both views and juxtaposes them.
  * These observations are written in a way that is hopefully general enough for most people to find they match their own experiences.
  * It trusts readers to infer from these juxtaposed observations their own understanding of the phenomena. After all, generalizing over particulars is much easier than integrating generalizations and applying them to particulars. The understanding gained this way will be imprecise, but it has the advantage of actually arriving inside the reader’s mind.
  * It is nearly jargon free; it only names the biases for the benefit of that small minority who might want to learn more.



What do you think about this? Should we communicate more concretely? If so, should we do it in this way or what would you do differently?

Would you like to correct these tables? Would you like to propose more analogous observations or other biases?

Thanks to Simon, miniBill and others for helping with the draft of this post.

_This work is licensed under a_[ _Creative Commons Attribution 4.0 International License_](https://creativecommons.org/licenses/by/4.0/) _._

# Purchase fuzzies and utilons separately
This is a linkpost for [https://www.lesswrong.com/posts/3p3CYauiX8oLjmwRF/purchase-fuzzies-and-utilons-separately](https://forum-bots.effectivealtruism.org/out?url=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F3p3CYauiX8oLjmwRF%2Fpurchase-fuzzies-and-utilons-separately)

 _Someone recently cross-posted this to the main EA Facebook group, where it got a lot of attention from people who came to EA from sources other than LessWrong. I think the essay is a classic, so I'm cross-posting it to the Forum, where I expect at least a few people to see it who hadn't seen it before._

Yesterday:

> There _is_ this very, very old puzzle/observation in economics about the lawyer who spends an hour volunteering at the soup kitchen, instead of working an extra hour and donating the money to hire someone...
> 
> If the lawyer needs to work an hour at the soup kitchen to keep himself motivated and remind himself why he's doing what he's doing, _that's fine._ But he should _also_ be donating some of the hours he worked at the office, because that is the power of professional specialization and it is how grownups really get things done. One might consider the check as buying the right to volunteer at the soup kitchen, or validating the time spent at the soup kitchen.

I hold open doors for little old ladies. I can't actually remember the last time this happened literally (though I'm sure it has, sometime in the last year or so). But within the last month, say, I was out on a walk and discovered a station wagon parked in a driveway with its trunk completely open, giving full access to the car's interior. I looked in to see if there were packages being taken out, but this was not so. I looked around to see if anyone was doing anything with the car. And finally I went up to the house and knocked, then rang the bell. And yes, the trunk had been accidentally left open.

Under other circumstances, this would be a simple act of altruism, which might signify true concern for another's welfare, or fear of guilt for inaction, or a desire to signal trustworthiness to oneself or others, or finding altruism pleasurable. I think that these are all perfectly legitimate motives, by the way; I might give bonus points for the first, but I wouldn't deduct any penalty points for the others. Just so long as people get helped.

But in my own case, since I already work in the nonprofit sector, the further question arises as to whether I could have better employed the same sixty seconds in a more _specialized_ way, to bring greater benefit to others. That is: can I really defend this as the _best_ use of my time, given the other things I claim to believe?

The obvious defense—or perhaps, obvious rationalization—is that an act of altruism like this one acts as an [willpower restorer](http://en.wikipedia.org/wiki/Ego_depletion), much more efficiently than, say, listening to music. I also mistrust my ability to be an altruist _only_ in theory; I suspect that if I walk past problems, my altruism will start to fade. I've never pushed that far enough to test it; it doesn't seem worth the risk.

But if that's the defense, then my act can't be defended as a good deed, can it? For these are self-directed benefits that I list.

Well—who said that I _was_ defending the act as a selfless good deed? It's a _selfish_ good deed. If it restores my willpower, or if it keeps me altruistic, then there are indirect other-directed benefits from that (or so I believe). You could, of course, reply that you don't trust selfish acts that are supposed to be other-benefiting as an "ulterior motive"; but then I could just as easily respond that, by the same principle, you should just look directly at the original good deed rather than _its_ supposed ulterior motive.

Can I get away with that? That is, can I really get away with calling it a "selfish good deed", and still derive willpower restoration therefrom, rather than feeling guilt about it being selfish? Apparently I can. I'm surprised it works out that way, but it does. So long as I knock to tell them about the open trunk, and so long as the one says "Thank you!", my brain feels like it's done its wonderful good deed for the day.

Your mileage may vary, of course. The problem with trying to work out an art of willpower restoration is that different things seem to work for different people. ([That is](http://www.overcomingbias.com/2008/11/chaotic-inversi.html): We're probing around on the level of surface phenomena without understanding the deeper rules that would also predict the variations.)

But if you find that you are like me in this aspect—that selfish good deeds still work—then I recommend that you _purchase warm fuzzies and utilons separately._ Not at the same time. Trying to do both at the same time just means that neither ends up done well. If status matters to you, purchase status separately too!

If I had to give advice to some new-minted billionaire entering the realm of charity, my advice would go something like this:

  * To purchase warm fuzzies, find some hard-working but poverty-stricken woman who's about to drop out of state college after her husband's hours were cut back, and personally, but anonymously, give her a cashier's check for $10,000. Repeat as desired.
  * To purchase status among your friends, donate $100,000 to the current sexiest X-Prize, or whatever other charity seems to offer the most stylishness for the least price. Make a big deal out of it, show up for their press events, and brag about it for the next five years.
  * Then—with absolute cold-blooded calculation—without [scope insensitivity](http://www.overcomingbias.com/2007/05/scope_insensiti.html) or [ambiguity aversion](http://en.wikipedia.org/wiki/Ambiguity_aversion)—without concern for status or warm fuzzies—figuring out some common scheme for converting outcomes to utilons, and trying to express uncertainty in percentage probabilitiess—find the charity that offers the greatest expected utilons per dollar. Donate up to however much money you wanted to give to charity, until their marginal efficiency drops below that of the next charity on the list.



I would furthermore advise the billionaire that what they spend on utilons should be at least, say, 20 times what they spend on warm fuzzies—5% overhead on keeping yourself altruistic seems reasonable, and I, your dispassionate judge, would have no trouble _validating_ the warm fuzzies against a multiplier that large. Save that the original, fuzzy act really should be helpful rather than actively harmful.

(Purchasing _status_ seems to me essentially unrelated to altruism. If giving money to the X-Prize gets you more awe from your friends than an equivalently priced speedboat, then there's really no reason to buy the speedboat. Just put the money under the "impressing friends" column, and be aware that this is not the "altruism" column.)

But the main lesson is that all three of these things—warm fuzzies, status, and expected utilons—can be bought _far_ more efficiently when you buy _separately_ , optimizing for only one thing at a time. Writing a check for $10,000,000 to a breast-cancer charity—while far more laudable than spending the same $10,000,000 on, I don't know, parties or something—won't give you the concentrated euphoria of being present in person when you turn a single human's life around, probably not anywhere _close_. It won't give you as much to talk about at parties as donating to something sexy like an X-Prize—maybe a short nod from the other rich. And if you threw away all concern for warm fuzzies and status, there are probably at least a _thousand_ underserved existing charities that could produce _orders of magnitude_ more utilons with ten million dollars. Trying to optimize for all three criteria in one go only ensures that none of them end up optimized very well—just vague pushes along all three dimensions.

Of course, if you're not a millionaire or even a billionaire—then you can't be quite as _efficient_ about things, can't so easily purchase in bulk. But I would still say—for warm fuzzies, find a relatively _cheap_ charity with bright, vivid, ideally in-person and direct beneficiaries. Volunteer at a soup kitchen. Or just get your warm fuzzies from holding open doors for little old ladies. Let that be _validated_ by your other efforts to purchase utilons, but don't _confuse_ it with purchasing utilons. Status is probably cheaper to purchase by buying nice clothes.

And when it comes to purchasing expected utilons—then, of course, [shut up and multiply](http://www.overcomingbias.com/2008/01/circular-altrui.html).

_This work is licensed under a_[ _Creative Commons Attribution 4.0 International License_](https://creativecommons.org/licenses/by/4.0/) _._

# We are in triage every second of every day
(Cross-posted from [this blog post.](https://mhollyelmoreblog.wordpress.com/2016/08/26/we-are-in-triage-every-second-of-every-day/))

 _ **Spoilers ahead** — listen to the episode beforehand if you don’t want to hear a rough summary first._

I quite liked the ["Playing God"](https://www.wnycstudios.org/podcasts/radiolab/articles/playing-god) episode of RadioLab.

The topic is [triage](https://en.wikipedia.org/wiki/Triage), the practice of assigning priority to different patients in emergency medicine. By extension, to triage means to ration scarce resources. The episode treats triage as a rare phenomenon– in fact, it suggests that medical triage protocols were not taken very seriously in the US until after Hurricane Katrina– but triage is not a rare phenomenon at all. We are engaging in triage with every decision we make.

* * *

The stories in “Playing God” are gripping, particularly the story of a New Orleans hospital thrown into hell in a matter of days after losing power during Hurricane Katrina. [Sheri Fink](http://www.sherifink.net/) from the New York Times discusses the events she reported in her book, [Five Days at Memorial.](https://www.amazon.com/Five-Days-Memorial-Storm-Ravaged-Hospital/dp/0307718972/ref=sr_1_1?ie=UTF8&qid=1471783956&sr=8-1&keywords=five+days+at+memorial) The close-up details are difficult to stomach. After evacuating the intensive care unit, the hospital staff are forced to rank the remaining patients for evacuation; moving the patients is backbreaking labor without the elevators, and helicopters and boats are only coming sporadically to take them away. Sewage is backing up into the hospital and the extreme heat is causing some patients and pets to have seizures.

Meanwhile, on the news, the staff hears exaggerated reports of looting and lawlessness in the city. Believing they have no choice, some of the staff begin to think euthanizing the sickest patients (and those hardest to transport for evacuation) may be the merciful thing to do. It is alleged that some patients _were_ euthanized, though no one involved was ever charged. Tragically, the possible killings took place on the same day that the rescue vehicles returned.

The crux of this story is that giving in to the logic of triage put the hospital staff on a slippery slope to “playing God”. The episode goes on to discuss ways of formalizing triage so people don’t have to rely on their own judgment at such a fraught time. (Utilitarian triage is discussed, and you can almost hear the speakers holding their noses.) Very often, concerns for the caregiver’s conscience take center stage, though no one acknowledges how selfish this is. Triage is portrayed very unsympathetically throughout, as if the people being forced to make the choice must be at fault somehow for having gotten in the situation.

But it was the last story that made me want to write this. Sheri Fink, the guest reporter, describes a woman she met in a American-run disaster-relief hospital in Haiti. Nathalie was a charming middle-aged woman whose life was spared because she went to the hospital for difficulty breathing. When the earthquake struck, her entire family was at their home, which collapsed and killed them all. Nathalie was putting on a brave face, just glad to be alive, and she radiated gratitude for the care she had received. 

But there was a problem. Nathalie needed oxygen, and the hospital (indeed, the nation) did not have enough to go around. Because she was suffering heart failure, the triage nurses had decided she should receive no more oxygen and return to a local Haitian-run hospital, most likely to die. Fink mentions ruefully that the nurse who made the call had never met Nathalie, as if that makes any difference at all. 

Fink rides in the ambulance with her to the new hospital, where she coughs and sputters and receives no oxygen to help. Fink’s heart breaks. But when Nathalie gets to the Haitian hospital, a clever doctor does what he can to drain the fluid from her lungs and manages to get her through the crisis without supplemental oxygen.

* * *

This story reinforces for Fink the fantasy that you never have to choose — that agreeing to choose is already going too far. Fink was so moved by Nathalie that she helped her to get a humanitarian visa to the US. It turned out Nathalie needed a heart transplant, and she died before she could get one. But, Fink says, she was a delight to everyone she met in those hospital; she even took up a collection for the other patients back in Haiti. So who were the doctors to say that she didn’t deserve every chance?

This is, of course, the wrong question. Of course Nathalie deserved every chance. No one should have to suffer heart failure in the first place. But did she deserve the oxygen more than all the other people who needed oxygen in that hospital? No. Did Nathalie’s time alive matter more than the greater amount of time the doctors could give other patients by employing the oxygen carefully? Absolutely not.

Nowhere in the episode were the beneficiaries of the triage discussed. There was no attempt to determine how many more people were saved because hospital staff took difficult, decisive action. There is no discussion of who _should_ have died in that situation if not Nathalie — someone with many healthy years ahead of them? Two people who could have been saved with the same amount of oxygen? There is only denial that anyone had to die at all. There is no gratitude for the extra lives saved — only [loss aversion](https://en.wikipedia.org/wiki/Loss_aversion). There is no acknowledgement that Fink would very likely not have wanted any other patient to die, either, had she met them, much less an acknowledgement that people matter whether you have personally met them or not.

Making better choices through conscious triage is no more “playing God” than blithely abdicating responsibility for the effects of our actions. Both choices are _choices_ to let some live and others die. The only difference is that the person who embraces triage has a chance to use their brain to improve the outcome. The suffering of the person who doesn’t receive the scarce resource is no less because you, personally, haven’t witnessed it. When Fink saw Nathalie’s suffering, it should only have informed her as to the gravity of the situation — both for Nathalie and for those who did receive the oxygen.

I understand that it’s hard, that we will always instinctively care more for the people we see than those we don’t. There’s no shame in Fink’s deep feelings for Nathalie. They are a key component of compassion. But there should be great shame in letting more people suffer and die than you need to because you can’t look past your own feelings. This is the kind of [narrow empathy that Paul Bloom is against](https://www.amazon.com/Against-Empathy-Case-Rational-Compassion/dp/0062339338).

There are [millions of people around the world dying of entirely preventable causes](http://www.un.org/apps/news/story.asp?NewsID=54340#.V7_XV7V8bWQ). Why should it make any difference that they aren’t in front of us? You know they are there. _They_ know the suffering they feel. [Poverty](https://www.givedirectly.org/?gclid=CjwKEAjwrvq9BRD5gLyrufTqg0YSJACcuF81S-ZBjDu85JfqJnmhncsRVcaL4Gb_InpXs74bUuvuGhoC4m7w_wcB) is a major culprit, as are [neglected tropical diseases](http://www.givewell.org/international/top-charities/amf) that could be cured for [pennies per person per year](http://www.givewell.org/international/top-charities/schistosomiasis-control-initiative). Money that you won’t even miss could be saving lives right now [if you put it to that purpose](https://www.givingwhatwecan.org/get-involved/join/) instead of, say, home improvement or collecting action figures. Every decision we make bears on the lives of the myriad others we might be able to help.

 **We are always in triage.** I fervently hope that one day we will be able to save everyone. In the meantime, it is irresponsible to pretend that we aren’t [making life and death decisions with the allocation of our resources](https://www.effectivealtruism.org/). Pretending there is no choice only makes our decisions worse.

_This work is licensed under a_[ _Creative Commons Attribution 4.0 International License_](https://creativecommons.org/licenses/by/4.0/) _._

# 500 Million, But Not A Single One More
This is a linkpost for [https://laneless.substack.com/p/500-million-but-not-a-single-one-more](https://forum-bots.effectivealtruism.org/out?url=https%3A%2F%2Flaneless.substack.com%2Fp%2F500-million-but-not-a-single-one-more)

 _Author's note: In 2023 this piece received two edits for historical accuracy. See_[ _comment_](https://forum.effectivealtruism.org/posts/jk7A3NMdbxp65kcJJ/500-million-but-not-a-single-one-more?commentId=nrhxEbKmv5yGQSMYu) _here for details._  
  
We will never know their names.

The first victim could not have been recorded, for there was no written language to record it. They were someone’s daughter, or son, and someone’s friend, and they were loved by those around them. And they were in pain, covered in rashes, confused, scared, not knowing why this was happening to them or what they could do about it — victims of a mad, inhuman god. There was nothing to be done — humanity was not strong enough, not aware enough, not knowledgeable enough, to fight back against a monster that could not be seen.

It was in Ancient Egypt, where it attacked slave and pharaoh alike. In Rome, it effortlessly decimated armies. It killed in Syria. It killed in Moscow. In India, five million dead. It killed a thousand Europeans every day in the 18th century. It killed more than ten million Native Americans. From the Peloponnesian War to the Civil War, it slew more soldiers and civilians than any weapon, any soldier, any army. (Not that this stopped the most foolish and empty souls from attempting to harness the demon as a weapon against their enemies.)

Cultures grew and faltered, and it remained. Empires rose and fell, and it thrived. Ideologies waxed and waned, but it did not care. Kill. Maim. Spread. An ancient, mad god, hidden from view, that could not be fought, could not be confronted, could not even be comprehended. Not the only one of its kind, but the most devastating.

For a long time, there was no hope — only the bitter, hollow endurance of survivors.

In China, in the 15th century, humanity began to fight back.

It was observed that survivors of the mad god’s curse would never be touched again: They had taken a portion of that power into themselves, and were so protected from it. Not only that, but this power could be shared by consuming a remnant of the wounds. There was a price, for you could not take the god’s power without first defeating it — but a smaller battle, on humanity’s terms. 

By the 16th century, the technique spread to India, then across Asia, the Ottoman Empire and, in the 18th century, Europe. In 1796, a more powerful technique was discovered by Edward Jenner.

An idea began to take hold: Perhaps the ancient god could be killed.

A whisper became a voice; a voice became a call; a call became a battle cry, sweeping across villages, cities, nations. Humanity began to cooperate, spreading the protective power across the globe, dispatching masters of the craft to protect whole populations. People who had once been sworn enemies joined in a common cause for this one battle. Governments mandated that all citizens protect themselves, for giving the ancient enemy a single life would put millions in danger.

And, inch by inch, humanity drove its enemy back. Fewer friends wept; fewer neighbors were crippled; fewer parents had to bury their children.

At the dawn of the 20th century, for the first time, humanity banished the enemy from entire regions of the world. Humanity faltered many times in its efforts, but there were individuals who never gave up, who fought for the dream of a world where no child or loved one would ever fear the demon ever again. Viktor Zhdanov, who called for humanity to unite in a final push against the demon; the great tactician Karel Raška, who conceived of a strategy to annihilate the enemy; Donald Henderson, who led the efforts in those final days.

The enemy grew weaker. Millions became thousands, thousands became dozens. And then, when the enemy did strike, scores of humans came forth to defy it, protecting all those whom it might endanger.

The enemy’s last attack in the wild was on Ali Maow Maalin, in 1977. For months afterwards, dedicated humans swept the surrounding area, seeking out any last, desperate hiding place where the enemy might yet remain.

They found none.

Thirty-five years ago, on December 9th, 1979, humanity declared victory.

This one evil, the horror from beyond memory, the monster that took 500 million people from this world, was destroyed.

You are a member of the species that did that. Never forget what we are capable of when we band together and declare battle on what is broken in the world.

[ _Happy Smallpox Eradication Day_](https://en.wikipedia.org/wiki/Smallpox#Eradication).

_This work is licensed under a_[ _Creative Commons Attribution 4.0 International License_](https://creativecommons.org/licenses/by/4.0/) _._

# More to explore on 'The Effectiveness Mindset'
## Other introductions

  * [ _Introduction to EA | Ajeya Cotra | EAGxBerkeley 2016_](https://www.youtube.com/watch?v=48VAQtGmfWY&feature=youtu.be&ab_channel=CentreforEffectiveAltruism) (Video - 30 mins.)
  * [ _ _Doing Good Better__](https://bit.ly/3fNWtzB) \- Introduction through to the end of Chapter 3 (50 mins.)
  * [ _Effective Altruism: An Introduction - 80,000 Hours_](https://80000hours.org/podcast/effective-altruism-an-introduction/) \- _Ten curated episodes from The 80,000 Hours Podcast. (Ten 1.5 hour - 4 hour podcasts)_
  * [ _Effective altruism as I see it_](https://lukemuehlhauser.com/effective-altruism-as-i-see-it/) (7 mins.)
  * [ _No matter your job, here’s 3 evidence-based ways anyone can have a real impact - 80,000 Hours_](https://tinyurl.com/4wy2xe8) (20 mins.)
  * [ _Other-centered ethics and Harsanyi's Aggregation Theorem_](https://forum.effectivealtruism.org/posts/iupkbiubpzDDGRpka/other-centered-ethics-and-harsanyi-s-aggregation-theorem) (107 min)



## Essays on caring

  * [ _ _The value of a life - Minding Our Own Way__](https://tinyurl.com/xzbzcbks) _\- Disentangling the difference between the value of a life and what it costs to save a life in our broken world. (15 mins.)_
  * [ _ _Excited altruism - GiveWell__](https://tinyurl.com/brv5wk37) _\- Where does our own passion and excitement fit in? (10 mins.)_



## Tradeoffs

  * [ _ _Tradeoffs__](https://tinyurl.com/4kwcv3t4) _\- How can we balance our own needs with the needs of others? (5 mins.)_
  * [ _Famine, affluence, and morality_](https://personal.lse.ac.uk/robert49/teaching/mm/articles/Singer_1972Famine.pdf) (15 mins.) _Note that many people in effective altruism disagree about exactly how demanding these ideas are._
  * [ _Sustainable motivation_](https://forum.effectivealtruism.org/posts/WuWDS4SmtLNd6sKtb/helen-toner-sustainable-motivation) \- _How can we stay motivated when facing massive problems_ (24 min talk) _?_



## Thinking carefully

  * [ _Minimal trust investigations_](https://forum.effectivealtruism.org/posts/8RcFQPiza2rvicNqw/minimal-trust-investigations) (18 mins.)
  * [ _Double crux: a strategy for mutual understanding_](https://www.lesswrong.com/posts/exa5kmvopeRyfJgCy/double-crux-a-strategy-for-mutual-understanding) (17 mins.)
  * [ _Outline of Julia Galef’s “Scout Mindset”_](https://forum.effectivealtruism.org/posts/HDAXztEbjJsyHLKP7/outline-of-galef-s-scout-mindset) (20 mins.)
  * [ _Humans are not automatically strategic_](https://www.lesswrong.com/posts/PBRWb2Em5SNeWYwwB/humans-are-not-automatically-strategic) (5 mins.)
  * [ _Beware surprising and suspicious convergence_](https://forum.effectivealtruism.org/posts/omoZDu8ScNbot6kXS/beware-surprising-and-suspicious-convergence) (22 mins.)
  * [ _Crucial Considerations and Wise Philanthropy_](http://www.stafforini.com/blog/bostrom/) (25 mins) - _talk by Nick Bostrom on the almost overwhelming difficulty of knowing what kind of impacts actions have._


