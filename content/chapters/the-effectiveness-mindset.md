+++
title = 'The Effectiveness Mindset'
date = 2024-01-23T01:12:17+08:00
draft = false
weight = 10
section = 'chapters'
+++

# Chapter 1: The Effectiveness Mindset

---

# About this handbook

## What the program is about [^1]

**Effective altruism (EA) is an ongoing project to find the best ways to do good, and put them into practice.**

**Our core goal with this program is to introduce you to some of the principles and thinking tools behind effective altruism**. We hope that these tools can help you as you think through how you can best help the world.

We also want to share some of the arguments for working on specific problems, like global health or biosecurity. People involved in effective altruism tend to agree that, partly due to uncertainty about which cause is best, we should split our resources between problems. But they don’t agree on what that split should be. **People in the effective altruism community actively discuss and disagree about which causes to prioritize and how**, even though we’ve learned a lot over the last decade. We hope that you will take these ideas seriously and think for yourself about which ways to help are most effective.

**Finally, we give you some time at the end of the program to begin to reflect on how you personally can help to solve these problems.** We don’t expect you’ll have an answer by the end of the eight weeks, but we hope you’re better prepared to explore this further.

## What the program involves

Each part of the program has a set of core posts and sometimes an exercise.

We think that the core posts take most people about 1-2 hours to get through, and the exercise another 30-60 minutes. We have matched the readings and exercises so that, in total, we think it will take around 2-2.5 hours per week to prepare for the weekly session.

The exercises help you put the concepts from the reading into practice.

Beyond the core posts, there are more materials each week in ‘More to Explore’ — these are all optional and explore the themes of the week in more depth and breadth.

Approximate reading times are given for each of the posts. Generally, we’d prefer you to take your time and think through the readings instead of rushing.

This curriculum was drawn up by staff from the Centre for Effective Altruism, incorporating feedback from others. Ultimately we had to make many judgement calls, and other people would have drawn up a different curriculum. [^2]

## How we hope you’ll approach the program

### Taking ideas seriously

Often, conversations about ideas are recreational: we enjoy batting around interesting thoughts and saying smart things, and then go back to doing whatever we were already doing in our lives. This is a fine thing to do — but at least sometimes, we think we should be asking ourselves questions like:

- “How could I tell if this idea was true?”
- “What evidence would it take to convince me that I was wrong about an idea?”
- “If it is true, what does that imply I should be doing differently in my life? What else does it imply I’m wrong about?”
- “How might this impact my plans for my career/life?”

And, zooming out:

- “Where are my blind spots?”
- “Which important questions should I be thinking about that I’m not?”
- “Do I really know if this idea/plan will help make things better or not?”

Answering these questions can help make our worldviews as accurate and full as possible and, by extension, help us make better decisions about things that we care about.

### Disagreements are useful

When thoughtful people with access to the same information reach very different conclusions from each other, we should be curious about why and we should actively encourage people to voice and investigate where those disagreements are coming from. If, for example, a medical community is divided on whether Treatment A or B does a better job of curing some disease, they should want to get to the bottom of that disagreement, because the right answer matters — lives are at stake. If you start off disagreeing with someone then change your mind, that can be hard to admit, but we think that should be celebrated. Helping conversations become clearer by changing your mind in response to arguments you find compelling will help the community act to save lives more effectively Even if you don’t expect to end up agreeing with the other person, you’ll learn more if you acknowledge that you disagree and try to understand exactly how and why their views disagree with yours.

### Be aware of our privilege and the seriousness of these issues

We shouldn’t lose sight of our privilege in being able to read and discuss these ideas, or that we are talking about real lives. We’re lucky to be in a position where we can have such a large impact, and this opportunity for impact is the consequence of a profoundly unequal world. Also, be conscious of the fact that people in this program come to these discussions with different ideas, backgrounds, and knowledge. Some of these topics can be uncomfortable to talk about — which is one of the reasons they’re so neglected, and so important to talk about — especially when we may have personal ties to some of these areas.

### Explore further

This handbook aims to introduce people to effective altruism in a structured manner. There are far too many relevant topics, ideas, and research for all but a small fraction of them to fit into this very short program. If you are interested in these topics, you may find it very useful to dive into the linked websites, and the websites those sites link to, and so on.

---

# The Effectiveness Mindset

“We are always in triage. I fervently hope that one day we will be able to save everyone. In the meantime, it is irresponsible to pretend that we aren’t making life and death decisions with the allocation of our resources. Pretending there is no choice only makes our decisions worse."

— [Holly Elmore](https://forum.effectivealtruism.org/s/B79ro5zkhndbBKRRX/p/vQpk3cxdAe5RX9xzo), explaining the need to prioritize given our limited resources.

In this chapter we’ll explore why you might want to help others, why it’s so critical to think carefully about how many people are affected by an intervention, and come to terms with the tradeoffs we face in our altruistic efforts.

Key concepts in this chapter include:

- **Scope sensitivity**: saving ten lives is more important than saving one, and saving a billion lives is a lot more important than saving ten.
- **Tradeoffs**: Because we have limited time and money, we need to prioritize between different ways to improve the world.
- **Scout mindset**: We’ll be better able to help others if we’re working together to think clearly and orient towards finding the truth, rather than trying to defend our own ideas. Humans naturally aren’t great at this (aside from wanting to defend our own ideas, we have a host of other biases), but if we want to really understand the world, it’s worth seeking the truth and trying to become clearer thinkers.

{{< rawhtml >}}

<html>
  <head>
    <script type="module" src="https://js.withorbit.com/orbit-web-component.js"></script>
  </head>
  <body>
    <orbit-reviewarea color="blue">
      <orbit-prompt
        question="What's scope sensitivity?"
        answer="Saving ten lives is more important than saving one."
      ></orbit-prompt>
      <orbit-prompt
        question="What kinds of tradeoffs will this chapter cover?"
        answer="How to prioritize between different ways of improving the world."
      ></orbit-prompt>
      <orbit-prompt
        question="What's the scout mindset in a nutshell?"
        answer="To think more clearly, it's better to truthseek rather than defend our own ideas."
      ></orbit-prompt>
    </orbit-reviewarea>
  </body>
</html>

{{< /rawhtml >}}

---

# Introduction to Effective Altruism

{{< hint info >}}
This is a linkpost for https://www.effectivealtruism.org/articles/introduction-to-effective-altruism
{{< /hint >}}

## What is effective altruism?

Effective altruism is a project that aims to find the best ways to help others, and put them into practice.

It’s both a **research field**, which aims to identify the world’s most pressing problems and the best solutions to them, and a \*practical community\*\* that aims to use those findings to do good.

This project matters because, while many attempts to do good fail, some are enormously effective. For instance, some charities help 100 or even 1,000 times as many people as others, when given the same amount of resources.

This means that by thinking carefully about the best ways to help, we can do far more to tackle the world’s biggest problems.

Effective altruism was formalized by scholars at Oxford University, but has now spread around the world, and is being applied by tens of thousands of people in more than 70 countries.[^3]

People inspired by effective altruism have worked on projects that range from funding the distribution of 200 million malaria nets, to academic research on the future of AI, to campaigning for policies to prevent the next pandemic.

They’re not united by any particular solution to the world’s problems, but by a way of thinking. They try to find unusually good ways of helping, such that a given amount of effort goes an unusually long way. Here are some examples of what they've done so far, followed by the values that unite them:

{{< rawhtml >}}

<html>
  <head>
    <script type="module" src="https://js.withorbit.com/orbit-web-component.js"></script>
  </head>
  <body>
    <orbit-reviewarea color="blue">
      <orbit-prompt
        question="Why does effective altruism matter?"
        answer="Some charities help 100 or 1,000 times as many people as others, when given the same amount of resources. By thinking carefully, we can help alot more. "
      ></orbit-prompt>
      <orbit-prompt
        question="Is Effective Altruism tied to a few cause areas or solutions?"
        answer="Effective Altruism is about a way of thinking, and not about any particular solution to a problem. EAs have worked on projects that range from funding the distribution of 200 million malaria nets, to academic research on the future of AI, to campaigning for policies to prevent the next pandemic."
      ></orbit-prompt>
    </orbit-reviewarea>
  </body>
</html>

{{< /rawhtml >}}

## What are some examples of effective altruism in practice?

### Preventing the next pandemic

#### Why this issue?

People in effective altruism [typically try to](https://forum.effectivealtruism.org/topics/itn-framework) identify issues that are big in scale, tractable, and unfairly neglected.[^4] The aim is to find the biggest gaps in current efforts, in order to find where an additional person can have the greatest impact. One issue that seems to match those criteria is preventing pandemics.

Researchers in effective altruism argued as early as 2014 that, given the history of near-misses, there was a good chance that a large pandemic would happen in our lifetimes.

But preparing for the next pandemic was, and remains, hugely underfunded compared to other global issues. For instance, the US invests around $8bn per year preventing pandemics, compared to around $280bn per year spent on counterterrorism over the last decade.[^5]

![Pandemic prevention spreading](/images/preventing-pandemics.png)

Preventing terror attacks is certainly important. But the scale of the issue seems smaller. For instance, just to focus on the number of deaths, in the last 50 years, around 500,000 people have been killed by terrorism. But over 21 million people were killed by COVID-19 alone[^6] – or consider the 40 million killed by HIV/AIDS.[^7]

![Pandemic deaths comparison](/images/people-died-pandemics.png)

Not to mention, a future pandemic could easily be much worse than COVID-19: there’s nothing to rule out a disease that’s more infectious than the Omicron variant, but that’s as deadly as smallpox. (See more on the comparison in footnote [^6].)

In effective altruism, once a big and neglected problem has been identified, the community then looks for solutions that have a chance of making a big contribution to solving the problem, and are neglected by others working on that issue, which brings us to...

#### Some examples of what’s been done

In 2016 Open Philanthropy – a foundation inspired by effective altruism – became the largest funder of the [Johns Hopkins Center for Health Security](https://www.centerforhealthsecurity.org/), which is one of the few groups doing research to identify better policy responses to pandemics, and was an important group in the response to COVID-19.[^8]

When COVID-19 broke out, members of the community founded [1DaySooner](https://www.1daysooner.org/), a non-profit that advocates for human challenge trials. In this type of vaccine trial, healthy volunteers are deliberately infected with the disease, enabling near-instant testing of the vaccine. As one of the only advocates for this intervention, 1DaySooner has signed up over 30,000 volunteers,[^9] and played an important role in starting the world’s first COVID-19 human challenge trial. This model can be repeated when we face the next pandemic.

Members of the effective altruism community helped to create the [Apollo Programme for Biodefense](https://biodefensecommission.org/reports/the-apollo-program-for-biodefense-winning-the-race-against-biological-threats/), a multibillion dollar policy proposal designed to prevent the next pandemic.

### Providing basic medical supplies in poor countries

#### Why this issue?

It’s common to say that charity begins at home, but in effective altruism, charity begins where we can help the most. And this often means focusing on the people who are most neglected by the current system – which is often those who are more distant from us.

Over 700 million people live on less than $1.90 per day.[^10]

In contrast, an American living near the poverty line lives on 20 times as much, and the average American college graduate lives on about 107 times as much. This places them in the top 1.3% of income, globally speaking.[^11] (These amounts are already adjusted for the fact that money goes further in poor countries.)

![Income distribution](/images/income-inequality.png)

Global inequality is extreme. Because of this, transferring resources to the very poorest people in the world can do a huge amount of good. In richer countries like the US and UK, governments are typically willing to spend over $1 million to save a life.[^12] This is well worth doing, but in the world’s poorest countries, the cost of saving a life is far lower.

[GiveWell](https://www.givewell.org/) is an organization that does in-depth research to find the most evidence-backed and cost-effective health and development projects. It discovered that while [many aid interventions don’t work](https://www.givewell.org/international/technical/criteria/impact/failure-stories), some, like providing insecticide-treated bednets, can save a child’s life for about $5,500 on average. That's 180 times less.[^13]

These basic medical interventions are so cheap and effective that even the [most prominent aid sceptics agree](https://blog.givewell.org/2015/11/06/the-lack-of-controversy-over-well-targ) they’re worthwhile.

![Cost to save a life](/images/cost-to-save-a-life.png)

#### Some examples of what’s been done

Over 110,000 individual donors have used GiveWell’s research to contribute more than $1 billion to its recommended charities, supporting organisations like the [Against Malaria Foundation](https://www.givewell.org/charities/amf), which has distributed over 200 million insecticide-treated bednets. Collectively these efforts are estimated to have saved 159,000 lives.[^14]

In addition to charity, it’s possible to help the world’s poorest people through business. [Wave](https://www.wave.com/en/) is a technology company founded by members of the effective altruism community, which allows people to transfer money to several African countries faster and several times more cheaply than existing services. It’s especially helpful for migrants sending money home to their families, and has been used by over 800,000 people in countries like Kenya, Uganda and Senegal. In Senegal alone, Wave has saved its users hundreds of millions of dollars in transfer fees – around 1% of the country’s GDP.[^15]

### Helping to create the field of AI alignment research

#### Why this issue?

People in effective altruism often end up focusing on issues that seem counterintuitive, obscure or exaggerated. But this is because it’s more impactful to work on the issues that are neglected by others (all else equal), and these issues are (almost by definition) going to be unconventional ones. One example is the AI alignment problem.

Artificial intelligence (AI) is progressing rapidly. The leading AI systems are now able to engage in limited conversation, solve college-level maths problems, explain jokes, generate extremely realistic images from text, and do basic coding.[^16] None of this was possible just ten years ago.

The ultimate goal of the leading AI labs is to develop AI that is as good as, or better than, human beings on all tasks. It’s extremely hard to predict the future of technology, but [various arguments and expert surveys suggest](https://www.cold-takes.com/where-ai-forecasting-stands-today/) that this achievement is more likely than not this century. And according to [standard economic models](https://www.openphilanthropy.org/research/could-advanced-ai-drive-explosive-economic-growth/), once general AI can perform at human level, technological progress could dramatically accelerate.

The result would be an enormous transformation, perhaps of a significance similar to or greater than the industrial revolution in the 1800s. If handled well, this transformation could bring about abundance and prosperity for everyone. If handled poorly, it could result in an extreme concentration of power in the hands of a tiny elite.

In the worst case, we could [lose control](https://www.cold-takes.com/ai-could-defeat-all-of-us-combined/) of the AI systems themselves. Unable to govern beings with capabilities far greater than our own, we would find ourselves with as little control over our future as chimpanzees have control over theirs.

This means this issue could not only have a dramatic impact on the present generation, but also on all future generations. This makes it especially pressing from a [“longtermist”](https://en.wikipedia.org/wiki/Longtermism) perspective, a school of thinking which holds that improving the long-term future is a key moral priority of our time.

How to ensure AI systems continue to further human values, even as they become equal (or superior) to humans in their capabilities, is called the AI alignment problem, and solving it requires advances in computer science.

Despite its potentially historic importance, only a couple of hundred researchers work on this problem, compared to tens of thousands working to make AI systems more powerful.[^17]

![AI research distribution](/images/ai-alignment.png)

It’s hard to sum up the case for the issue in a few paragraphs, so if you’d like to explore more, we’d recommend starting [here](https://www.vox.com/future-perfect/2018/12/21/18126576/ai-artificial-intelligence-machine-learning-safety-alignment), [here](https://80000hours.org/problem-profiles/artificial-intelligence/) and [here](https://www.cold-takes.com/most-important-century/).

#### Some examples of what’s been done

One priority is to simply tell more people about the issue. The book [Superintelligence](https://en.wikipedia.org/wiki/Superintelligence:_Paths,_Dangers,_Strategies) was published in 2014, making the case for the importance of AI alignment, and became a [New York Times best-seller](https://en.wikipedia.org/wiki/Superintelligence:_Paths,_Dangers,_Strategies#Reception).

Another priority is to build a research field focused on this problem. For instance, AI pioneer Stuart Russell, and others inspired by effective altruism, founded [The Center for Human-Compatible AI](https://humancompatible.ai/) at UC Berkeley. This research institute aims to develop a new paradigm of AI development, in which the act of furthering human values is central.

Others have helped to start teams focused on AI alignment at major AI labs such as [DeepMind](https://www.deepmind.com/safety-and-ethics) and [OpenAI](https://openai.com/safety), and outline research agendas for AI alignment, in works such as [Concrete Problems in AI Safety](https://arxiv.org/abs/1606.06565).

### Ending factory farming

#### Why this issue?

People in effective altruism try to extend their circle of concern – not only to those living in distant countries or future generations, but also to non-human animals.

Nearly 10 billion animals live and die in factory farms in the US every year[^18] – often unable to physically turn around their entire lives, or castrated without anaesthetic.

Lots of people agree we shouldn’t make animals suffer needlessly, but most of this attention goes towards pet shelters. In the US, about 1,400 times more animals pass through factory farms than pet shelters.[^19]

![Animals welfare populations](/images/farm-population.png)

Despite this, pet shelters receive around $5 billion per year in the US, compared to only $97 million on advocacy to end factory farming.[^20]

![Animal welfare spending](/images/spending-on-farms.png)

#### Some examples of what’s been done

One strategy is advocacy. The [Open Wing Alliance](https://openwingalliance.org/impact), which received significant funding from funders inspired by effective altruism, developed a campaign to encourage large companies to commit to stop buying eggs from caged chickens. To date, they have won over 2,200 commitments, and as a result over 100 million birds have been spared from cages.[^21]

Another strategy is to create alternative proteins, which if made cheaper and tastier than factory farmed meat, could make demand disappear, ending factory farming. The [Good Food Institute](https://gfi.org/) is working to kick-start this industry, helping to create companies like Dao Foods in China and Good Catch in the US, encouraging big business to enter the industry (including JBS, the world’s largest meat company) and securing tens of millions of dollars of government support.[^22]

Open Philanthropy was an [early investor](https://www.openphilanthropy.org/grants/impossible-foods-rd-investment/#:~:text=working%20to%20overcome.-,Background,Impossible%20Burger%2C%20in%20July%202016.) in [Impossible Foods](https://en.wikipedia.org/wiki/Impossible_Foods), which created the Impossible Burger – an entirely vegan burger that tastes much more like meat, and is now sold in Burger King.

### Improving decision-making

#### Why this issue?

People who want to do good often prefer to directly tackle problems, since it’s more motivating to see the tangible effects of their actions. But what matters is that the world gets better, not that you do it with your own two hands. So people applying effective altruism often try to help indirectly, by empowering others.

One example of this is by improving decision-making. Namely: if key actors — such as politicians, private and third sector leaders, or grantmakers at funding bodies — were generally better at making decisions, society would be in a better position to deal with a whole range of future global problems, whatever they turn out to be.

So, if we can find new, neglected ways to improve the decision-making of important actors, that could be a route to having a big impact. And it seems like there are some promising solutions that could achieve this.

#### Some examples of what’s been done

Many global problems are exacerbated by a lack of trustworthy information. [Metaculus](https://www.metaculus.com/questions/) is a forecasting technology platform that identifies important questions (such as the chance of Russia invading Ukraine), aggregates forecasts made by hundreds of forecasters, and weighs them by their past accuracy. Metaculus gave a probability of a Russian invasion of Ukraine of 47% by mid January 2022, and 80% shortly before the invasion on the 24th of February21 – a time when many pundits, journalists and experts were saying it definitely wouldn’t happen.

![Metaculus Ukraine Prediction](/images/metaculus.png)

The [Global Priorities Institute](https://globalprioritiesinstitute.org/) at the University of Oxford does foundational research at the intersection of philosophy and economics into how key decision-makers can identify the world’s most pressing problems. It has helped to create a new academic field of global priorities research, creating a [research agenda](https://globalprioritiesinstitute.org/research-agenda/), publishing [tens of papers](https://globalprioritiesinstitute.org/papers/), and helping to inspire relevant research at Harvard, NYU, UT Austin, Yale, Princeton and elsewhere.

{{< rawhtml >}}

<html>
  <head>
    <script type="module" src="https://js.withorbit.com/orbit-web-component.js"></script>
  </head>
  <body>
    <orbit-reviewarea color="blue">
      <orbit-prompt
        question="Why is preventing the next pandemic a big issue?"
        answer="Much less is spent on preventing pandemics compared to counterterrorism, while the number of deaths due to covid-19 far exceed the number of deaths from terrorism.
        In effective altruism, once a big and neglected problem has been identified, the community then looks for solutions that have a chance of making a big contribution to solving the problem, and are neglected by others working on that issue"
      ></orbit-prompt>
      <orbit-prompt
        question="Why is providing basic medical supplies in poor countries a big issue?"
        answer="Over 700 million people live on less than $1.90 per day. In contrast, an American living near the poverty line lives on 20 times as much, and the average American college graduate lives on about 107 times as much. Global inequality is extreme. Because of this, transferring resources to the very poorest people in the world can do a huge amount of good."
      ></orbit-prompt>
      <orbit-prompt
        question="Why is AI alignment a big issue?"
        answer="With rapid progress in artificial intelligence (AI), the goal is to develop AI surpassing human capabilities. The potential consequences, both positive and negative, are compared to the significance of the industrial revolution. If handled well, AI advancements could bring prosperity, but if mismanaged, power could concentrate in the hands of a few, or worse, control could be lost.
        The AI alignment problem, ensuring AI systems align with human values, is crucial for the future. Despite its significance, only a small number of researchers work on this problem compared to those enhancing AI capabilities. The issue not only impacts the present generation but holds long-term implications, making it a priority from a "longtermist" perspective."
      ></orbit-prompt>
      <orbit-prompt
        question="Why is ending factory farming a big issue?"
        answer="Nearly 10 billion animals live and die in factory farms in the US every year – often unable to physically turn around their entire lives, or castrated without anaesthetic. In the US, about 1,400 times more animals pass through factory farms than pet shelters, but pet shelters receive around $5 billion per year in the US, compared to only $97 million on advocacy to end factory farming "
      ></orbit-prompt>
      <orbit-prompt
        question="Why is improving decision making a big issue?"
        answer="If key actors — such as politicians, private and third sector leaders, or grantmakers at funding bodies — were generally better at making decisions, society would be in a better position to deal with a whole range of future global problems, whatever they turn out to be."
      ></orbit-prompt>
    </orbit-reviewarea>
  </body>
</html>

{{< /rawhtml >}}

## What values unite effective altruism?

Effective altruism isn't defined by the projects above, and what it focuses on could easily change. What defines effective altruism are some tentative values and principles that underpin its search for the best ways of helping others:

1. **Prioritization**: Our [intuitions](https://en.wikipedia.org/wiki/Scope_neglect) about doing good don't usually take into account the scale of the outcomes — helping 100 people often makes us feel as satisfied as helping 1000. But since some ways of doing good also achieve dramatically more than others, it’s vital to attempt to use numbers to roughly weigh how much different actions help. The goal is to find the best ways to help, rather than just working to make any difference at all.

2. **Impartial altruism**: It's easy — and reasonable — to have special concern for one's own family, friends or nation. But, when trying to do as much good as possible, it seems that we should give everyone's interests equal weight, no matter where or when they live. This means focusing on the groups who are most neglected, which usually means focusing on those who don’t have as much power to protect their own interests.

3. **Open truthseeking**: Rather than starting with a commitment to a certain cause, community or approach, it’s important to consider many different ways to help and seek to find the best ones. This means putting serious time into deliberation and reflection on one’s beliefs, being constantly open and curious for new evidence and arguments, and being ready to change one’s views quite radically.

4. **Collaborative spirit**: It’s often possible to achieve more by working together, and doing this effectively requires high standards of honesty, integrity, and compassion. Effective altruism does not mean supporting ‘ends justify the means’ reasoning, but rather is about being a good citizen, while working toward a better world.

We’re not totally confident in the above ideas - but we think that they are probably right, and that they are undervalued by much of society. Anyone who is trying to find better ways to help others is participating in effective altruism. This is true no matter how much time or money they want to give, or which issue they choose to focus on.

Effective altruism can be compared to the scientific method. Science is the use of evidence and reason in search of truth – even if the results are unintuitive or run counter to tradition. Effective altruism is the use of evidence and reason in search of the best ways of doing good.

The scientific method is based on simple ideas (e.g. that you should test your beliefs) but it leads to a radically different picture of the world (e.g. quantum mechanics). Likewise, effective altruism is based on simple ideas – that we should treat people equally and it’s better to help more people than fewer – but it leads to an unconventional and ever-evolving picture of doing good.

{{< rawhtml >}}

<html>
  <head>
    <script type="module" src="https://js.withorbit.com/orbit-web-component.js"></script>
  </head>
  <body>
    <orbit-reviewarea color="blue">
      <orbit-prompt
        question="What are the values of Effective Altruism?"
        answer="Prioritization, impartial altruism, open seeking, and collaborative spirit."
      ></orbit-prompt>
    </orbit-reviewarea>
  </body>
</html>

{{< /rawhtml >}}

## How can you take action?

People interested in effective altruism most often attempt to apply the ideas in their lives by:

- Choosing careers that help tackle pressing problems, or by finding ways to use their existing skills to contribute to these problems, such as by using advice from [80,000 Hours](https://80000hours.org/).

- Donating to carefully chosen charities, such as by using research from [GiveWell](https://www.givewell.org/) or [Giving What We Can](https://www.givingwhatwecan.org/best-charities-to-donate-to-2024).

- [Starting new organizations](https://80000hours.org/career-reviews/founder-impactful-organisations/#lists-of-ideas) that help to tackle pressing problems.

- Helping to build communities tackling pressing problems.

See a [longer list of ways to take action](https://forum.effectivealtruism.org/topics/take-action).

The above are not exhaustive. You can apply effective altruism no matter how much you want to focus on doing good, and in any area of your life – what matters is that, no matter how much you want to contribute, your efforts are driven by the four values above, and you try to make your efforts as effective as possible.

Typically, this involves trying to identify big and neglected global problems, the most effective solutions to those problems, and ways you can contribute to those solutions – with whatever time or money you’re willing to give.

By doing this and thinking carefully, you might find it’s possible to have far more impact with those resources. It really is possible to save hundreds of people’s lives over your career. And by teaming up with others in the community, you can play a role in tackling some of the most important issues civilization faces today.

---

# Four Ideas You Already Agree With

{{< hint info >}}
This is a linkpost for [https://www.givingwhatwecan.org/blog/four-things-you-already-agree-with-effective-altruism](https://forum.effectivealtruism.org/out?url=https%3A%2F%2Fwww.givingwhatwecan.org%2Fblog%2Ffour-things-you-already-agree-with-effective-altruism)
{{< /hint >}}

Here are four ideas that you probably already agree with. Three are about your values, and one is an observation about the world. Individually, they each might seem a bit trite or self-evident. But taken together, they have significant implications for how we think about doing good in the world.

![Women in Uganda holding bales of insecticide-treated bednets provided by the Against Malaria Foundation, one of Giving What We Can's Top Charities.](https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/wYjMsKsEkDPgHeAbS/nbbvuynsnhzvyu7shir9 "Women in Uganda holding bales of insecticide-treated bednets provided by the Against Malaria Foundation")

The four ideas are as follows:

1.  **It's important to help others** — when people are in need and we can help them, we think that we should. Sometimes we think it might even be morally required: most people think that millionaires should give something back. But it may surprise you to learn that those of us on or above the median wage in a rich country are [typically part of the global 5%](https://www.givingwhatwecan.org/get-involved/how-rich-am-i)[\[1\]](#fnnmf8yn1l9i) — maybe we can also afford to give back too.
2.  **People**[\[2\]](#fn29y9eszyin9) **are equal** — everyone has an equal claim to being happy, healthy, fulfilled and [free](http://www.dictionaryofobscuresorrows.com/post/23536922667/sonder), whatever their circumstances. All people matter, wherever they live, however rich they are, and whatever their ethnicity, age, gender, ability, religious views, etc.
3.  **Helping more is better than helping less** — all else being equal, we should save more lives, help people live longer, and make more people happier. Imagine twenty sick people lining a hospital ward, who’ll die if you don’t give them medicine. You have enough medicine for everyone, and no reason to hold onto it for later: would anyone really choose to arbitrarily save only *some* of the people if it was just as easy to save *all* of them?
4.  **Our resources are limited** — even millionaires have a finite amount of money they can spend. This is also true of our time — there are never enough hours in the day. Choosing to spend money or time on one option is an implicit choice [not to spend it on other options](https://en.wikipedia.org/wiki/Opportunity_cost) (whether we think about these options or not).

I think that these four ideas are all pretty uncontroversial. I think it seems pretty intuitive that we should help people in need if we can; that we shouldn’t arbitrarily preference some groups of people over others; that we would prefer to help more people if given the option; and that we don’t have infinite time and money.

In fact I’d go further — I’d say that we’d feel pretty uncomfortable trying to [defend the alternative positions](https://en.wikipedia.org/wiki/Reversal_test) if we were talking to someone, namely:

1.  Helping others in need isn’t morally required, important, or even that good
2.  It’s OK to value people differently based on arbitrary differences like race, gender, ability etc.
3.  It doesn’t matter if some people die even if it doesn’t really cost us anything extra to save their lives
4.  We have unlimited resources

See what I mean?

We don't have infinite money, so we always need to choose which worthy cause to support.

![](https://res.cloudinary.com/cea/image/upload/f_auto,q_auto/v1/mirroredImages/wYjMsKsEkDPgHeAbS/g1aoagy0u623kdyfasxk)

So if we agree that these four ideas embody important values — and I think that they do — then there are big implications for how we should think about doing good. In fact, it means that the way we typically think about doing good is wrong.

In order to be true to these values, we need to think about how we can help the most people with our limited resources.

This is important, because there are [some causes](https://www.givingwhatwecan.org/cause-areas) where we can make a big impact for a small amount of money. In fact the best options are [much, much better than the average](https://80000hours.org/articles/effective-or-not/) — sometimes hundreds of times better. That might mean the difference between helping one person, and helping hundreds of people _for exactly the same amount of time or money_.

Because a charity chosen at random _is almost certainly not making as big an impact as the_ [_most effective charities_](https://www.givingwhatwecan.org/best-charities-to-donate-to-2022) (and let’s face it, many causes we choose to support tend to be the result of either random chance, or systemic factors that mean we’re only exposed to certain causes).

And this matters, because if we don’t choose well, then we’re either not giving people equal consideration (that is, implicitly discriminating against some groups of people), or we’re not helping as many people as we can (that is, allowing extra people to suffer or die, even though we could potentially help them).

So, at first, every worthy cause — from cancer research, to climate justice, to animal sanctuaries, to preventing [easily treatable but unpronounceable](https://www.givingwhatwecan.org/charities/unlimit-health) diseases in places that we'll probably never visit — should be on the table... *except* that we also think it's better to help more people and we understand that we don’t have the resources to help everyone. So we should first focus on the causes where we can help the most people for our limited time and money, **not just on those that we happen to have already heard about**.

Trying to be cause-neutral can be a really hard thing to do. Most people have first-hand experience of loss: I’ve lost two relatives to leukaemia; watched as the disease consumed their bodies and the pain meds fogged their minds; lived through the shared grief of their passing. It’s entirely reasonable that this makes us want to donate to organisations trying to solve the specific problem or cure the particular disease that has robbed us of our loved ones. We’re empathetic creatures, and we don’t want other people to experience the same suffering, or for their loved ones to experience the same grief.

But if we care about treating *people* equally, we should also care about treating their experiences equally. There’s not a really good reason that I should prefer averting the death, disability, and suffering caused by a particular disease (like leukaemia) any more than I should care about suffering caused by malaria, tuberculosis, traffic accidents, or anything else. What matters is that lives are cut short, parents are deprived of their children, people are living in pain. Caring about equality means treating *all* death and suffering as a tragedy, not just that caused by specific diseases that we — by cruel twists of fate that thrust them into our field of view — happen to notice.

Making these decisions is really, really hard. But there is a set of thinking tools we can use to help us. This way of thinking is called [effective altruism](http://www.ethics.org.au/on-ethics/blog/january-2016/effective-altruism). It's basically the same as regular altruism (in that it emphasises the importance of helping other people) — the word 'effective' just means trying to think clearly about how your actions can help the _most people_, or do the _most good_.

I see effective altruism as a way of being able to better live up to **values that we already hold**.

This way of thinking is applicable to any way that we might want to do good — whether that be agitating for political change, choosing where we donate our money, or how to have a big impact with our careers.

In a world where there are so many worthy causes we could work on, it gives us a way out of decision paralysis, by systematically looking for ways to do the most good with our limited time and money.

It asks us to face up to some hard choices. But remember, we’re making these choices anyway, whether we think about them or not. So even though it might be hard to not donate to something that seems really important — whether for personal reasons, or because you’re convinced by a charity’s marketing pitch — remember that you’re always trading off against other worthy causes.

Here’s an example of this in action. The typical person in the UK donates around £6,700 ($9,600USD)[\[3\]](#fntye9jj85m1) over the course of their working lifetimes. For this money we could fund the distribution of [around 1,900 mosquito nets](https://www.givingwhatwecan.org/charities/against-malaria-foundation)[\[4\]](#fnvv86mon9xl9) (likely preventing around 200children from becoming really, really sick from malaria[\[5\]](#fnje9b322xb2), and probably [saving at least two or three](https://www.givingwhatwecan.org/blog/bednets-have-prevented-450-million-cases-of-malaria) [_lives_](https://www.givingwhatwecan.org/blog/bednets-have-prevented-450-million-cases-of-malaria)). However, most voluntary donations go to domestic medical charities.[\[6\]](#fnia7l87p9cwk) The UK’s National Health Service considers it good value to save one *year* of healthy life for around £25,000. [\[7\]](#fnsp4h7xnqvm)It’s highly unlikely that a domestic charity will beat this figure, so the typical donor’s impact is going to be many, many times less than it could otherwise be. Remember, **just because we don’t think about these choices, doesn’t mean that they’re not there.**

So please, think carefully about these ideas — the importance of altruism, equality, and doing as much as we can with our scarce resources — and see if they make sense to you.

If they do, then the next time you think about how to make the world a better place, give voice to these values by thinking _effectively_, as well as altruistically.

**Some resources for learning more about effective altruism:**

- [What is Effective Altruism?](https://www.givingwhatwecan.org/what-is-effective-altruism)
- This really quick [summary of effective altruism](http://web.archive.org/web/20171111054827/http:/www.ethics.org.au/on-ethics/blog/january-2016/effective-altruism)
- The [Wikipedia entry on effective altruism](https://en.wikipedia.org/wiki/Effective_altruism)
- [Doing Good Better](http://www.effectivealtruism.com/) by Will MacAskill
- The [Effective Altruism Handbook](http://effective-altruism.com/ea/hx/effective_altruism_handbook_now_online/)

**Some actions you can take that we think are really effective**

- [Donate](https://www.givingwhatwecan.org/best-charities-to-donate-to-2022) to a charity recommended on the basis of its impact and cost-effectiveness — check out our [Top Charities](https://www.givingwhatwecan.org/best-charities-to-donate-to-2022), and [GiveWell’s recommendations](http://www.givewell.org/charities/top-charities). If you’d like to support charities that increase the welfare of non-human animals effectively, check out [Animal Charity Evaluators](http://www.animalcharityevaluators.org/).
- [Pledge](https://www.givingwhatwecan.org/pledge) to keep donating over the course of your lifetime — 8,438 people (and counting) have pledged to donate 10% of their lifetime income to the most effective charities, and 798 have made pledges of 1% or more of their income for a custom period.
- Choose a career that’s really high-impact by reading career advice from [80,000 Hours](https://80000hours.org/)
- Start a [chapter or discussion group](https://www.givingwhatwecan.org/get-involved/groups) in your local area or at your university, and get other people interested in making a bigger difference

[^1]: This handbook is also accessible as a Google Doc version [here](https://docs.google.com/document/d/1ju83W3yFqvUBvsSrHadjEwazNBphCTmLWd-xZkVArBM/edit?usp=sharing)
[^2]: Our goal is to introduce people to some of the core principles of effective altruism, to share the arguments for different problems that people in effective altruism work on, and to encourage you to think about what you want to do on the basis of those ideas.

    We also tried to give a balance of materials that is in line with the (significant) diversity of views on these topics within effective altruism.
    In drawing up the curriculum, we consulted community members, subject matter experts, and program facilitators.

    We think that these readings are interesting and give a good introduction, but we hope that you engage with them critically, rather than taking them all at face value. Once you’ve read this curriculum, we encourage you to explore other EA writings (e.g. on this [wiki](https://forum.effectivealtruism.org/topics)).

[^3]: You can see the global distribution of local EA groups on the [Effective Altruism Forum](https://forum.effectivealtruism.org/groups), which lists groups in over 70 countries.
[^4]: The less neglected an issue, the more the best opportunities will have been taken, so the harder it will be for an additional person to make an impact.

    In fact, there are [good reasons to expect](https://web.archive.org/web/20220728174703/https://www.fhi.ox.ac.uk/law-of-logarithmic-returns/) that returns to investment in an issue are roughly logarithmic.

    Logarithmic returns imply that if 10 times more has been invested in one cause compared to another, then additional resources will achieve about 1/10 as much progress.

    If the two issues are equally important, and then an additional person working on the more neglected one will have ten times the impact.

[^5]: From 2010 to 2019, US Federal Funding for Health Security is estimated at $141 billion. We judge that 55% of this was spent on what could arguably prevent future pandemics. For example, 4% was spent tackling the ongoing ebola epidemic, which provided infrastructure for potential other pandemics. However, 17% was spent on chemical and nuclear radiation threats in a way unlikely to affect future pandemic spread.

    141 billion \* 0.55 = 79 billion

    Annualized over the ten year period is $8 billion per year.

    [Federal funding for health security in FY2019](https://www.liebertpub.com/doi/10.1089/hs.2018.0077) Watson, Crystal, et al., Health security 16.5 (2018): pages 281-303. [Archived link](https://web.archive.org/web/20200305190440/https://www.liebertpub.com/doi/10.1089/hs.2018.0077), accessed 5 March 2020.

    [Open Philanthropy](https://web.archive.org/web/20220708181859/https://www.openphilanthropy.org/research/biosecurity/) also identifies other foundations and philanthropists working on the topic prior to the COVID pandemic, which we believe total under $100 million in funding.

    Crawford, director of the Costs of War project, calculates US spending on Counter-Terrorism from 2001-2022 to be $5.8 trillion.

    5.8 trillion / 20 years = $290 billion per year.

    [United States budgetary costs of Post-9/11 wars](https://watson.brown.edu/costsofwar/files/cow/imce/papers/2021/Costs%20of%20War_U.S.%20Budgetary%20Costs%20of%20Post-9%2011%20Wars_9.1.21.pdf) Crawford, Neta C., Watson Institute for International & Public Affairs, Brown University, 2021. [Archived link](https://web.archive.org/web/20220726160700/https://watson.brown.edu/costsofwar/files/cow/imce/papers/2021/Costs%20of%20War_U.S.%20Budgetary%20Costs%20of%20Post-9%2011%20Wars_9.1.21.pdf), accessed 26 July 2022

[^6]: Deaths from terrorism from 1970-2020 were approximately 456,000. This is from the Global Terrorism Database 2020, accessed 11 August 2022.

    Note that Our World in Data says "The Global Terrorism Database is the most comprehensive dataset on terrorist attacks available and recent data is complete. However, we expect, based on our analysis, that longer-term data is incomplete (with the exception of the US and Europe). We therefore do not recommend this dataset for the inference of long-term trends in the prevalence of terrorism globally."

    This means the source above is likely an undercount of confirmed terrorism deaths; however, even if we assume deaths have been at the same level as the highest recorded decade (2010-2020) since 1970, the total deathtoll would still only be 1.2 million; far less than deaths due to pandemics.

    Deaths from COVID-19:

    The Economist estimated cumulative excess deaths due to COVID-19 were 21.47m as of June 2022, and this amount is still rising.

    You can see this data and their model through Our World in Data (archived page, retrieved 28 July 2022).

    We see this as the best current estimate of COVID-19’s total death toll. The number of confirmed deaths is lower, at around 6 million, but this excludes deaths that were indirectly caused or weren’t reported. The Economist’s methodology compares excess deaths to the seasonal average, to estimate in total how many additional people died, and adjusts for underreporting.

    Deaths due to pandemics and terrorism are both heavy tailed, so past death rates will typically understimate the magnitude of the risk.

    For instance, it’s possible that terrorists could set off a nuclear weapon in a large city, which might kill over 1 million people. This didn’t happen over the last fifty years, but would have been the main driver of the death toll if it had. And likewise, there could have been a pandemic much worse than COVID-19 or HIV/AIDS in the last 50 years.

    The key question then becomes whether the historical record is a greater undercount of the risk for terrorism or for pandemics (i.e. whether terrorism deaths are more heavily-tailed than pandemic deaths).

    It seems plausible that the worst case scenario from pandemics is worse than for terrorism. There’s nothing to rule out the emergence of a pandemic that’s more infectious than COVID-19, but with a fatality rate of 10-50%, or worse. And there seem to be more near-misses in the historical record.

    So, the problem of missing tail events in the sample may well be worse for pandemics than terrorism. Indeed, the most plausible way for terrorism to kill 1+ billion people is probably via causing a pandemic.

    Given that terrorism receives ~100x more funding than pandemic prevention, while pandemics seem to have caused 10-100x more deaths historically, the corrections would need to be very heavily in favour of terrorism in order for the current allocation of resources to seem more balanced.

    The above analysis was just in terms of the number of deaths, since that’s an important yet relatively measurable metric. Deaths due to both pandemics and terrorism also produce important indirect costs, and a fuller comparison would attempt to consider the relative scale of each.

[^7]: “40.1 million [33.6 million–48.6million] people have died from AIDS-related illnesses since the start of the epidemic.”

    Global HIV & AIDS statistics — Fact sheet UNAIDS, 2022. Archived link, accessed 11 August 2022.

[^8]: Open Philanthropy is a foundation inspired by effective altruism. They first funded the Johns Hopkins Centre for Health Security (CHS) in 2016. This was followed by several other large grants, including one for $16m in 2017 and another for $19.5m in 2019.
[^9]: 38,659 volunteers, as of 7 July 2022. 1Day Sooner
[^10]: Before COVID-19, the number of people living on less that $1.90 per day had decreased to 689 million in 2017. However, estimates now point to the first rise in the extreme poverty rate since 1998, leading to an estimated 731 million people now living on less than $1.90 per day.

    UN SDG 1 - End poverty in all its forms. UN Statistics, 2022. Archived link, accessed 26 July 2022.

    These estimates have been adjusted for the fact that money goes further in poor countries (purchasing parity). There are many complications to the estimates, but it’s clear that hundreds of millions of people live at near subsidence levels of income. See “how accurately does anyone know the global distribution of income?” if you’d like to learn more.

[^11]: The US poverty line for 1 person is an annual income of $13,590.

    13,590 / 365 = $37.23 per day.

    This is 20x the international poverty line of $1.90, which is adjusted for purchasing parity.

    According to the 2019 census, full-time workers aged 25-65 with a college degree or higher earned a median of $74,000 per year.

    $74,000 / 365 = $202.7 per day

    $202 / 1.9 = 107x.

    According to SmartAsset, a single person household earning $74,000 pre-tax and living in New York, receives about $53,000 post-tax.

    According to Giving What We Can’s calculator, a post-tax income of $53,000 puts you in the top 1.3% of income globally.

[^12]: The UK’s National Institute for Health and Care Excellence recommends spending up to £30,000 per quality-adjusted life year (QALY) gained, where the intervention is reliable.

    “Above a most plausible ICER of £30,000 per QALY gained, advisory bodies will need to make an increasingly stronger case for supporting the intervention as an effective use of NHS resources” Methods for the development of NICE public health guidance. UK National Institute for Health and Care Excellence, September 2012. Archived link, accessed July 28, 2022.

    It’s typical in global health to say that saving one life is equivalent to 30 QALYs. Source: World Bank (Box 1.1)

    This amounts to a cost of saving a life of 30 x £30,000 = £900,000 = $1.1 million.

    In the US, different global agencies estimate “the value of life”, and use this figure in the prioritization of different spending projects. The Federal Emergency Management Agency estimated the value of life at $7.5 million in 2020. This estimate has fluctuated based on the context. For example, the US Department of Transport estimated the value of life to be between $5.2 million and $13.0 million in 2014.

[^13]: GiveWell's estimates of the cost to save a life have varied over time (depending on their research, and which opportunities are available), but have typically fallen within $2,500 to $7,500. In 2021, GiveWell estimated that $5500 spent on distributing insecticide-treated bednets will save one life in expectation.

    You can see their most up-to-date estimates in their full cost-effectiveness analysis: How We Produce Impact Estimates GiveWell, July 2022. Archived link, accessed 28 July 2022.

[^14]: “More than 110,000 donors have trusted GiveWell to direct their donations. Together, they have given over $1 billion to the organizations we recommend. These donations will save over 150,000 lives and provide cash grants of over $175 million to the global poor.”

    About GiveWell, GiveWell, July 2022. Archived link, accessed 28 July 2022.

[^15]: “When Wave launched in Senegal, our average transfer would have cost 3-5x more if done via the largest existing mobile money system. Multiplied by our millions of monthly active users, that comes out to a savings of over $200 million every year, … around 1% of Senegal’s GDP.”

    Working at Wave is an extremely effective way to improve the world. Ben Kuhn, July 8 2021. Archived link, accessed 26 July 2022.

[^16]: Conversation: "Our best end-to-end trained Meena model achieves a… SSA [Sensibleness and Specificity Average] score of 72%... our SSA score of 72% is not far from the 86% SSA achieved by the average person.” Towards a Conversational Agent that Can Chat About…Anything. Adiwardana et. al., Google, 28 January 2020. Archived link, accessed 28 July 2022.

    Math: The graphs in the attached article show Google’s Minerva accurately answers over 50% of “high school math competition-level problems”. Other state-of-the-art models were achieving less than 10% accuracy.

    Minerva: Solving Quantitative Reasoning Problems with Language Models. Dyer et. al, Google, 30 June 2022. Archived link, accessed 28 July 2022.

    Jokes: Google’s AI PaLM can provide explanations for jokes never seen before, including jokes nowhere on the internet. For example:

    “Joke: Did you see that Google just hired an eloquent whale for their TPU team? It showed them how to communicate between two different pods!

    Explanation: TPUs are a type of computer chip that Google uses for deep learning. A ‘pod’ is a group of TPUs. a ‘pod’ is also a group of whales. The joke is that the whale is able to communicate between two groups of whales, but the speaker is pretending that the whale is able to communicate between two groups of TPUs”

    Pathways Language Model (PaLM): Scaling to 540 Billion Parameters for Breakthrough Performance. Narang et. al., Google, 4 April 2022. Archived link

    Images: Example images from OpenAI’s Dall-E 2 can be seen here.

    Coding: Section 3.1 in Salesforce’s ‘A Conversational Paradigm for Program Synthesis‘ research paper about CodeGen, their AI tool turning human instructions into code, outlines that CodeGen achieves a 75% HumanEval score, meaning it can solve 75% of the programming challenges described with normal human language in the HumanEval set.

[^17]: It’s difficult to estimate the number of researchers focused on a certain topic since it’s hard to define the topic in the first place, many researchers work on multiple topics, and it’s hard to know the bar for ‘being a researcher’. So these numbers should be understood as estimates to within a factor of three or so, and they could be out by an order of magnitude depending on some interpretations of the question.

    In 2020, 87,000 authors published AI research on arXiv. The 2020 Global AI Talent Report from Element AI estimates there are even more people than this working on AI development globally, with 155,000 people labelled on social media as working in AI research or engineering. However we expect some working in AI engineering to not be working on engineering new advancements in AI. We have taken the smaller estimate of 87,000 and roughly halved it for an estimate of 40,000.

    In 2021, Gavin Leech estimated that 270 to 830 FTE people worked on AI Safety. However, the upper end of the range of this estimate is based on what we think is an overly broad notion of what constitutes research into AI alignment, and much of the sum was driven by adding up time from lots of researchers spending a small fraction of their time on safety research; while our aim is to quantify the number of researchers focused on AI safety.

    AI Watch attempted a headcount of AI Safety researchers, which found 160 notable researchers who have worked on AI Safety. This includes many people who have not published on AI safety in over a year, whereas for the estimate of 87,000 above, all had published in the last year. On the other hand, the bar for being a ‘notable’ researcher might be higher than publishing in arXiv.

    Our final estimate is 300 researchers focused on AI safety.

[^18]: In 2018, 9.56 billion farm animals were slaughtered for meat in the US. This number has likely risen since then. This includes 9.16 billion chickens; 237 million turkey; 125 million pigs; 34 million cattle and 2 million sheep. Source: visualization at Our World in Data, using data from the UN Food and Agriculture Organization.
[^19]: In 2021, approximately 6.5 million animals passed through animal shelters in the US. In 2011, this number was 7.2 million. Assuming a steady decline, this means in 2018 there were approximately 6.7 million animals passing through animal shelters.

    9.56 billion / 6.7 million = 1427 times as many animals in factory farms.

    Pet Statistics. American Society for the Prevention of Cruelty to Animals, 2021. Archived link, accessed August 2021.

[^20]: Animal shelter spending:

    Andrew Rowan calculated $5 billion of funding to the top 3000 animal shelter organizations in the US in 2018, published in his paper “Cat Demographics & Impact on Wildlife in the USA, the UK, Australia and New Zealand: Facts and Values” Rowan et. al. (2020), Journal of Applied Animal Ethics Research, pages 7–37.

    Andrew Rowan confirmed the data behind these calculations in correspondence with us.

    Farm animal advocacy funding:

    Research from Open Philanthropy published here finds the following funding for farm animal advocacy groups in 2018:

    $32.3 million for Established US groups (PETA, PCRM, HSUS, ALDF, ASPCA)
    $32.6 million for new, major US-based groups (CIWF, WAP, RSPCA, HSI)
    $32.2 million for all other US groups
    32.3 + 32.6 + 32.2 = $97.1 million

[^19]: 106.5 million hens are now in cage-free housing in the US alone as of May 2022, as reported by the USDA Egg Markets Overview, compared to 17 million in 2016. We believe another 100 million have become cage-free in Europe as a result of Open Wing Alliance’s work, although this number is harder to attribute to them specifically.

    In addition, advocates have now secured corporate pledges that, if implemented, should cover more than 500 million hens alive at any time.

[^20]: After engagement with GFI, the US government announced a $10 million grant to create a center of excellence in cellular agriculture at Tufts University. The UK’s independent National Food Strategy recommended a £125 million investment in alternative protein research and innovation. Source: GFI Year in Review 2021 (page 3)
[^23]: The full timeline of forecasts can be found on Metaculus.
[^24]:
    The number I’ve pre-loaded into the calculator ($32,140USD) is the [median personal income](https://en.wikipedia.org/wiki/Personal_income_in_the_United_States) for someone 25 or older in the US, but of course you should substitute in your own income, country, and household details. Some other generic values you could use for comparison are [$24,062USD](https://www.givingwhatwecan.org/blog/four-things-you-already-agree-with-effective-altruism#) ([median personal income](https://en.wikipedia.org/wiki/Personal_income_in_the_United_States) for people in the US over 18), [£21,100GBP](https://www.givingwhatwecan.org/blog/four-things-you-already-agree-with-effective-altruism#) ([median personal income](http://www.theguardian.com/money/2014/mar/25/uk-incomes-how-salary-compare) of the sixth decile in the UK), or [$59,900AUD](https://www.givingwhatwecan.org/blog/four-things-you-already-agree-with-effective-altruism#) ([median salary of full-time workers](http://www.abs.gov.au/ausstats/abs@.nsf/mf/6310.0) in Australia).
    [^25]:

    I’ve used the word ‘people’ in this article for convenience, but of course if you’re concerned with the welfare of non-human animals, then you could read this as ‘animals’ or ‘sentient beings’ etc. — the arguments all still apply

3.  **[^](#fnreftye9jj85m1)**

    Charities Aid Foundation, _UK Giving 2014_, p12 <[https://www.cafonline.org/docs/default-source/about-us-publications/caf-ukgiving2014](https://www.cafonline.org/docs/default-source/about-us-publications/caf-ukgiving2014)\>. Arrived at by multiplying the typical amount donated each month (£14) by 12 (to get yearly donations) and then by 40 (number of years someone is typically active in the workforce)

4.  **[^](#fnrefvv86mon9xl9)**

    This is using the figure of around $5 per bednet distributed by the Against Malaria Foundation, which is correct for most places in which they operate. Some countries (such as DRC) are more expensive to work in, but even at the higher figure of $7.50 per net, you could still distribute 1,000 bednets.

5.  **[^](#fnrefje9b322xb2)**

    White, MT. "Costs and cost-effectiveness of malaria control interventions ..." 2011. [https://malariajournal.biomedcentral.com/articles/10.1186/1475-2875-10-337](https://malariajournal.biomedcentral.com/articles/10.1186/1475-2875-10-337)

6.  **[^](#fnrefia7l87p9cwk)**

    Charities Aid Foundation, _UK Giving 2014_, p14 [https://www.cafonline.org/docs/default-source/about-us-publications/caf-ukgiving2014](https://www.cafonline.org/docs/default-source/about-us-publications/caf-ukgiving2014)

7.  **[^](#fnrefsp4h7xnqvm)**

    [https://www.nice.org.uk/news/blog/carrying-nice-over-the-threshold](https://www.nice.org.uk/news/blog/carrying-nice-over-the-threshold)
