+++
title = '3. Radical Empathy'
date = 2024-02-03T01:12:26+08:00
draft = false
weight = 30
+++

# Radical empathy

> _“The question is not, Can they reason?, nor Can they talk? but, Can they suffer? Why should the law refuse its protection to any sensitive being?”_

– Jeremy Bentham (1789)

During this chapter we explore who our moral consideration should include. We focus especially on farmed animals as an important example of this question this week.

Key concepts from this chapter include:

- **Impartiality:** helping those that need it the most (only discounting people according to location, time, and species if those factors are in fact morally relevant).
- **The importance (and difficulty) of considering unusual ideas:** Society’s consensus has been wrong about many things over history (e.g. the sun circling the Earth, the morality of slavery). In order to avoid making similar mistakes, we need to be open to considering unusual ideas and moral positions, while still thinking critically about the issues and acting cooperatively with others.

_This work is licensed under a_[ _Creative Commons Attribution 4.0 International License_](https://creativecommons.org/licenses/by/4.0/) _._

# Radical Empathy

_This version of the essay has been lightly edited. You can find the original[here](https://web.archive.org/web/20200220220116/https://www.openphilanthropy.org/blog/radical-empathy)._

---

One theme of our work is trying to help populations that many people don't feel are worth helping at all.

We've seen [major opportunities to improve the welfare of factory-farmed animals](https://www.openphilanthropy.org/blog/initial-grants-support-corporate-cage-free-reforms), because so few others are trying to do it. When working on [immigration reform](https://www.openphilanthropy.org/focus/us-policy/immigration-policy), we've seen big debates about how immigration affects [wages for people already in the U.S.](http://davidroodman.com/blog/2014/09/03/the-domestic-economic-impacts-of-immigration), and much less discussion of how it affects immigrants. Even our interest in [global health and development](http://www.openphilanthropy.org/focus/global-health-and-development) is fairly unusual: Many Americans may agree that [charitable dollars go further overseas](http://www.givewell.org/giving101/Your-dollar-goes-further-overseas), but prefer to give domestically because they so strongly prioritize people in their own country compared to people in the rest of the world.[^1]

The question "Who deserves empathy and moral concern?" is central for us. We think it's one of the most important questions for effective giving.

Unfortunately, we don't think we can trust conventional wisdom and intuition on the matter: History has too many cases where entire populations were dismissed, mistreated, and deprived of basic rights for reasons that fit the conventional wisdom of the time but today look indefensible. Instead, we aspire to radical empathy: working hard to extend empathy to everyone it should be extended to, even when it is unusual or seems strange to do so.

To clarify the choice of terminology:

- "Radical" is intended as the opposite of "traditional" or "conventional." It doesn't necessarily mean "extreme" or "all-inclusive"; we don't extend empathy to everyone and everything (this would leave us essentially no basis for making decisions about morality). It refers to working hard to make the best choices we can, without anchoring to convention.

- "Empathy" is intended to capture the idea that one could imagine oneself in another's position, and recognizes the other as having experiences that are worthy of consideration. It does not refer to literally feeling what another feels, and is therefore distinct from the "empathy" critiqued in [Against Empathy](https://smile.amazon.com/Against-Empathy-Case-Rational-Compassion-ebook/dp/B01CY2LCZI/) (a book that acknowledges the multiple meanings of the term and explicitly focuses on one).

## Conventional wisdom and intuition aren't good enough

In [The Expanding Circle](https://smile.amazon.com/dp/B005646EGY/ref=dp-kindle-redirect?_encoding=UTF8&btkr=1), Peter Singer discusses how, over the course of history, "The circle of altruism has broadened from the family and tribe to the nation and race ... to all human beings" (and adds that "the process should not stop there"). [^2] By today's standards, the earliest cases he describes are striking:

> At first, [the] insider/ outsider distinction applied even between the citizens of neighboring Greek city-states; thus there is a tombstone of the mid-fifth century B.C. which reads:

> _This memorial is set over the body of a very good man. Pythion, from Megara, slew seven men and broke off seven spear points in their bodies ... This man, who saved three Athenian regiments ... having brought sorrow to no one among all men who dwell on earth, went down to the underworld felicitated in the eyes of all._

> This is quite consistent with the comic way in which Aristophanes treats the starvation of the Greek enemies of the Athenians, starvation which resulted from the devastation the Athenians had themselves inflicted. Plato, however, suggested an advance on this morality: he argued that Greeks should not, in war, enslave other Greeks, lay waste their lands or raze their houses; they should do these things only to non-Greeks. These examples could be multiplied almost indefinitely. The ancient Assyrian kings boastfully recorded in stone how they had tortured their non-Assyrian enemies and covered the valleys and mountains with their corpses. Romans looked on barbarians as beings who could be captured like animals for use as slaves or made to entertain the crowds by killing each other in the Colosseum. In modern times Europeans have stopped treating each other in this way, but less than two hundred years ago some still regarded Africans as outside the bounds of ethics, and therefore a resource which should be harvested and put to useful work. Similarly Australian aborigines were, to many early settlers from England, a kind of pest, to be hunted and killed whenever they proved troublesome. [^3]

The end of the quote transitions to more recent, familiar failures of morality. In recent centuries, extreme racism, sexism, and other forms of bigotry ⁠— including slavery ⁠— have been practiced explicitly and without apology, and often widely accepted by the most respected people in society.

From today's vantage point, these seem like extraordinarily shameful behaviors, and people who were early to reject them ⁠— such as early abolitionists and early feminists ⁠— look to have done extraordinary amounts of good. But at the time, looking to conventional wisdom and intuition wouldn't necessarily have helped people avoid the shameful behaviors or seek out the helpful ones.

Today's norms seem superior in some respects. For example, racism is much more rarely explicitly advocated (which is not to say that it is rarely practiced). However, we think today's norms are still fundamentally inadequate for the question of who deserves empathy and moral concern. One sign of this is the discourse in the U.S. around immigrants, which tends to avoid explicit racism but often embraces nationalism ⁠— excluding or downplaying the rights and concerns of people who aren't American citizens (and even more so, people who aren't in the U.S. but would like to be).

## Intellect vs. emotion

I sometimes hear the sentiment that moral atrocities tend to come from thinking of morality abstractly, losing sight of the basic emotional basis for empathy, and distancing oneself from the people one's actions affect.

I think this is true in some cases, but importantly false in others.

People living peaceful lives are often squeamish about violence, but it seems that this squeamishness can be overcome disturbingly quickly with experience. There are ample examples throughout history where large numbers of "conventional" people casually and even happily practiced direct cruelty and violence to those whose rights they didn't recognize. [^4] Today, watching the casualness with which factory farm workers handle animals (as shown in [this gruesome video](https://www.youtube.com/watch?v=mYwhSX3ltJg)), I doubt that [people would eat much less meat if they had to kill animals themselves](http://michaelpollan.com/articles-archive/an-animals-place/). I don't think the key is whether people see and feel the consequences of their actions. More important is whether they recognize those whom their actions affect as fellow persons, meriting moral consideration.

On the flip side, there seems to be at least some precedent for using logical reasoning to reach moral conclusions that look strikingly prescient in retrospect. For example, see Wikipedia on [Jeremy Bentham](https://en.wikipedia.org/wiki/Jeremy_Bentham), who is known for basing his morality on the straightforward, quantitative logic of utilitarianism:

He advocated individual and economic freedom, the separation of church and state, freedom of expression, equal rights for women, the right to divorce, and the decriminalising of homosexual acts. [My note: he lived from 1747-1832, well before most of these views were common.] He called for the abolition of slavery, the abolition of the death penalty, and the abolition of physical punishment, including that of children. He has also become known in recent years as an early advocate of animal rights.

## Aspiring to radical empathy

Who deserves empathy and moral concern?

To the extent that we get this question wrong, we risk making atrocious choices. If we can get it right to an unusual degree, we might be able to do outsized amounts of good.

Unfortunately, we don't think it is necessarily easy to get it right, and we're far from confident that we are doing so. But here are a few principles we try to follow, in making our best attempt:

**Acknowledging our uncertainty.** For example, we're quite unsure of where animals should fit into our moral framework. My own reflections and reasoning about philosophy of mind have, so far, seemed to indicate against the idea that e.g. chickens merit moral concern. And my intuitions value humans astronomically more. However, I don't think either my reflections or my intuitions are highly reliable, especially given that many thoughtful people disagree. And if chickens do indeed merit moral concern, the amount and extent of their mistreatment is staggering. With [worldview diversification](https://www.openphilanthropy.org/blog/worldview-diversification) in mind, I don't want us to pass up the [potentially considerable opportunities to improve their welfare.](https://www.openphilanthropy.org/blog/initial-grants-support-corporate-cage-free-reforms)

I think the uncertainty we have on this point warrants putting significant resources into [farm animal welfare](https://www.openphilanthropy.org/focus/us-policy/farm-animal-welfare), as well as working to generally avoid language that implies that only humans are morally relevant.[^5]

That said, I don't feel uncertain about all of our unusual choices. I'm confident that differences in geography, nationality, and race ought not affect moral concern, and our giving should reflect this.

**Being extremely careful about too quickly dismissing "strange" arguments on this topic.** Relatively small numbers of people argue that [insects](http://reducing-suffering.org/do-bugs-feel-pain/), and even [some algorithms run on today's computers](http://petrl.org/), merit moral concern. It's easy and intuitive to laugh off these viewpoints, since they seem so strange on their face and have such radical implications. But as argued above, I think we should be highly suspicious of our instincts to dismiss unusual viewpoints on who merits moral concern. And the stakes could certainly be high if these viewpoints turn out to be more reasonable than they appear at first.

So far I remain unconvinced that insects, or any algorithms run on today's computers, are strong candidates for meriting moral concern. But I think it's important to keep an open mind.

**Exploring the idea of supporting deeper analysis.** [Luke Muehlhauser](https://www.openphilanthropy.org/about/team/luke-muehlhauser) is currently exploring [^6] the current state of research and argumentation on the question of who merits moral concern (which he calls the question of moral patienthood). It's possible that if we identify gaps in the literature and opportunities to become better informed, we'll recommend funding further work. In the near future, work along these lines could affect our priorities within [farm animal welfare](https://www.openphilanthropy.org/focus/us-policy/farm-animal-welfare) ⁠— for example, it could affect how we prioritize work focused on [improving the treatment of fish](https://www.openphilanthropy.org/focus/us-policy/farm-animal-welfare/global-aquaculture-alliance-fish-welfare-best-practices). Ideally, our views on moral patienthood would be informed by an extensive literature drawing on as much deep reflection, empirical investigation, and principled argumentation as possible.

**Not limiting ourselves to the "frontier," because widely recognized problems still do a great deal of damage.** In our work, we often find ourselves [focusing](https://www.openphilanthropy.org/focus) on unconventional targets for charitable giving, such as farm animal welfare and potential risks from advanced artificial intelligence. This is because we often find that opportunities to do disproportionate amounts of good are in areas that have been, in our view, relatively neglected by others. However, our goal is to do the most good we can, not to seek out and support those causes which are most "radical" in our present society. When we see great opportunities to play a role in addressing harms in more widely-acknowledged areas ⁠— for example, in the [U.S. criminal justice system](https://www.openphilanthropy.org/focus/us-policy/criminal-justice-reform) ⁠— we take them.

_This work is licensed under a[Creative Commons Attribution 4.0 International License.](https://creativecommons.org/licenses/by/4.0/)_

---

[^1]:
    For example, according to data from Giving USA, only approximately 4% of US
    giving in 2015 was focused on international aid. (Reported by Charity
    Navigator here.) ︎

[^2]: Page 120. ︎
[^3]: Pages 112-113.
[^4]: Many examples available in the first chapter of [The Better Angels of Our Nature](https://www.amazon.com/dp/B0052REUW0/ref=dp-kindle-redirect?_encoding=UTF8&btkr=1).
[^5]:
    As a side note, it is often tricky to avoid such language. We generally use
    the term "persons" when we want to refer to beings that merit moral concern,
    without pre-judging whether such beings are human and also without causing too
    much distraction for casual readers. A more precise term is ["moral patients."](https://web.archive.org/web/20200220220116/http://www.ncbi.nlm.nih.gov/pubmed/19254100)

[^6]:
    You can find his final report
    [here](https://www.openphilanthropy.org/research/2017-report-on-consciousness-and-moral-patienthood/).

{{< rawhtml >}}

<html>
  <head>
    <script type="module" src="https://js.withorbit.com/orbit-web-component.js"></script>
  </head>
  <body>
    <orbit-reviewarea color="blue">
      <orbit-prompt
        question="What does 'radical empathy' mean?"
        answer="
- **Radical**: the opposite of conventional. Not necessarily extreme or all-inclusive. 
- **Empathy**: you can imagine yourself in another's position, and acknowledge their experiences as worthy of consideration. Not literally feeling what they feel."
      ></orbit-prompt>
      <orbit-prompt
        question="How do we know that our current moral norms aren't perfect?"
        answer="In recent centuries, extreme forms of sexism, bigotry, and racism have been considered respectful positions to hold."
      ></orbit-prompt>
      <orbit-prompt
        question="'Moral atrocities come from thinking of morality abstractly, losing sight of empathy'. What are the arguments for and against?"
        answer="(Do think of your own answers) 
- **Against**: There are ample examples throughout history where large numbers of “conventional” people casually and even happily practiced direct cruelty and violence to those whose rights they didn’t recognize"
      ></orbit-prompt>
      <orbit-prompt
        question="What's a good reaction to hearing strange arguments about morality, e.g. that insects merit moral concern?"
        answer="To not be dismissive right away and give them a fair judgement, as the stakes could be high if we are wrong (and we sometimes are!)."
      ></orbit-prompt>
    </orbit-reviewarea>
  </body>
</html>

{{< /rawhtml >}}

# Moral progress and "Cause X"

This is a linkpost for [https://www.youtube.com/watch?v=VH2LhSod1M4&list=PLwp9xeoX5p8P_O5rQg-SNMwQOIvOPF5U2&index=3](https://forum-bots.effectivealtruism.org/out?url=https%3A%2F%2Fwww.youtube.com%2Fwatch%3Fv%3DVH2LhSod1M4%26list%3DPLwp9xeoX5p8P_O5rQg-SNMwQOIvOPF5U2%26index%3D3)

_The effective altruism community has grown tremendously since it began in 2009. In the opening keynote of EA Global: San Francisco 2016, Toby Ord and Will MacAskill discuss this history and consider what might happen in the movement's future._

## **Transcript: Toby Ord and Will MacAskill's Opening Keynote at the EAG San Francisco 2016**

_Starts at 2:22._

#### **The most important conversation of my life**

Hello Effective Altruism Global. I say this every single year and every single year it’s true. Welcome to the largest gathering of the Effective Altruism Community that the world has ever seen. It's my absolute delight to introduce the conference on the past, present, and future of effective altruism. I'm going to introduce Dr. Toby Ord, who will talk about the past of effective altruism before talking, myself, about what's happening at the moment and what the future of effective altruism might look like.

It's my absolute delight to introduce Toby because there's no one in the world who's had a bigger positive impact on my life than he has. I met Toby in the spring of 2009 in Oxford. I'd had an idea for the Ph.D. thesis and my supervisor said, "Oh, if you're interested in that, you've got to talk to Toby." And so you might think, well, two Oxford philosophy graduate students meeting in the spring. The venue might be this really wonderful location. It might look something like this. As many of you know, the most important conversation in my life actually happened in a graveyard. Now, this is an actual gravestone from the graveyard where we spoke, though it made something of an exaggeration. That was in my college in Oxford. And it's really a little bit more scenic, though there are still a lot of dead people there. I met Toby and it is at a time of quite extreme moral turmoil for me. I was very influenced by the ideas of Peter Singer and the previous summer they'd spent that summer fundraising for Care International. I spent all day, every day talking about extreme poverty and how much good we could do if we just chose to spend some of our money to fight global poverty. But what I'd found coming to Oxford is that all the academics I spoke to - there's a lot of hand-wringing. A lot of people accepted these ideas, but very few people were actually putting them into action. And that's why when I met Toby, I was completely blown away. We met up, it was meant to be for an hour, and that conversation turned into five hours. And if you've ever met Toby and know of his amazing ability to talk, basically at length forever, you will know that that is no surprise. Though I wish it could have gone into the wee hours of the morning. He told me all sorts of weird ideas. He told me about this thing called a quality-adjusted life here. He told me about intestinal worms. He told me about the quantified impact of all the different foodstuffs, some meat products you could buy or not, and how damaging they were in terms of animal welfare. He told me he was concerned about this thing called existential risk and at the time I thought he was literally insane. But most of all, he told me about the commitment that he'd made to give away most of his income over the course of his life. And at the time, he was actually still a graduate student. He was just living on GBP 9,000, saving GBP 2,000 and donating a further GBP 2,000. I planned to give away most of that. And had this idea for Giving What We Can, an organization that would encourage as many people as possible to give 10% of their income to the most effective charities. At that point, I was just completely on board. I dropped all of my other projects just so that I could focus on this as much as I could. Happily, we co-founded Giving What We Can six months later. And since then, I've just really never looked back. It's my absolute delight to introduce Toby to talk about the history of Effective Altruism. As I've said, there's no one who's had a more positive impact on my life. If it hadn't been for that chance meeting with him back in 2009, I'd probably still be working on the philosophy of language. It'd be in some dusty library somewhere, and my life would completely suck. With that note, here's Toby Ord to talk about the history of Effective Altruism. Here you go, Toby.

###

#### **The Scientific Revolution**

Thanks, Will. It's hard to know what to say after that introduction. Actually, if I hadn't met Will, I don't think all of you would be here at the moment. He's done a huge amount to actually get Effective Altruism running, also with what we can in those early days, which I'll explain in a moment. To really situate Effective Altruism in its history, I think it makes sense first to really take a step back from this graveyard discussion and the foundation of Giving What We Can and to think about the history of ideas.

The first really big idea that's useful to give us some context is the scientific revolution. In the 1600s in Europe, various scientific greats such as Copernicus, Galileo, Newton, and this fashionable gentleman, Francis Bacon, who took those ideas and really synthesized them to help set up the rural society and really get science moving. The really interesting thing about the scientific revolution is that up until that point, the idea of intellectual progress wasn't really there. People in the Middle Ages, and even the early Renaissance, were looking back to the past. The whole narrative was about how the Greeks knew so much, and the Romans knew a little bit less, and then in the Dark Ages and the Middle Ages they knew less and less. And they were clinging to and trying to preserve the knowledge from the past, which was seen as a diminishing supply. And when people wanted to know the answer to something, they would try to look it up in Aristotle rather than go out and find out the answer themselves.

The scientific revolution really changed that narrative to be looking forward rather than back and creating a method for the systematic creation of knowledge. At this point, we got the idea of the central role of mathematics and understanding the world and the central role of experimentation as well. And it is still our best method of finding the truth. A hundred years later, we started to see some applications of this outside of natural science. In Europe, we had the enlightenment. And this was the application of both reason and evidence to various things in society. And you'll start to see how this could be connected to effective altruism. It created the fields such as sociology, economics, and law, so it got into the social sciences. And perhaps most importantly, it involved rethinking political structures. These were the ideas of, say, liberty, egality, fraternity that led to the French Revolution overthrowing the absolute monarchy. Also the ideas behind the Declaration of Independence. And it also led to an end to unquestioned authority. That includes both political authority from the divine right of kings, and also an end to authority from the old masters, authority from Aristotle, and so forth. They challenged these ideas and tried to see whether they were really correct. So how does effective altruism fit in with those two big ideas?

Well, one way to think about it is that effective altruism is the pursuit of the good as the scientific revolution was the pursuit of the truth. Another way perhaps to think about it. How does it interact with enlightenment? Well, the enlightenment involved rethinking the best political systems to have, whereas effective altruism re-thinks the best actions, both personal actions and also perhaps larger government actions such as how best to run an aid program or something like that, as opposed to how best to structure society. That's two major threads. A third major thread in the history of ideas, which is really relevant to effective altruism, is utilitarianism. And this really got out of the gates with Bentham in 1780 when he published an Introduction to the Principles of Morals and Legislation. This was an amazing document. He was a legal scholar in Britain, and he created utilitarianism and this greatest happiness principle that the end of all legislation should be to create the greatest happiness in society. And he then immediately applied it to doing that. He aimed to create a thoroughly utilitarian setup of legislation (he didn't get all the way there) and to radically improve public policy. And here is just a number of the things that happened (and remember the date in 1780) that were included in this [book]. He advocated for individual and economic freedom, separation of church and state, and equal rights for women in 1780. The rights of divorce, the decriminalization of homosexuality, the abolition of slavery, the abolition of the death penalty, the abolition of corporal punishment, and respecting animal welfare. And so we still don't even have all of these things today. But the types of things that he was deducing from these principles actually look a lot like some of the effective altruist ideas. Many of these have become commonplace, but it was an example of really trying to use reason and evidence in order to push things forward. His work was extended and developed and strengthened by John Stuart Mill and Henry Sidgwick. And then much more recently there was a lot of work by Peter Singer in the 1970s, where his focus wasn't on state action but on individual action. He made very strong and compelling cases for personal action on poverty and animal welfare.

###

#### **How does Effective Altruism fit?**

How does effective altruism fit into that? Well, effective altruism is not utilitarianism. It's a much broader church than that. It allows for many diverse views about what makes someone's life go well. It doesn't have to be just happiness. And also about many other things mattering as well, such as equality between people or rights or many other aspects about morality. The main similarity, as I see them, between this utilitarian movement and the effective altruism movement is that there was a focus on going out and helping others, not just on keeping your hands clean and not doing any wrong. It was about actively going out and doing good. There was also a real focus on scale. If something was 10 or 100 times bigger, they really took that seriously and made it of central importance. And involved being willing to question the status quo.

###

#### **Taking medicine seriously**

Here are another couple of things taking us closer to the present. And I think this is really interesting. In the history of medicine, the biggest thing I think happened in the late 1800s, was when they applied the scientific method to medicine. This was, as you'll know, 200 years after the scientific method had been developed. And this was the first time that they actually tried to find out how to improve health, rather than just messing about basically or respecting authority. The famous names Ignaz Semmelweis, John Snow, Louis Pasteur, Robert Koch. They developed the germ theory of disease, which led to the saving of, I guess, hundreds of millions of lives, at least, probably billions of lives. Really radical improvements as soon as they started applying science to medicine. And then another big breakthrough was the application of priority setting, which was the first time that people were trying to actually improve health as much as possible. To say, we want our population to be healthier, rather than less healthy. We'll actually prioritize based on how cost-effective these things are so that with our limited budget, we produce as much health as possible.

Key moments

- 1968: the development of the quality-adjusted life year
- 1999:the establishment in the UK of the National Institute for Clinical Excellence, which tried to do this priority setting for health, was really exciting and led to much better health outcomes.

Really similar story, interestingly, for global poverty. In the 1950s, aid, as we know it, began, both in terms of government and in terms of NGOs. And then the scientific method was applied quite a bit later. There was actually a long period with aid where the discussions were largely people from the armchair having disputes. So, for example, there's a famous one on ben nets, from malaria. Would it be the case that if they charged a small amount of money instead of giving them away for free, would that mean that there was more uptake and people who then respected the value of it and wouldn't use it as a fishing net or some other kind of bad use? There's a lot of back and forth about this, but all from the armchair. And then people eventually decided, why don't we just find out? Why don't we apply our best method for seeking truth to this question and get serious about it and just actually find out the answer?

And that happened. They found out in that case that actually you're better off giving them away for free. There's no more argument about that now because people actually just worked out the answer. In the 1990s, a lot of that happened. In 2002, IPA was established - Innovation and Property Action. In 2003, J-PAL, and then Priority Setting came in at a similar time. These ideas of actually trying to improve the lives of people in poor countries as much as possible, trying to say, “Why don't we do the things which are 100 times more effective? Why are we doing something that only helps 100 as much as it could, when there are still these really great opportunities to be done?” The World Development Report 1993 was a pivotal moment for Dean Jamison and Chris Murray. And then the DCP project, WHO Choice, and then in 2007, Givwell was established. In 2008, they gave their first recommendations, trying to help individual donors make decisions based on evidence when it comes to development and also other areas. 2009, Giving What We Can. That’s the huge sweep of ideas and how it brings us to the present day.

###

#### **Giving What We Can**

But now I want to take a step back and just tell you a bit more personal side of things. This is the story of setting things up at Oxford. It's not the whole story of how the kind of most recent part of effective altruism came to be. But I thought you'd appreciate the bits that I was there for on the ground and can speak the most to. In 2005, I was studying for a BPhil degree at Oxford. There's this infamous examinations period where in the Oxford winter, we kind of isolate ourselves for 14 weeks and write a whole lot of essays. And that was basically the whole assessment. And one of these essays, I did. I looked at the list of topics and saw this interesting topic about global poverty. In fact, it was called, “ought we to forego a luxury whenever we can thereby enable someone's life to be saved.” It sounded a bit like your answer was obviously yes. But then if you think about it and how it applies to your life, you see that it means that perhaps you can never have any luxuries because every single time you should help people in poorer countries instead. I thought about this a lot. I read Peter Singer, and Peter Unger and they’re really excellent writings that were there. And I'd always taken this seriously and wanted to do something about global poverty. But it'd never been that central to me. And I had a couple of weeks just looking at these questions and I had to really confront them and really think about them. And seeing these other people paving some of the way for me there was very valuable and maybe think that yeah, I should do this. I should make this a central part of my life. I made a commitment to donate most of my money over my life and to live on a limited income. And I talked about that a lot with my wife. And then in 2006, I decided that I needed to set up some kind of organization to help other people do this too. People had contacted me saying, I want to join you in doing this. And I needed some way of getting that to work. And I had the idea for an organization that would involve both giving more and giving more effectively. But I didn't have all the pieces of exactly how to set it up. Over the next couple of years, I iterated on this. I kept thinking about it, kept taking it to other people in Oxford, and talked to everyone who had listened to me about these topics. I got lots of feedback, and kept improving the ideas. And at some point, they actually had to finish my Ph.D. as well. And that was a bit of a distraction. But then shortly after handing in my Ph.D., a couple of weeks later, I got this email saying I should meet this Will Crouch chap. And all I knew about him at that point was that he was studying the same degree I had studied, the BPhill and that he was going to be wearing a tweed jacket, so I'd recognize him. So, he brought me into this graveyard at his college. And I met, finally, a really kindred spirit who was really excited by this project and was interested in all these ideas that we had. In fact, as well as the ones he mentioned, we're already talking about career choice and counterfactuals and how they could be relevant in career choice at that point. As Ben Todd has said, he's going to be saying that's not quite as important as we first thought. So, I'd be interested to see what he has to say about that. And then with Will present, things really rocketed it along. We just got together, spent all of our time on this, and really pushed it forward to the launch a few months later. We had this launch - here are a few memories.

That's Alan Fennick from SCI, our first recommended charity, who's here today, and who is thanking my wife and me. And there are various people in the audience who are still around, still part of effective altruism. In this picture, there's Ben Todd from 80,000 hours. There's Pablo Stafforini from CEA. Michelle Hutchinson, [from] Giving What We Can and now the Oxford Institute for Effective Altruism. And I think that is Will, back when his hair was a little bit longer. And this really took off when we launched this. We weren't sure what the reception would be. There was a flood of media interest - here are a few clippings. And a lot of people thought, “This is never really going to take off, isn't it?” You know, they were excited to talk to me and I thought it was an interesting story. But they kept saying, “No one's really going to do this, are they?” And we had 23 people at that point - our founding members, who had taken this 10% pledge, including I think it may be about a quarter of them are here at E.A. Global. More people wanted to join. I got to the dining table and started sending out forms to people so they could get the information and sign up. Our membership started growing very rapidly. It's about 90% annual growth over that period, taking us to about 100 times as many members as we had just six and a half years ago, almost 2000 members. In fact, a really amazing moment was when I was in Seattle at a meeting where we were rethinking the disability-adjusted life year, the DALY, and changing the definition and improving it. And I noticed that at a meeting of about 20 people, one-quarter of the people who are making this decision were Giving What We Can members. It's both a grassroots movement, but it also has a lot of support from people who are really at the heart of cost-effectiveness and priority setting in the world.

This is a chart of the amount of money pledged, both these things I find really humbling, to see how much it's grown, how the initial skeptics were wrong, and how many people have joined, and going to actually put their money where their mouth is in terms of helping the world to both give more and give more effectively, getting this multiplicative benefit between the two. For example, if you give ten times more and give it to a place that is ten times as effective, then having a hundred times the impact with your giving, so many people have joined with this.

A little bit later, in 2011, 80,000 hours was launched by Will and Ben. It involved this radical rethinking of how ethical careers should work. The initial focuses were on the impact of your career, which believe it or not, one else was looking at. They were just looking at don't do harm, basically, rather than actually doing good with your career. Or at least largely, also at the counterfactuals and on the idea of earning to give was a kind of radical new idea that we were pushing. This brought many new people from Oxford into this mix of ideas, and there's a really exciting time. Here's (something) to embarrass Ben- here’s their early logo. In fact, something that not many people would know here is that 80,000 hours was originally called High Impact Careers. And something that fewer of you would know was that in between the two, it was briefly 70,000 hours. And then at some point, we gave another 10,000 hours.

###

#### **The Centre for Effective Altruism (CEA)**

And now that we had these two different organizations, in this cluster of ideas and people working on them and trying to think about whether we could set up other things to kind of broaden this portfolio, we set up something called the Center for Effective Altruism. And when we were coming up with a name for this organization, we ended up naming this wider movement. We weren't actually sure if the name was really going to get used very much, but we had a long series of discussions and eventually settled on effective altruism. And what's quite amazing to me now is that was less than five years ago, that the name effective altruism was coined. The roots of effective altruism go back further than that, but it's quite interesting that it's such a recent name that we've all been united under. CEA was an umbrella organization for these different projects and an incubator for new projects, involving, Given What We Can, 80,000 hours, the life you can save, Animal Charity Evaluators, Global Priorities Project, and EA Outreach. Some of them found that they only needed the incubation for a while, we spun them out, and other ones are still with us.

In that summer, I thought I'd give you a few photos. We didn't have any office space, so we approached the university. Michelle tried to work out how to get some office space for us, and the only place you could find over the summer was in her college, Exeter. Here are Michelle and Holly working, and what you can't quite see from there is where they were working. We're on a balcony above an old medieval hall, and we had this strip about four meters wide by ten meters long, and that was our office. We also had various meetings and retreats trying to organize the community of people in Oxford interested in effective altruism, getting to talk about a lot of things. This is a debate that we had on the grounds of a castle in Wales. We also continued our academic work, writing papers on the moral importance of cost-effectiveness, and contributing back to the priority-setting community, such as J-PAL and economics, the WHO. In 2014, we had our first academic conference called Good Done Right at Oxford. Here are a couple of photos. That’s Derek Parfit, my old Ph.D. supervisor, who actually has a whole lot of really proto-EA ideas, and ideas that are quite foundational. I'll get to one at the end. Here he's giving a talk about population ethics to the audience there.

Now that's a bit of the Oxford story, but let's zoom out a little bit more. There were many things happening further afield as well at the same time. One of them was GiveWell founded in 2007, the first charity recommendations in 2008. Initially, they were looking at multiple different areas such as education in New York City for disadvantaged kids as well as global poverty. Over the years, they realized that actually these ones helping people in America couldn't really keep up in terms of effectiveness and that they really had to make a decision to just focus on global poverty because that was where they could do so much more to help people. In 2011, they allied with Good Ventures. There was a really major transition for Give Well, meaning that they were both grassroots helping advice organizations, but also advising this really large fund that was really based on EA principles. Also, set up what became the Open Philanthropy project, an arm of GiveWell in collaboration with Good Ventures, looking at bigger questions outside of global poverty, re-extending the set of areas they were looking at, but trying to include various things that could be really high impact in other areas. Another really exciting development, I think.

###

#### **Rationalism**

There's also the rationalism community. The aims of the rationalist community were helping people to have more accurate beliefs about the world and helping people to better achieve those aims, whatever their aims are. The first is called theoretical rationality and the second is practical rationality. There was also a lot of questioning of conventional wisdom. Two major parts of this were Overcoming Bias, a blog with Robin Hanson and Eliezer Yudkowsky in 2006, and LessWrong in 2009. I was working at the Future of Humanity Institute in Oxford and was a sponsor of both of these and I was involved in that as well. In fact, it was actually, I was the person who's responsible for telling them about GiveWell and connecting that together, which turned out to be a marriage made in heaven for the LessWrong folk who wanted to get quantitative about charity. There was lots of discussions there about existential risk and a growing amount of discussion over the years about what they were calling optimal philanthropy or what we think of as effective giving.

Another thread was a utilitarianism community, particularly around a site called Felicifia from 2006. Lots of interesting ideas were discussed there, including questions like “Should we give now or should we invest the money and give later when you can give more?” and lots of questions that are central to effective altruism. Starting in 2006, some of the key people from that are here as well. They were looking to apply utilitarian principles into action more than just doing theory. Many more organizations as well, particularly as time has gone on, too many to list.

Let's finally go back to the big picture again. One question that I hear occasionally and I think it's a good question and a challenging question is “Why hasn't effective altruism happened already?” If these ideas were of God, which involved sometimes radical rethinking of our role in society, saying that it's not good enough to have a life where you don't do any harm, but instead there's something important going out and doing good in the world and using reason and evidence to work out how to do that good rather than using your intuition or following what everyone else is doing. If we're really right about that and it's quite different from common sense, what's going on there? How do we explain that? Why would we be right and other people be wrong or how does that work? Maybe the challenge is that if this is such a good idea, why hasn't it already happened?

I think there are actually some very good answers to that. Firstly, there have been people with EA. mindset over history. John Wesley is an example. Jeff Kaufman did some good work finding cases of him directly advocating, only to give centuries ago. Jeremy Bentham, as already mentioned, is another good example. Things have changed recently to allow the community to develop around this. One is education. There's much more mathematical and scientific literacy in the world, so people have the tools needed to understand these concepts. The internet has been huge. It's enabled people with this mindset to find each other and build a community. It's the type of thing that labels communities where even if only one percent of the people find this really interesting and passionate, they don't find it hard to find each other in a pre-internet world, but now it's been able to build this global community. Data, there's much more information about what's effective now, which really helps things get moving. One thing I think is really interesting, not many people might be aware of, is impact. It's only relatively recently that we've been able to do so much. Here are some more details on these different cause areas.

Global poverty. We've only really been able to help since the 1950s. Prior to that, state-based aid was actually imperial aid through the British Empire, prior to World War II. NGOs didn't exist. Instead, it was missionaries that you could fund. But, it was a lot less clear that that was actually going to help people in poor countries. Scientific evidence based on effectiveness has only really been around since the 1990s. Actually, Give Well and Give What We Can, seem to have risen almost as soon as they possibly could. Animal welfare, factory farming, has only become widespread in the 1960s. It was only a decade later when Peter Singer made his rallying cry to say that this was really problematic and we needed to take a whole lot of personal action in order to stop it. Existential risk. People see my poster in the poster session. I explain this, but the background, natural risks, are actually quite small, less than a tenth of a percent per century. That's still significant, but it was in the 1950s and 60s with the development of thermonuclear weapons and stockpiles of them that the USA and the USSR produced, that mankind first developed the power to really destroy itself. Then this anthropogenic risk of extinction arose, which was much greater than the natural risk. As soon as that happened, there was an anti-nuclear community in my parents' generation that was part of it. I'm sure many of your parents are part of it. There was a passion for this. Concern about existential risk is a natural generalization of that to say, well, it's not just nuclear weapons we care about. We care about the next technology like that that could threaten us as well. Let's try to be proactive about it and think things through, trying to minimize those risks to the flourishing of humanity. Since the 1950s, we've entered this new era of opportunities for ethical impact. Good cost-effectiveness information has only really come in since the 1990s and in some fields like animal welfare. It's still hard to get good cost-effectiveness estimates. There just really hasn't been much time for common sense about ethics to catch up. I really think that this is the way of the future here. Common sense will relatively quickly shift. It already has in the charitable world. GiveWell did a whole lot of really good work on this, getting people to focus less on cost-effectiveness ratios. In fact, to pretty much dismiss them. It’s now not okay to talk about cost-effectiveness ratios, as in the amount spent on overhead ratios because that's just not relevant. What you really care about is the impact. I think common sense is changing and I think this is actually the way of the future.

Finally, where does this look like it's heading? I'm optimistic about it. Derek Parfit, who you saw earlier, in his magnum opus, Reasons and Persons, which is probably the most influential work of philosophy in the 20th century, has this final chapter just right at the end of this incredibly long and difficult book, which is called How Both Human History and the History of Ethics Maybe Just Beginning. In that chapter, it's just a few pages, he introduces and really advocates for the idea of existential risk as a really big concern for humanity and that it may be one of the most important moral issues. I thought it was a very interesting and powerful idea when I read it. He thinks it's so important because human history may be only just beginning. We talked a bit about the history of ideas, but potentially many more thousands of years to come and many more great things that humanity will achieve and that's why I thought it was really important to keep it alive. He also thought that the history of ethics may be only just beginning. He pointed out that actually, almost all ethics that had been done prior to the 20th century was in a religious context with people in a very focused way looking back again to the things that had been said thousands of years ago and trying to reinterpret them, rather than rethinking some of the principles and trying to be a bit more revisionary and forward-thinking about it. He pointed out that only until the 1960s, there were only about a dozen people who had ever made a non-religious approach to ethics in their life's work. You could count them on your fingers, a number of people who even tried that. It's only very recently that people have been thinking about this seriously, pushing forward, trying to understand the world, now placing it, what we should do about it and how we should care for the future and each other. He says that he's very optimistic about the future of ethics and I am too, particularly about practical action with that. He's a Giving What We Can member as well and has been an inspiration to me.

###

#### **The Past Year**

Thank you, Toby. After he talked about the history, I'm going to talk a little bit about what we've achieved over the last year, the future potential of effective altruism, and then how that relates to the conference today and tomorrow. In terms of the present, what’s been happening over the last year? One big thing was the reception. The books by Peter Singer and myself were just launched just before last year's Effective Altruism Global. We've now really seen how they've been received. It's actually been pretty remarkable how positive it was. I expected these ideas to be met with a lot of resistance, a lot of controversies, and a lot of people get annoyed by them. Actually, it's been really remarkably positive, in fact. There have been positive reviews from some people like Reed Hoffman, co-founder of LinkedIn, Tim Ferris of the Four-Hour Work Week, Nick Christoff, the New York Times journalist, Alexandra Wolfe from the Wall Street Journal, and even the CEO of the Gates Foundation, Sue Desmond-Hellmann as well, has become a promoter of these ideas. The reception overall has been remarkably positive, it's really been wonderful to see. Of course, as with all new ideas, there's been some criticisms as well, and also some of the views have been somewhat bizarre. This one, for example, on treehugger.com that is, you know, objects to the idea at quite some length of this book written by this professor of psychology, William McAllister, and goes on a length to talk about how much of an idiot William MacAllister is. I'm really happy that I didn't like that book because it sounds like it's just full of mistakes, but I am quite happy that now every mistake I make, I have someone to blame it on. I can be like, no, no, that was William McAllister's thing. He's a psychologist, they don't know anything.

The books have had a remarkable reception, but obviously what we care about is impact. But in terms of that, I think things have been even better again. When we look at the main effective altruist groups and how their impact measures have increased over the last year, it's really been pretty astonishing, and it's quite clear that we're experiencing something like exponential growth.

This is GiveWell. As you can see, the amount of money they're moving to the top of their commended charities is growing hugely, and this year they exceeded a hundred million dollars to their top charities. It's absolutely fantastic. That means 50,000 households have had their incomes double over the years as a result of direct cash transfers. Eight million bed nets have been distributed through the Against Malaria Foundation, and 15 million D-worming tablets have been distributed through SEI and Deworm the World. And that amounts to something like, obviously these are estimates, can't take cost, effectiveness estimates, literally, and so on, but given our best guesses, that means at least 10,000 lives have been saved, and that's really pretty phenomenal. Good work, GiveWell.

Other organizations have actually been in a similar story. You saw the growth chart for Giving What We Can. One thing to point out about that. We're now almost 2,000 members, and almost 800 million dollars pledged, yet to put that in context for the three years before Giving What We Can launch when Toby was talking about it, and he and I trying to get as many members as possible. Up until that point we had 23 members. Giving What We Can now get to that many members, over that many members every two weeks. It's an astonishing change in the kind of rate of growth. With 80,000 hours, it's just, you know, maybe the story is even more extreme, it's got this kind of hockey stick growth trajectory as well. There are now hundreds of people every year who are significantly changing their career plans in a way that they believe will do a lot more good on the basis of the advice that 80,000 hours is giving. And there are just so many organizations doing this. The Life You Can Save, which is Peter Singer and Charlie Bresler's organization, encourages people to make at least a 1% pledge to global poverty charities. In 2015, it raised over 1.5 million dollars, raising for effective giving, which encourages poker players to make a 2% pledge of their winnings and moved about $600,000. Animal charity Evaluators, which is the GiveWell for animal charities, moved over $800,000 to top charities. Apparently, in 2016, it's already done more than that. And Founders Pledge, a very new organization within the effective altruism community, encourages entrepreneurs to give 2% of their earnings on exit. 2% of the profit they make when their company exits to whatever charities they prefer. In just a year, they do over $100 million in legally binding pledges. In terms of the amount of money that we're raising, it's just really pretty astonishing, even compared to one year ago and certainly compared to just a few years ago.

And there's impact that we're having through other means as well in terms of outreach. Here are some other miscellaneous bits of impact. Charity Entrepreneurship launched a new organization, actually officially launched it just two days ago called Charity Science Health. And I'm super excited about this because this is the first non-profit directly focused on global poverty to have come out of the effective altruism community. And that's some Joey and Kate just going to developing countries, figuring out what are the things that are most important that we could potentially turn into an extremely effective charity and just going out and doing that. It's been incredibly impressive. Similarly with Wave, which has had incredible growth. This is a for-profit organization, again, set up by someone in the effective altruism community and hiring many people in the community, which makes the remittances cheaper for people in the US to send the remittances back to East Africa. And this is potentially huge. I mean, the global flows of remittances are about $500 billion every year. And again, they've been experiencing astonishing growth. They're now one of the top senders of remittances in the US to East Africa. And they've saved their users over a million dollars already. .Impact launched the Students For High Impact charity. That's an organization that's kind of developed effective altruism as a curriculum for people while they're still in school. We've held four EA Global X events, and there’s seven more to come, including just next week there's going to be one in Nairobi, which I'm particularly excited about. We now have over a hundred local groups all around the world.

It's just tremendous growth within effective altruism. And over the last year, more than anything, I mean, these are all kind of quantitative, the facts and figures, but more than anything, effective altruism is starting to feel like a real thing. I now talk to journalists and they're like, oh yeah, yeah, that was a really good article on earning to give as if this concept has just been around there forever. People now write academic articles, you know, debating and criticizing effective altruism again as if it's a kind of real institution. People donate to the center, just not even because they’re involved with effective altruism, but just because they think it's a good thing to donate to in the same way as someone might donate to Oxfam or to the United Way. It really feels like this is a year when effective altruism is entering the mainstream. It's starting to become a concept that many, many people are very familiar with.

###

#### **The Future of EA**

That's been tremendously exciting. And it raises the question, well, if so, what's going to happen in the future? Let's just engage in a thought experiment and imagine that this sort of exponential growth, which means, you know, it's been about doubling every 18 months, supposing that trend were to continue. What would the world look like in 10 years time, for example? Well, if so, if it continued for the next 10 years, Giving What We Can would have a hundred billion dollars in pledges, and it would become the de facto biggest foundation in the world. GiveWell in the Open Philanthropy project would be moving more than 10 billion dollars a year to the most effective charities. And around the world, hundreds of thousands of people would self-identify as part of the effective altruism community. And, you know, let's indulge further, what if we think 20 years out, what would the world look like then? Well, if it continues for the next 20 years, well, perhaps cause prioritization would become, rather than this very niche thing that it’s only really us that are really seriously thinking about that and a couple of small other organizations, perhaps it would become a major field of research. You could imagine politicians, prime ministers, and presidents, incorporating the ideas of effective altruism into the political platforms in which they stand. And ultimately, you could imagine the idea of effective altruism, the idea of using evidence from a reason to try and promote the welfare of all, to become just as common sense as the scientific method is common sense today. Perhaps you've still got some people debating it, but it's kind of far from the mainstream.

And so that's imagining if this kind of growth trend continues over the next decade, the next couple of decades. And, of course, we should think that this is just very unlikely. I mean, this would be huge, it'd be completely changing the world. But I think it's a real possibility now. I think we actually can think, “Wow, yeah, maybe we can achieve this.” Maybe over the long run, if we keep working on this, this actually is within our power. And it might well be that a significant fraction of the expected value of what we're doing today, as well as having this direct benefit, comes from this long-run potential to really change the mindset of people all around the world.

###

#### **Better allocation of resources**

And so it's worth thinking, well, if we did get to that sort of stage, where would the value be coming from? And so one thing, of course, is just better allocation of resources. Of the sort of causes that we think of today, that we think of as priority causes - global poverty, factually farming, global catastrophic risks. If we were able to get this sort of mindset change on such a large scale, these problems would start to look kind of trivial almost. I mean, to put this in context for extreme poverty, if we imagine that the top one billion wealthiest people, if over one year, they just kept their wealth at the same level. You're just taking an interest in that wealth, nothing more. No one's being made worse off than they were before. And that money will be distributed to the very poorest billion people in the world. You would double the income of all the poorest billion people in the world. That alone would eradicate extreme poverty. And that's just about people's mindset. That's about how people choose to spend their resources. And that's even the problem that perhaps requires the biggest amount of resources, which is global poverty.

When we look at factory farming, when we look at existential risks, are problems that really just are about people's attitudes. We don't need to have factory farms. We don't need to be taking risks with the long-run future of the human race. If we do have this power to change people's minds on this grand scale, well, we really have an astonishing ability to make the world a better place. But I think there's also a subtle and potentially even larger benefit that's worth thinking about, which is the potential to drive forward moral progress. If you look at the history of ideas, the history of the human race, in every single generation there have been huge moral atrocities that have been committed by the people of that generation that at the time just seemed completely normal. In every generation, people have been completely oblivious to the fact of how wrong some of their practices were.

For example, Aristotle spent his entire life dedicated to thinking about how to lead an ethical life, and it just didn't occur to him that maybe keeping slaves was the wrong thing to do. That's a pretty astonishing fact. He was one of the smartest people in the world at the time, spent all his time thinking about this, and was still oblivious.

But when we look at the history of the human race; when we look at atrocities like slavery, the deplorable treatment of foreigners, the subjugation of women, the persecution of people who aren't heterosexual, the persecution of animals today, what we see over and over again is how easy it is for people to be oblivious to serious moral problems.

###

#### **Moral progress**

It seems very unlikely that we've discovered all of the moral problems today. It seems very unlikely that we are the generation that figured it all out. Given this, what we should be thinking about is: What are the sorts of major moral problems that in several hundred years we'll look back and think, "Wow, we were barbarians!"? What are the major issues that we haven't even conceptualized today?

I will refer to this as Cause X.

I think you could argue that one of the most important aims of the effective altruism community is to discover this Cause X; to discover a cause that's one of the most important moral problems of our time, but that we haven't even clearly conceptualized yet. Cause X might be an idea that today seems laughable, but will seem obvious in the future just as ideas like animal welfare or existential risk were laughable 200 years ago. Or perhaps Cause X will be something that we are aware of today, but for bad reasons, we deprioritized.

Perhaps the most exciting or interesting way in which the EA community could have a huge positive impact on the world is if we can drive forward moral progress and figure out the problems, the Cause X, that we're not even aware of today.

###

#### **Effective altruism as an intellectual project**

And that takes us back to the day. The theme of this conference is effective altruism as an intellectual project. Of course, that's not all of this to effective altruism, but the focus of this conference. And it's the intellectual project of asking, how can we help others as much as possible? How can we do the most good? And in that sense, effective altruism, it's not an ideology, it's not a set of prescriptions, it's not a body of facts, it's not a set of recommended charities, it's not even a list of preferred causes. It's a methodology. It's a pursuit of a question. And that means we need to be constantly trying to, you know, revitalize ourselves, address this question, keep thinking about what the best ways of doing good are, what ways we might be wrong. And, you know, effective altruism is concerned with these intellectual issues, not because we're a bunch of nerds and because, you know, we're just interested in puzzles. Nor is it the case that we're just a bunch of jerks and we want to belittle causes that we don't like. But it's because we just care very deeply about the plight of others. We see there's a huge amount of suffering and injustice in the world, and we want to be able to help. And we know that if we just posture and assume that we know everything, well, that's not going to be the best way of helping. We just need to appreciate that we don't know what the best way of doing good is and we need to figure that out. And if you look at the history of improvements in a lot of people's lives, a lot of that is driven by intellectual progress. It was intellectual progress that allowed us to, you know, develop the scientific method, develop vaccines, eradicate smallpox that saved over 60 million lives, bring polio and measles close to eradication, make the world richer such that basically everyone in the world is far richer than humanity has ever been for most of its life. It's because of that intellectual progress that we've been able to have these achievements.

And when we look to the future, well, things are going to change a lot again. That means we need to constantly keep this flame of intellectual curiosity burning because circumstances and opportunities are going to be very different in five, or 10 years than they are now. And when that comes to today, there are these incredibly important questions that we need to address that might have huge potential. Can we use CRISPR to end malaria? Can we develop meat substitutes that just render people's desire for meat irrelevant and completely end the factory farming industry? Can we develop better forecasting methods so that we can better predict geopolitical events? These are the kind of cutting-edge intellectual and technological progress today and they have a huge potential if done correctly to make the world better.

So that's why the focus of this conference is on effective altruism as an intellectual project. And that's why I want to suggest that the kind of key thing to take with you through this conference is to think, well, what's the biggest, most important issue in which you still might be uncertain and which you might be very wrong? And in which case, I think what could you do? Who could you talk to? What talks could you go to that could potentially change your mind on that issue? And if you do see people who are changing their mind say, “Yeah. Wow. I've had this crucial consideration and I've realized that things are just radically different in terms of how I should evaluate my options than they were before.” You know, celebrate that. Applaud that because that's the most important thing. It’s the ability to change our minds in light of new evidence and to move on to maybe accept the beliefs that we found that we cherished, cause areas that we were really personally attached to, maybe they're not the best thing, maybe there are better ways of doing it. It's only by constantly learning, being able to constantly appreciate new ideas, new arguments, and new evidence by constantly learning and being willing to change our minds - that's the only way that we're going to be able to do the most good. Thank you.

_This work is licensed under a_[ _Creative Commons Attribution 4.0 International License_](https://creativecommons.org/licenses/by/4.0/) _._

# The Possibility of an Ongoing Moral Catastrophe (Summary)

This is a linkpost for [https://docs.google.com/document/d/18ZzC-WkDcWK-WPlIzKvDv83j8aBwSfdOxnZRmoio-zE/edit?usp=sharing](https://forum-bots.effectivealtruism.org/out?url=https%3A%2F%2Fdocs.google.com%2Fdocument%2Fd%2F18ZzC-WkDcWK-WPlIzKvDv83j8aBwSfdOxnZRmoio-zE%2Fedit%3Fusp%3Dsharing)

A few years ago, I made a outline of Evan G. Williams' [excellent philosophy paper](https://philpapers.org/rec/WILTPO-101), for a local discussion group. It slowly got circulated on the EA internet. Somebody recently recommended that I make the summary more widely known, so here it is.

The paper is readable and not behind a paywall, so I'd highly recommend reading the original paper if you have the time.

## Summary

**I. Core claim**

1. Assuming moral objectivism (or a close approximation), we are probably _unknowingly_ guilty of serious, large-scale wrong-doing (“ongoing moral catastrophe”).

**II. Definition: What is a moral catastrophe? Three criteria:**

1. Must be a _serious_ wrong-doing (closer to wrongful death or slavery than mild insults or inconveniences).
2. Must be large-scale (instead of a single wrongful execution, or a single man tortured)
3. Broad swathes of society are responsible through action or inaction (can’t be unilateral unavoidable actions by a single dictator).

**III. Why we probably have unknown moral catastrophes. Two core arguments:**

1.  **The Inductive Argument**
    1.  Assumption: It’s possible to engage in great moral wrongdoings even while acting in accordance to your own morals, and that of your society.
        1.  Basic motivation: an honest, sincere Nazi still seems to be acting wrongly in important ways.
        2.  It’s not relevant whether this wrongdoing is due to mistaken empirical beliefs (All Jews are part of a major worldwide conspiracy) or wrong values (Jews are subhuman and have no moral value).
    2.  Given that assumption in mind, pretty much every major society in history has acted catastrophically wrongly.
        1. Consider conquistadores, crusaders, caliphates, Aztecs etc. who conquered in the name of God(s), who they called _good_ and _just_.
        2. It’s unlikely that all of these people in history only _professed_ such a belief, and that all of them were liars instead of true believers.
        3. Existence proof: People can (and in fact do) do great evil without being aware of this.
    3.  Us having ongoing moral catastrophes isn’t just a possibility, but _probable_.
        1.  _We are not that different_ from past generations: Literally hundreds of generations have thought that they actually were right and had figured out the One True Morality
        2.  As recent as our parents’ generation, it was a common belief that some people have more rights than others because of race, sexuality etc.
        3.  We live in a time of moral upheaval, where our morality is very different from our grandparents’.
        4.  Even if _some_ generation would eventually figure out All of Morality, the generation that gets everything right is probably a generation whose parents gets _almost_ everything right.
2.  **The Disjunctive Argument**
    1.  Activists are not exempt. Even if all your pet causes come to fruition, this doesn’t mean our society is good, because there are still _unknown_ moral catastrophes.
    2.  There are so many _different_ ways that a society could get things very wrong, that it’s almost _impossible_ to get literally _everything_ right.
        1.  This isn’t just a minor concern, we could be wrong in ways that are a sizable proportion of how bad the Holocaust is.
    3.  There are many different _kinds_ of ways that society could be wrong.
        1.  We could be wrong about _who_ has moral standing.(eg. fetuses, animals)
        2.  We could be _empirically_ wrong about what harms or hurts people who morally matter (eg. religious indoctrination of children)
        3.  We could be right about _some_ obligations but not others.
        4.  We can act immorally in paying too much attention and using resources on false moral obligations (a la crusaders)
        5.  We could be right about what’s wrong and should be fixed, but wrong at how to _prioritize_ different fixes.
        6.  We could be right about what’s wrong, but wrong about what is and is not our _responsibility_ to fix. (eg. poverty, borders)
        7.  We could be wrong about the far future (natalism, existential risk)
    4.  Within each category, there are multiple ways to go wrong.
        1.  Further, some are mutually exclusive. Eg. Pro-lifers could be right and abortion is a great sin, _or_ fetuses don’t matter and it’s greatly immoral to deprive women of their freedom in eg. third trimester abortions.
        2.  Unlikely that we’re currently at the golden mean for all of these trade-offs.
    5.  Disjunction comes into play.
        1.  Even if you believe that we’re 95% right at each major issue, and there are maybe 15 of them, the total probability that we are right is maybe ~.95^15~=46% (LZ: Assumes independence)
        2.  In practice, 95% sure we’re right at each major issue seems way too confident, and 15 items too low.

**IV. What should we do about it?**

1. Discarded possibility: _hedging_. If you’re not sure, play it “safe”, morally speaking.
   1. Eg. even if you think farmed animals probably aren’t sentient, or sentience doesn’t morally matter, you can go vegetarian “just in case”
   2. This does NOT generally work well enough because it’s not _robust_ : as noted, too many things can go wrong, some in _contradictory_ directions.
2. **Recognition of Wrongdoing**
   1. Actively try to figure out which catastrophic wrongs we’re committing
      1. Research more into practical fields (eg. animal consciousness) where we can be critically wrong
      2. Research more into moral philosophy
         1. Critical: bad to have increased technological knowledge w/o increased moral wisdom
         2. imagine Genghis Khan w/nuclear weapons
      3. These fields _must_ interact
         1. Not enough for philosophers to say that animals are important _if_ they are conscious and for scientists to say that dolphins are conscious but don’t know if this is important...our society must be able to integrate this.
   2. Need marketplace of ideas where true ideas win out
   3. Rapid intellectual progress is _critical_.
      1. If it’s worth fighting literal _wars_ to defeat the Nazis or end slavery, it’s worth substantial material investment and societal loss to figure out what we’re currently doing wrong.
3. Implementation of improved values
   1. Once we figure out what great moral wrongs we’ve committed, we want to be able to make moral reparations for past harms, or at least stop doing future harms in that direction _as quickly as possible_.
   2. To do this, we want to maximize _flexibility_ in _material_ conditions
      1. Extremely poor/war-torn societies would be unable to make rapid moral changes as needed
      2. LZ example: Complex systems built along specific designs are less resilient to shocks, and also harder to change, cf. Antifragile.
      3. In the same way we stock up resources for war preparation, we might want to save up resources for future _moral_ emergencies, so we can eg. pay reparations, or at least quickly make the relevant changes.
         1. LZ: Unsure how this is actually possible in practice. Eg, individuals usually save by investing, and governments save by buying other government’s debt or by investing in the private sector, but it’s unclear how the world “saves” as a whole.
   3. We want to maximize flexibility in _social_ conditions
      1. Even if it’s materially possible to make large changes, society might make such changes very difficult, because inertia and conservatism bias.
      2. Constitutional amendments, for example, are suspect.

**V. Conclusion/Other remarks**

1.  **Counterconsideration One** : Building a society that can correct moral catastrophes isn’t the same as actually correcting moral catastrophes.
2.  **Counterconsideration Two :** Many of the measures suggested above to prepare for correcting moral catastrophes may themselves be evil. e.g. money spent on moral research could have instead been spent on global poverty, building a maximally flexible society might involve draconian restrictions on current people’s rights
3.  However, this is still worth doing in the short term.

{{< rawhtml >}}

<html>
  <head>
    <script type="module" src="https://js.withorbit.com/orbit-web-component.js"></script>
  </head>
  <body>
    <orbit-reviewarea color="blue">
      <orbit-prompt
        question="What is a moral catastrophe?"
        answer="**Serious**, **large-scale** wrong-doing by **broad swaths of society**."
      ></orbit-prompt>
      <orbit-prompt
        question="When the authors argue that we are unknowingly guilty of an ongoing moral catastrophe, what is the key assumption?"
        answer="We assume moral objectivism."
      ></orbit-prompt>
      <orbit-prompt
        question="What are the key arguments that we are unknowingly guilty of an ongoing moral catastrophe?"
        answer="
1. **The inductive argument**: A lot of people have engaged in great moral wrongdoings, even while acting in accordance to society's morals — hundreds of generations thought that they've figured out the One True Morality. 
2. **The disjunctive argument**: "
      ></orbit-prompt>
      <orbit-prompt
        question="What is the inductive argument for an ongoing moral castrophe?"
        answer="
- Lots of people have done wrong, while in accordance to society's morals. 
- Our parents' generation was wrong about race, sexuality etc. 
- Even if some generation would eventually figure out morality, the generation that gets everything right is probably a generation whose parents gets almost everything right."
      ></orbit-prompt>
      <orbit-prompt
        question="What is the disjunctive argument for an ongoing moral catastrophe?"
        answer="
- There are so many ways for a society to be wrong, e.g. who has moral standing, which moral obligations are valid, factual mistakes. 
- Even if we are 95% right about 15 issues, we are only ~.95^15~=46% right."
      ></orbit-prompt>
    </orbit-reviewarea>
  </body>
</html>

{{< /rawhtml >}}

_This work is licensed under a_[ _Creative Commons Attribution 4.0 International License_](https://creativecommons.org/licenses/by/4.0/) _._

# On "fringe" ideas

This is a linkpost for [https://theunitofcaring.tumblr.com/post/185847413171/what-do-you-think-about-the-more-fringe-parts-of](https://forum-bots.effectivealtruism.org/out?url=https%3A%2F%2Ftheunitofcaring.tumblr.com%2Fpost%2F185847413171%2Fwhat-do-you-think-about-the-more-fringe-parts-of)

_The Forum team published this with Kelsey's permission. We've slightly edited the original content, which you can find_[ \_ \_here\_\_](https://web.archive.org/web/20190701003844/https://theunitofcaring.tumblr.com/post/185847413171/what-do-you-think-about-the-more-fringe-parts-of) _._

## Question to the blog

> What do you think about the more fringe parts of EA?
>
> I get really angry seeing people call themselves EAs but then spending all of their time writing speculative essays on, say (to quote those I came across most recently), how actually wildlife conservation is bad because animals in the wild suffer. Like, it's fun to think about that, but my goals as an EA are very different than those of someone who thinks stuff like that is even comparable with global development or long-term sustainability.
>
> But I do wonder what your opinion is, since you do have a record of being sensible in evaluating ideas regardless of how fringe they are, which I really appreciate.

## Kelsey’s response

> One big formative influence on how I think about this is imagining that effective altruism had existed at various other moments in history. Would we have been doing any good, or would we have been too stuck in the assumptions of the time period?
>
> Would an effective altruist movement in the 1840s U.S. have been abolitionist? If we think we would have failed to stand up against slavery, what do we need to change, now, as a movement, to make sure we’re not getting similarly big things wrong?
>
> Would an effective altruist movement in the 1920s U.S. have been eugenicist? If we think we would have embraced a pseudoscientific and deeply harmful movement like the sterilization campaigns of the Progressive era, what habits of mind and thought would have prevented us from doing that, and are we actively employing them?
>
> I think that for effective altruism to be robustly good — to be a movement that would have done good even when embedded in societies that were doing great evil, or societies that were oriented around entirely the wrong questions, or a society that had a “do-gooder” consensus that was actually terrible — there are a bunch of things that have to be in place.
>
> Firstly, we have to actually be doing things that benefit the people who need it most. Last year, donations moved through GiveWell to top charities (not counting donations from Good Ventures) increased to $65 million. If that number wasn’t impressive, and wasn’t increasing, I would be worried that we were failing as a community. We need the reality check of being accountable for actual results. We need to actually do things.
>
> Next, we need to be continually monitoring for signs that the things we’re doing are actually doing harm, under _lots of possible worldviews_. That includes worldviews that aren’t intuitive, or that aren’t the way most people think about charity. If recipients aren’t happy, that’s an enormous potential warning sign. If our efforts increase suffering, even if it’s in some weird way that’s hard to take seriously, that’s a warning sign. If there are forces systematically ensuring we don’t hear from recipients, that’s a warning sign. Basically, we need to cast a really, really wide net for possible ways we’re screwing up, so that the right answer is at least available to us.
>
> Next, imagine someone walked into that 1840s EA group and said, ‘I think black people are exactly as valuable as white people and it should be illegal to discriminate against them at all,” or someone walked into the 1920s EA group and said, “I think gay rights are really important.” I want us to be a community that wouldn’t have kicked them out. I think the principle I want us to abide by is something like ‘if something is an argument for caring _more_ about entities who are widely regarded as not worthy of such care, then even if the argument sounds pretty absurd, I am supportive of some people doing research into it. And if they’re doing that research with the intent of increasing everyone’s well-being and flourishing as much as possible, then they’re part of our movement’.
>
> So that’s a bunch of broad movement-level principles about how I’d like effective altruism to work. I want us to be open to the idea that our society is very wrong about important things, I want us to be supportive of efforts to care about more, and I want us to be casting a really wide net for ways we could be going wrong. Finally, to make sure all of this work stays grounded enough that it can actually help people, I want all of the above to happen only in conjunction with growth in the resources we allocate to concrete priorities.
>
> In other words, at any given time, I hope most of our efforts are dedicated to doing solid, clearly important things — and at the same time, I hope we have space to hear out more speculative things, and specifically to hear out (1) arguments for caring about things we wouldn’t normally think to care about, (2) arguments that our society is fundamentally and importantly wrong, and (3) arguments that we are making important mistakes.
>
> So that provides one angle of argument for why I want people to call themselves EAs even if their work is quite speculative and even if they care about different things than me, as long as they’re trying to do as much good in the world as possible in an impartial, maximizing, outcome-oriented way.
>
> This means many EAs will have very different goals from one another. That’s okay. The main argument against EAs all sharing a single priority is that we’d be very motivated not to change our minds if we had to leave the movement when we became persuaded that something else was the most important thing to do. It works a lot better, given how much uncertainty there is about what the most important priorities are, to have a movement for _everyone_ trying to do as much good as possible in an impartial, maximizing, outcome-oriented way.
>
> Then, in addition to that, I think there’s a very concrete argument that wild animal suffering is an area worth researching.
>
> Right now there is vanishingly little research into what animals’ lives are like, especially wild animals. Almost no research into the effects of climate change, environmental measures, or land use changes examines the effects those will have on the suffering of animals. There’s a new research field focused on these questions, called welfare biology. I think fundamental welfare biology research, like fundamental development economics research or fundamental medicine research, is going to dramatically influence our understanding, ten years from now, of which interventions are a good idea.
>
> Just like I want people who develop vaccines and research global development to be in EA, I want people who research welfare biology to be in EA. This doesn’t rely on any of the above arguments that speculative work is good in general. The whole core of this argument is ‘welfare biology looks like a field that has important research questions relevant to doing as much good as possible.’ I am excited about what the field will look like in ten years, even though most of its core questions, given the field’s nascent stage, are pretty uncertain.
>
> One last thing: There are so many awful problems in the world, and every person working on them can do so much, that it is hard not to take it personally when someone is wasting their time. After all, there’s so much good they could do if they spent it well! But I think that, long-term, it’s just not sustainable to be mad at people for being wrong about what’s most important. **One of the biggest changes in my thinking over the last few years has just been this growing sense of how hard it is to arrive at true understandings of things, and how complicated and detailed reality is. This has made it a lot easier for me to look at people who I feel are totally wrong-headed and be glad they’re trying, and hopeful that there’s some productive fruit down the path they’re walking.** I think that every single person doing speculative research in EA really, deeply cares about making the world a better place, and even though I think many of them are off-base, I very much hope their research teaches them important things I can use to try to fix stuff.

{{< rawhtml >}}

<html>
  <head>
    <script type="module" src="https://js.withorbit.com/orbit-web-component.js"></script>
  </head>
  <body>
    <orbit-reviewarea color="blue">
      <orbit-prompt
        question="According to Kelsey Piper, what does it mean for effective altruism to be robustly good?"
        answer="To have done good even when embedded in societies that were doing great evil, or societies that were oriented around entirely the wrong questions, or a society that had a “do-gooder” consensus that was actually terrible."
      ></orbit-prompt>
      <orbit-prompt
        question="How do we ensure that EA is robustly good?"
        answer="We have to be accountable and check for results, check if we're doing harm under many possible worldviews, and be supportive of sound but fringe ideas."
      ></orbit-prompt>
    </orbit-reviewarea>
  </body>
</html>

{{< /rawhtml >}}

_This work is licensed under a_[ _Creative Commons Attribution 4.0 International License_](https://creativecommons.org/licenses/by/4.0/) _._

# All Animals Are Equal

_by Peter Singer, excerpted from All Animals Are Equal, the first chapter of Animal Liberation_ , third edition

![](http://res.cloudinary.com/cea/image/upload/v1667999557/mirroredImages/AXkbKxw2znzRcDEcS/iypcrbw26oczxdnzzvdl.jpg)

When we say that all human beings, whatever their race, creed, or sex, are equal, what is it that we are asserting? Those who wish to defend hierarchical, inegalitarian societies have often pointed out that by whatever test we choose it simply is not true that all humans are equal. Like it or not we must face the fact that humans come in different shapes and sizes; they come with different moral capacities, different intellectual abilities, different amounts of benevolent feeling and sensitivity to the needs of others, different abilities to communicate effectively, and different capacities to experience pleasure and pain. In short, if the demand for equality were based on the actual equality of all human beings, we would have to stop demanding equality. Still, one might cling to the view that the demand for equality among human beings is based on the actual equality of the different races and sexes.

However, there is no need to pin the case for equality to one particular outcome of a scientific investigation. The appropriate response to those who claim to have found evidence of genetically based differences in ability among the races or between the sexes is not to stick to the belief that the genetic explanation must be wrong, whatever evidence to the contrary may turn up; instead we should make it quite clear that the claim to equality does not depend on intelligence, moral capacity, physical strength, or similar matters of fact. Equality is a moral idea, not an assertion of fact. There is no logically compelling reason for assuming that a factual difference in ability between two people justifies any difference in the amount of consideration we give to their needs and interests. The principle of the equality of human beings is not a description of an alleged actual equality among humans: it is a prescription of how we should treat human beings.

Jeremy Bentham, the founder of the reforming utilitarian school of moral philosophy, incorporated the essential basis of moral equality into his system of ethics by means of the formula: "Each to count for one and none for more than one." In other words, the interests of every being affected by an action are to be taken into account and given the same weight as the like interests of any other being...

It is an implication of this principle of equality that our concern for others and our readiness to consider their interests ought not to depend on what they are like or on what abilities they may possess. Precisely what our concern or consideration requires us to do may vary according to the characteristics of those affected by what we do: concern for the well-being of children growing up in America would require that we teach them to read; concern for the well-being of pigs may require no more than that we leave them with other pigs in a place where there is adequate food and room to run freely. But the basic element-the taking into account of the interests of the being, whatever those interests may be-must, according to the principle of equality, be extended to all beings, black or white, masculine or feminine, human or nonhuman.

Thomas Jefferson, who was responsible for writing the principle of the equality of men into the American Declaration of Independence, saw this point. It led him to oppose slavery even though he was unable to free himself fully from his slaveholding background. He wrote in a letter to the author of a book that emphasized the notable intellectual achievements of Negroes in order to refute the then common view that they had limited intellectual capacities:

“Be assured that no person living wishes more sincerely than I do, to see a complete refutation of the doubts I myself have entertained and expressed on the grade of understanding allotted to them by nature, and to find that they are on a par with ourselves... but whatever be their degree of talent it is no measure of their rights. Because Sir Isaac Newton was superior to others in understanding, he was not therefore lord of the property or persons of others.”

It is on this basis that the case against racism and the case against sexism must both ultimately rest; and it is in accordance with this principle that the attitude that we may call "speciesism," by analogy with racism, must also be condemned. If possessing a higher degree of intelligence does not entitle one human to use another for his or her own ends, how can it entitle humans to exploit nonhumans for the same purpose?

It may be objected that comparisons of the sufferings of different species are impossible to make and that for this reason when the interests of animals and humans clash the principle of equality gives no guidance. It is probably true that comparisons of suffering between members of different species cannot be made precisely, but precision is not essential. Even if we were to prevent the infliction of suffering on animals only when it is quite certain that the interests of humans will not be affected to anything like the extent that animals are affected, we would be forced to make radical changes in our treatment of animals that would involve our diet, the farming methods we use, experimental procedures in many fields of science, our approach to wildlife and to hunting, trapping and the wearing of furs, and areas of entertainment like circuses, rodeos, and zoos. As a result, a vast amount of suffering would be avoided.

{{< rawhtml >}}

<html>
  <head>
    <script type="module" src="https://js.withorbit.com/orbit-web-component.js"></script>
  </head>
  <body>
    <orbit-reviewarea color="blue">
      <orbit-prompt
        question="In Animal Liberation, what's the key argument for all animals being equal?"
        answer="The principle of the equality of human beings is not a description of an alleged actual equality among humans: it is a prescription of how we should treat human beings. Similarly, our concern for a particular species ought not to depend on what they are like or on what abilities they may possess."
      ></orbit-prompt>
      <orbit-prompt
        question="What is speciesism?"
        answer="One species is entitled to higher moral concern than others, because of differences in intelligence."
      ></orbit-prompt>
    </orbit-reviewarea>
  </body>
</html>

{{< /rawhtml >}}

# Animal Welfare Cause report, Founders Pledge

This is a linkpost for [https://founderspledge.com/stories/animal-welfare-cause-report](https://forum-bots.effectivealtruism.org/out?url=https%3A%2F%2Ffounderspledge.com%2Fstories%2Fanimal-welfare-cause-report)

_This work is licensed under a_[ _Creative Commons Attribution 4.0 International License_](https://creativecommons.org/licenses/by/4.0/) _._

# Want to help animals? Focus on corporate decisions, not people’s plates.

This is a linkpost for [https://www.vox.com/future-perfect/2018/10/31/18026418/vegan-vegetarian-animal-welfare-corporate-advocacy](https://forum-bots.effectivealtruism.org/out?url=https%3A%2F%2Fwww.vox.com%2Ffuture-perfect%2F2018%2F10%2F31%2F18026418%2Fvegan-vegetarian-animal-welfare-corporate-advocacy)

{{< rawhtml >}}

<html>
  <head>
    <script type="module" src="https://js.withorbit.com/orbit-web-component.js"></script>
  </head>
  <body>
    <orbit-reviewarea color="blue">
      <orbit-prompt
        question="Why is it more effective to focus on convincing corporations, not people, when it comes to animal welfare advocacy?"
        answer="
- Empirically, it is exceptionally hard to turn people vegetarian, or change their minds, period. 
- Meanwhile, groups like the Humane League have been successful in getting concessions from companies to use e.g. cage-free hens."
      ></orbit-prompt>
    </orbit-reviewarea>
  </body>
</html>

{{< /rawhtml >}}

# Animal Advocacy Careers (Website to explore)

This is a linkpost for [https://www.animaladvocacycareers.org/](https://forum-bots.effectivealtruism.org/out?url=https%3A%2F%2Fwww.animaladvocacycareers.org%2F)

# Exercise for 'Radical Empathy'

This chapter's exercise is about doing some personal reflection. There are no right or wrong answers here, instead this is an opportunity for you to take some time and think about your ethical values and beliefs.

**A letter to the past (10 mins.)**

This exercise asks you to explore what it would take to change your mind about something important.

Imagine someone from the past who held views characteristic of that time. Also imagine, for the sake of the exercise, that this person is not too different from you - perhaps you would have been friends. Unfortunately, many people in the past were complicit in horrible things, such as slavery, sexism, racism, and homophobia, which were even more prevalent in the past than they are now. And, sadly, this historical counterpart is also complicit in some moral tragedy common to their time, perhaps not out of malevolence or ill-will, but merely through indifference or ignorance.

This exercise is to write a short letter to this historical friend arguing that they should care about a specific group that your present self values. Imagine that they are complicit in owning slaves, or in the oppression of women, people of other races, or sexual minorities.

For the sake of this exercise, imagine your historical counterpart is not malevolent or selfish, they think they are living a normal moral life, but are unaware of where they are going wrong. What could you say to them to make them realize that they’re doing wrong? What evidence are they overlooking that allows them to hold their discriminatory views? You might want to write a few paragraphs or just bullet points, and spend time reflecting on what you write.

# More to explore on 'Radical Empathy'

## An expanding moral circle?

- _The Expanding Circle_ pg. 111-124 [_‘Expanding the Circle of Ethics’ section_](https://tinyurl.com/ywy6kjkx) (20 mins.)
- [ _The Narrowing Circle_](https://tinyurl.com/em2w8xhf) (see here for [_summary and discussion_](https://tinyurl.com/jpxdh98r)) - _An argument that the “expanding circle” historical thesis ignores all instances in which modern ethics narrowed the set of beings to be morally regarded, often backing its exclusion by asserting their non-existence, and thus assumes its conclusion._ (30 mins.)
- [ _Our descendants will probably see us as moral monsters. What should we do about that? - 80,000 Hours_](https://tinyurl.com/2ck3wk6s) _\- A conversation with Professor Will MacAskill._ (Podcast - 1 hour 50 mins.)
- [ _The Possibility of an Ongoing Moral Catastrophe_](https://tinyurl.com/2cpkedav) (full text of the required article, 30 mins.)

## The case for caring about animal welfare

- [ _The Case Against Speciesism - Centre for Reducing Suffering_](https://tinyurl.com/26ts84md) (10 mins.)
- [ _Factory Farming - 80,000 Hours_](https://80000hours.org/problem-profiles/factory-farming/) (5 mins.)
- [ _Should animals, plants, and robots have the same rights as you? - Vox_](https://tinyurl.com/3sypp6ux) (20 mins.)
- _Animal Liberation,_ [_Chapter 3 - Down on the factory farm_](https://tinyurl.com/vre6jyy) (1 hour.)
- [ _2017 Report on Consciousness and Moral Patienthood_](https://tinyurl.com/57d3wkda) \- An _investigation into what types of beings merit moral concern._ (6 hours, skimmable)
- [ _Suffering in Animals vs. Humans_](https://tinyurl.com/ytt4xb7u) (13 mins.)
- [ _Rethink Priorities’ Welfare Range Estimates_](https://forum.effectivealtruism.org/s/y5n47MfgrKvTLE3pw/p/Qk3hd6PrFManj8K6o) (19 mins.)

## Reforming animal agriculture

- [ \_ \_Dominion\_\_](https://tinyurl.com/6vzkmyr7) _\- Dominion uses drones, hidden and handheld cameras to expose the dark side of modern animal agriculture. (Film - 2 hours)_
  - Content Warning: Much of the film here can be extremely disturbing and includes graphically violent footage of factory farming. Please make sure to watch this in a moment without e.g. any upcoming deadlines or important meetings the same day. We include it because we think it’s important to really see how broken the world is.
- [ _Food impacts_](https://foodimpacts.org/) _a tool to explore the moral impact of different dietary choices._
- [ _A New Agricultural Revolution_](https://tinyurl.com/wbsfev8s) (~22 mins. and [_transcript_](https://tinyurl.com/jp9ja8f2) available; Q&A after Friedrich’s talk is optional)
- [ _How Students Will Lead the Alternative Protein Revolution_](https://tinyurl.com/ursaat9h) \- Amy Huang (26 mins.)

## Wild animal welfare

- [ _Wild animal suffering: An introduction - Animal Ethics_](https://www.animal-ethics.org/introduction-to-wild-animal-suffering/) \- _An argument for us to take into account the wellbeing of animals that live in the wild._ (10 mins)
- [ _Wild Animal Initiative’s FAQ_](https://www.wildanimalinitiative.org/faq)

## Criticism of EA-related animal welfare work

- [ _How the animal movement could do even more good_](https://forum.effectivealtruism.org/posts/uz3NjAJjkjpb3mj6w/how-the-animal-movement-could-do-even-more-good) (11 mins.)
- [ _EAA is relatively overinvesting in corporate welfare reforms_](https://forum.effectivealtruism.org/posts/kHdKWmTcS3FfcYAZj/eaa-is-relatively-overinvesting-in-corporate-welfare-reforms) _There is also an interesting response to this post from Saulius in the first set of comments._ (7 mins.)
- [ _Against the Moral Standing of Animals_](http://faculty.philosophy.umd.edu/pcarruthers/The%20Animals%20Issue.pdf) _critique of arguments that animals deserve moral standing_
- [ _What’s Wrong with Speciesism?_](https://cpb-us-w2.wpmucdn.com/campuspress.yale.edu/dist/7/724/files/2016/03/Whats-Wrong-with-Speciesism-299h6xu.pdf) _Argument that animals do deserve moral standing, but lower moral status_

## Taking Action

- [ _Impactful Animal Advocacy_](https://www.impactfulanimaladvocacy.org/) \- An online community of animal advocates with an active Slack space
- [ _Effective Animal Advocacy - Discussion_](https://www.facebook.com/groups/EffectiveAnimalAdvocacy/permalink/563599303810945/) \- Global, active Facebook group discussing topics in EAA
- [ _Talist_](https://talist.org/job-board) \- Alternative protein job board
- [ _Animal Advocacy Careers_](https://www.animaladvocacycareers.org/job-board) \- Job board for careers in animal advocacy
- [ _Connect for Animals_](https://connectforanimals.com/events) \- Animal advocacy events database
- [ _How I Learned to Love Shrimp_](https://www.howilearnedtoloveshrimp.com/) \- A podcast about impactful and innovative ways to help animals
